"""
å¢å¼ºç‰ˆç°ä»£è‚¡ç¥¨åˆ†æç³»ç»Ÿ
æ”¯æŒ25é¡¹è´¢åŠ¡æŒ‡æ ‡ã€è¯¦ç»†æ–°é—»åˆ†æã€æŠ€æœ¯åˆ†æã€æƒ…ç»ªåˆ†æå’ŒAIå¢å¼ºåˆ†æ
æ•°æ®æºï¼šBaoStock + akshareï¼ˆå¤‡ç”¨ï¼‰
"""

import os
import sys
import logging
import warnings
import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import time
import re
import concurrent.futures

# BaoStockæ•°æ®æ¥å£
import baostock as bs

def check_market_status():
    """æ£€æŸ¥Aè‚¡å¸‚åœºå¼€ç›˜çŠ¶æ€"""
    now = datetime.now()
    weekday = now.weekday()  # 0=å‘¨ä¸€, 6=å‘¨æ—¥
    hour = now.hour
    minute = now.minute
    current_time = hour * 100 + minute  # è½¬æ¢ä¸ºHHMMæ ¼å¼ä¾¿äºæ¯”è¾ƒ
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºäº¤æ˜“æ—¥ï¼ˆå‘¨ä¸€åˆ°å‘¨äº”ï¼‰
    if weekday >= 5:  # å‘¨å…­å‘¨æ—¥
        return False, "å¸‚åœºä¼‘å¸‚ï¼ˆå‘¨æœ«ï¼‰"
    
    # Aè‚¡äº¤æ˜“æ—¶é—´ï¼š
    # ä¸Šåˆï¼š9:30-11:30
    # ä¸‹åˆï¼š13:00-15:00
    if (930 <= current_time <= 1130) or (1300 <= current_time <= 1500):
        return True, "å¸‚åœºå¼€ç›˜ä¸­"
    elif current_time < 930:
        return False, "å¸‚åœºæœªå¼€ç›˜ï¼ˆæ—©ç›˜å‰ï¼‰"
    elif 1130 < current_time < 1300:
        return False, "å¸‚åœºä¼‘å¸‚ï¼ˆåˆä¼‘ï¼‰"
    else:  # current_time > 1500
        return False, "å¸‚åœºæ”¶ç›˜"

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('stock_analyzer.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class EnhancedStockAnalyzer:
    """å¢å¼ºç‰ˆç»¼åˆè‚¡ç¥¨åˆ†æå™¨"""
    
    def __init__(self, config_file='config.json', weights: Optional[Dict[str, float]] = None, thresholds: Optional[Dict[str, float]] = None):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.logger = logging.getLogger(__name__)
        self.config_file = config_file
        
        # åˆå§‹åŒ–BaoStockè¿æ¥
        self._init_baostock()
        
        # åŠ è½½é…ç½®æ–‡ä»¶
        self.config = self._load_config()

        # å¯é€‰ï¼šç½‘ç»œä»£ç†è®¾ç½®ï¼ˆç”¨äºä¸œè´¢ç­‰ç½‘ç»œè®¿é—®ä¸ç•…åœºæ™¯ï¼‰
        try:
            net = self.config.get('network', {}) if isinstance(self.config, dict) else {}
            if net.get('enable_proxies'):
                http_p = net.get('http_proxy') or net.get('HTTP_PROXY')
                https_p = net.get('https_proxy') or net.get('HTTPS_PROXY')
                no_p = net.get('no_proxy') or net.get('NO_PROXY')
                if http_p:
                    os.environ['HTTP_PROXY'] = str(http_p)
                if https_p:
                    os.environ['HTTPS_PROXY'] = str(https_p)
                if no_p:
                    os.environ['NO_PROXY'] = str(no_p)
                self.logger.info("âœ“ å·²åº”ç”¨ç½‘ç»œä»£ç†é…ç½®åˆ°ç¯å¢ƒå˜é‡")
            # è¯»å–èµ„é‡‘æµæ¥å£ç¨³å¥æ€§é…ç½®
            try:
                self.fund_flow_timeout_seconds = float(net.get('fund_flow_timeout_seconds', 6.5))
            except Exception:
                self.fund_flow_timeout_seconds = 6.5
            try:
                self.fund_flow_retries = int(net.get('fund_flow_retries', 3))
            except Exception:
                self.fund_flow_retries = 3
        except Exception as e:
            self.logger.warning(f"ä»£ç†é…ç½®åº”ç”¨å¤±è´¥: {e}")
        
        # ç¼“å­˜é…ç½®
        cache_config = self.config.get('cache', {})
        self.cache_duration = timedelta(hours=cache_config.get('price_hours', 1))
        self.fundamental_cache_duration = timedelta(hours=cache_config.get('fundamental_hours', 6))
        self.news_cache_duration = timedelta(hours=cache_config.get('news_hours', 2))
        
        self.price_cache = {}
        self.fundamental_cache = {}
        self.news_cache = {}
        
        # åˆ†ææƒé‡é…ç½®ï¼ˆå…è®¸é€šè¿‡æ„é€ å‡½æ•°è¦†ç›–ï¼‰
        cfg_weights = self.config.get('analysis_weights', {})
        merged_weights = {
            'technical': cfg_weights.get('technical', 0.4),
            'fundamental': cfg_weights.get('fundamental', 0.4),
            'sentiment': cfg_weights.get('sentiment', 0.2)
        }
        if isinstance(weights, dict) and weights:
            merged_weights.update({k: float(v) for k, v in weights.items() if k in merged_weights})
        self.analysis_weights = merged_weights
        # å…¼å®¹ï¼šåŒæ—¶æä¾› self.weights å¼•ç”¨ï¼Œä¾¿äºå¤–éƒ¨æˆ–åç»­é€»è¾‘ç»Ÿä¸€è¯»å–
        self.weights = merged_weights

        default_thresholds = {
            'rsi_overbought': 70.0,
            'rsi_oversold': 30.0,
            'rsi_neutral_low': 45.0,
            'rsi_neutral_high': 65.0,
            'bb_lower': 0.2,
            'bb_upper': 0.8,
            'volume_ratio_low': 0.6,
            'volume_ratio_high': 1.5,
            'volume_ratio_very_low': 0.7,
            'volume_ratio_very_high': 2.0,
            'atr_high_risk': 6.0,
            'atr_low_vol': 2.0,
            'confirm_days': 1
        }
        cfg_thresholds = self.config.get('technical_thresholds', {})
        default_thresholds.update({k: cfg_thresholds.get(k, v) for k, v in default_thresholds.items()})
        if isinstance(thresholds, dict) and thresholds:
            default_thresholds.update({k: thresholds.get(k, v) for k, v in default_thresholds.items()})
        self.thresholds = default_thresholds
        
        # æµå¼æ¨ç†é…ç½®
        streaming = self.config.get('streaming', {})
        self.streaming_config = {
            'enabled': streaming.get('enabled', True),
            'show_thinking': streaming.get('show_thinking', True),
            'delay': streaming.get('delay', 0.1)
        }
        
        # AIé…ç½®
        ai_config = self.config.get('ai', {})
        self.ai_config = {
            'max_tokens': ai_config.get('max_tokens', 4000),
            'temperature': ai_config.get('temperature', 0.7),
            'model_preference': ai_config.get('model_preference', 'openai')
        }
        # åˆ†æå‚æ•°é…ç½®
        params = self.config.get('analysis_params', {})
        self.analysis_params = {
            'max_news_count': params.get('max_news_count', 200),
            'technical_period_days': params.get('technical_period_days', 365),
            'financial_indicators_count': params.get('financial_indicators_count', 25)
        }
        
        # APIå¯†é’¥é…ç½®
        self.api_keys = self.config.get('api_keys', {})
        
        self.logger.info("å¢å¼ºç‰ˆè‚¡ç¥¨åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
        self._log_config_status()

    # =============================
    # å¸‚åœºä¸ä»£ç è¾…åŠ©
    # =============================
    def _get_trading_dates(self, start_date: datetime, end_date: datetime) -> List[datetime]:
        """è·å–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„Aè‚¡äº¤æ˜“æ—¥åˆ—è¡¨
        
        ä½¿ç”¨ç®€å•è§„åˆ™è¿‡æ»¤ï¼šæ’é™¤å‘¨æœ«ï¼ˆå‘¨å…­æ—¥ï¼‰ï¼Œæš‚ä¸å¤„ç†èŠ‚å‡æ—¥ï¼ˆå› Kçº¿æ•°æ®æœ¬èº«å·²æ˜¯äº¤æ˜“æ—¥ï¼‰
        å®é™…ä½¿ç”¨ä¸­ï¼Œä»æ•°æ®æºè·å–çš„Kçº¿æ•°æ®å·²ç»æ˜¯äº¤æ˜“æ—¥ï¼Œæ­¤æ–¹æ³•ä¸»è¦ç”¨äºéªŒè¯å’Œè¯´æ˜
        """
        try:
            trading_dates = []
            current_date = start_date
            while current_date <= end_date:
                # æ’é™¤å‘¨æœ«ï¼ˆ0=å‘¨ä¸€, 6=å‘¨æ—¥ï¼‰
                if current_date.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                    trading_dates.append(current_date)
                current_date += timedelta(days=1)
            return trading_dates
        except Exception as e:
            self.logger.warning(f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
            return []

    def _format_code_for_eastmoney(self, stock_code: str) -> str:
        """æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ä¸ºEastmoneyéœ€è¦çš„å‰ç¼€æ ¼å¼ï¼Œå¦‚ sh600000 / sz000001 / bj8xxxxx"""
        try:
            s = str(stock_code)
            if s.startswith(('60', '68')):
                return f"sh{s}"
            if s.startswith(('00', '30', '20')):
                return f"sz{s}"
            if s.startswith(('83', '87', '43')):
                return f"bj{s}"
            # å…œåº•ï¼šå¤§æ¦‚ç‡æ·±å¸‚
            return f"sz{s}"
        except Exception:
            return str(stock_code)

    def _detect_board(self, stock_code: str) -> str:
        """æ£€æµ‹æ¿å—ï¼šMain/SME/ChiNext/STAR/Beijing"""
        s = str(stock_code)
        if s.startswith(('600', '601', '603', '605')):
            return 'Main'
        if s.startswith('002'):
            return 'SME'
        if s.startswith('300'):
            return 'ChiNext'
        if s.startswith('688'):
            return 'STAR'
        if s.startswith(('83', '87', '43')):
            return 'Beijing'
        return 'Other'

    def _estimate_market_cap(self, fundamental_data: dict) -> Optional[float]:
        """ä»å·²è·å–çš„ä¼°å€¼ä¿¡æ¯ä¼°ç®—æ€»å¸‚å€¼ï¼ˆå…ƒï¼‰ã€‚è‹¥ä¸å¯ç”¨è¿”å›None"""
        try:
            val = (fundamental_data or {}).get('valuation') or {}
            m = val.get('æ€»å¸‚å€¼')
            if m is None:
                # æœ‰äº›æ¥å£è¿”å›å•ä½äº¿
                m = val.get('æ€»å¸‚å€¼(äº¿)')
                if m is not None:
                    return float(m) * 1e8
            return float(m) if m is not None else None
        except Exception:
            return None

    def _call_with_timeout(self, func, timeout_seconds: float, *args, **kwargs):
        """åœ¨çº¿æ•°æ®è°ƒç”¨çš„è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…ç¬¬ä¸‰æ–¹åº“åœ¨ç½‘ç»œä¸ç•…æ—¶é•¿æ—¶é—´é˜»å¡ã€‚

        è¿”å›ï¼š
        - æ­£å¸¸ï¼šfunc çš„è¿”å›å€¼
        - è¶…æ—¶ï¼šç‰¹æ®Šå¯¹è±¡ TimeoutError('timeout')
        - å¼‚å¸¸ï¼šåŸå§‹å¼‚å¸¸å¯¹è±¡
        """
        executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)
        fut = executor.submit(func, *args, **kwargs)
        try:
            return fut.result(timeout=max(0.5, float(timeout_seconds)))
        except concurrent.futures.TimeoutError:
            try:
                self.logger.info(f"è°ƒç”¨è¶…æ—¶({timeout_seconds}s): {getattr(func, '__name__', 'func')}")
            except Exception:
                pass
            return TimeoutError("timeout")
        except Exception as e:
            return e
        finally:
            try:
                executor.shutdown(wait=False, cancel_futures=True)
            except Exception:
                pass

    # =============================
    # èµ„é‡‘æµå‘ï¼ˆè¿‘1ä¸ªæœˆï¼‰
    # =============================
    def calculate_capital_flow(self, stock_code: str, price_data: pd.DataFrame, fundamental_data: Optional[dict] = None, window_days: int = 30) -> dict:
        """
        è®¡ç®—è¿‘1ä¸ªæœˆï¼ˆæŒ‰äº¤æ˜“æ—¥å›æº¯çº¦30å¤©ï¼‰åˆ†æ¡£èµ„é‡‘æµå‘ï¼šè¶…å¤§/å¤§/ä¸­/å°å•å‡€æµé¢åˆè®¡ï¼Œä¸»åŠ›å‡€æµå…¥ç­‰ã€‚

        è¿”å›ç»“æ„ç¤ºä¾‹ï¼š
        {
          'window_days': 30,
          'sum_amount': <æ€»æˆäº¤é¢>,
          'buckets': {
             'extra_large': {'net': x, 'pos_days': n1, 'neg_days': n2, 'ratio_to_turnover': r1, 'status': 'å¼ºåŠ²æµå…¥/...' },
             'large': {...},
             'medium': {...},
             'small': {...}
          },
          'main_force_net': <è¶…å¤§+å¤§å‡€é¢>,
          'main_force_ratio_to_turnover': <å æ€»æˆäº¤é¢æ¯”ä¾‹>,
          'status': 'ä¸»åŠ›å‡€æµå…¥å¼º/ä¸­/å¼±/å‡€æµå‡º',
          'note': 'å•ä½ä¸å£å¾„è¯´æ˜'
        }
        """
        result = {
            'window_days': int(window_days),
            'buckets': {},
            'main_force_net': None,
            'main_force_ratio_to_turnover': None,
            'status': 'æ•°æ®ä¸è¶³',
            'sum_amount': None,
            'note': '',
            'source': ''
        }

        try:
            import akshare as ak
        except Exception as e:
            self.logger.info(f"èµ„é‡‘æµæ¥å£ä¸å¯ç”¨(akshareæœªå®‰è£…): {e}")
            result['note'] = 'akshareæœªå®‰è£…'
            return result

        # è·å–èµ„é‡‘æµï¼Œå¸¦é‡è¯•
        df = None
        em_code = self._format_code_for_eastmoney(stock_code)
        last_err = None
        retries = max(1, int(getattr(self, 'fund_flow_retries', 3)))
        timeout_s = max(1.0, float(getattr(self, 'fund_flow_timeout_seconds', 6.5)))
        for i in range(retries):
            try:
                self.logger.info(f"æ­£åœ¨è·å–è¿‘æœˆèµ„é‡‘æµ: {em_code}")
                # ä¸ºé¿å…ç½‘ç»œé˜»å¡ï¼Œå¢åŠ è°ƒç”¨è¶…æ—¶ä¿æŠ¤
                res = self._call_with_timeout(ak.stock_individual_fund_flow, timeout_s, stock=em_code)
                if isinstance(res, TimeoutError):
                    last_err = res
                elif isinstance(res, Exception):
                    last_err = res
                else:
                    df = res
                    if df is not None and not getattr(df, 'empty', True):
                        result['source'] = 'akshare_em'
                        break
                    last_err = RuntimeError("ç©ºæ•°æ®")
            except Exception as e:
                last_err = e
            # é€€é¿
            try:
                time.sleep(0.6 * (i + 1))
            except Exception:
                pass
        if df is None or (hasattr(df, 'empty') and df.empty):
            self.logger.info(f"è·å–èµ„é‡‘æµå¤±è´¥: {last_err}")
            result['note'] = f"èµ„é‡‘æµæ¥å£å¤±è´¥:{str(last_err)[:60] if last_err else 'æœªçŸ¥'}"
            return result

        if df is None or df.empty:
            result['note'] = 'æ— èµ„é‡‘æµæ•°æ®'
            return result

        # è§£ææ—¥æœŸå¹¶æˆªå–çª—å£
        date_col = None
        for c in ['æ—¥æœŸ', 'date', df.columns[0]]:
            if c in df.columns:
                date_col = c
                break
        try:
            df['_dt'] = pd.to_datetime(df[date_col], errors='coerce')
        except Exception:
            df['_dt'] = pd.NaT
        cutoff = datetime.now() - timedelta(days=max(7, int(window_days)))
        df = df[df['_dt'] >= cutoff]
        if df.empty:
            result['note'] = 'çª—å£å†…æ— æ•°æ®'
            return result

        # åˆ—åæ˜ å°„ï¼Œå…¼å®¹ä¸åŒå­—æ®µ
        def pick(*cands):
            for c in cands:
                if c in df.columns:
                    return c
            return None

        cols = {
            'xd_net': pick('è¶…å¤§å•å‡€æµå…¥-å‡€é¢', 'è¶…å¤§å•-å‡€é¢', 'xl_net'),
            'xl_ratio': pick('è¶…å¤§å•å‡€æµå…¥-å‡€å æ¯”', 'è¶…å¤§å•-å‡€å æ¯”', 'xl_ratio'),
            'lg_net': pick('å¤§å•å‡€æµå…¥-å‡€é¢', 'å¤§å•-å‡€é¢', 'lg_net'),
            'lg_ratio': pick('å¤§å•å‡€æµå…¥-å‡€å æ¯”', 'å¤§å•-å‡€å æ¯”', 'lg_ratio'),
            'md_net': pick('ä¸­å•å‡€æµå…¥-å‡€é¢', 'ä¸­å•-å‡€é¢', 'md_net'),
            'md_ratio': pick('ä¸­å•å‡€æµå…¥-å‡€å æ¯”', 'ä¸­å•-å‡€å æ¯”', 'md_ratio'),
            'sm_net': pick('å°å•å‡€æµå…¥-å‡€é¢', 'å°å•-å‡€é¢', 'sm_net'),
            'sm_ratio': pick('å°å•å‡€æµå…¥-å‡€å æ¯”', 'å°å•-å‡€å æ¯”', 'sm_ratio'),
        }

        # æ•°å€¼åŒ–
        for key, c in cols.items():
            if c and c in df.columns:
                try:
                    df[key] = pd.to_numeric(df[c], errors='coerce')
                except Exception:
                    df[key] = np.nan
            else:
                df[key] = np.nan

        # è®¡ç®—çª—å£å†…åˆè®¡å‡€é¢ä¸å¤©æ•°
        def agg_bucket(net_col: str):
            s = df[net_col].dropna()
            net = float(s.sum()) if len(s) else 0.0
            pos_days = int((s > 0).sum()) if len(s) else 0
            neg_days = int((s < 0).sum()) if len(s) else 0
            return net, pos_days, neg_days

        xd_net, xd_pos, xd_neg = agg_bucket('xd_net')
        lg_net, lg_pos, lg_neg = agg_bucket('lg_net')
        md_net, md_pos, md_neg = agg_bucket('md_net')
        sm_net, sm_pos, sm_neg = agg_bucket('sm_net')

        # è®¡ç®—æˆäº¤é¢åŸºå‡†ï¼ˆæ¥è‡ªä»·æ ¼æ•°æ®çš„ amount åˆ—ï¼ŒBaoStockä¸ºäº¤æ˜“é¢ï¼‰
        try:
            if price_data is not None and not price_data.empty and 'amount' in price_data.columns:
                p = price_data.copy()
                p['_dt'] = pd.to_datetime(p.get('date', p.index), errors='coerce')
                p = p[p['_dt'] >= cutoff]
                sum_amount = float(pd.to_numeric(p['amount'], errors='coerce').dropna().sum()) if not p.empty else np.nan
            else:
                sum_amount = np.nan
        except Exception:
            sum_amount = np.nan

        result['sum_amount'] = None if not np.isfinite(sum_amount) else float(sum_amount)

        # æ¯”ä¾‹ï¼ˆå¯¹æ€»æˆäº¤é¢ï¼‰ï¼Œè‹¥æˆäº¤é¢ä¸å¯ç”¨åˆ™ä»…è¿”å›å‡€é¢
        def ratio(v):
            if np.isfinite(sum_amount) and sum_amount > 0:
                return float(v / sum_amount)
            return None

        result['buckets'] = {
            'extra_large': {
                'net': float(xd_net), 'pos_days': xd_pos, 'neg_days': xd_neg, 'ratio_to_turnover': ratio(xd_net)
            },
            'large': {
                'net': float(lg_net), 'pos_days': lg_pos, 'neg_days': lg_neg, 'ratio_to_turnover': ratio(lg_net)
            },
            'medium': {
                'net': float(md_net), 'pos_days': md_pos, 'neg_days': md_neg, 'ratio_to_turnover': ratio(md_net)
            },
            'small': {
                'net': float(sm_net), 'pos_days': sm_pos, 'neg_days': sm_neg, 'ratio_to_turnover': ratio(sm_net)
            }
        }

        # ä¸»åŠ›ï¼ˆè¶…å¤§+å¤§ï¼‰
        main_net = float((xd_net if np.isfinite(xd_net) else 0.0) + (lg_net if np.isfinite(lg_net) else 0.0))
        result['main_force_net'] = main_net
        result['main_force_ratio_to_turnover'] = ratio(main_net)

        # æ ¹æ®æ¿å—ä¸ä½“é‡åŠ¨æ€é˜ˆå€¼æ‰“åˆ†/è¯„çº§
        board = self._detect_board(stock_code)
        # åŸºç¡€é˜ˆå€¼ï¼ˆå æˆäº¤é¢æ¯”ä¾‹ï¼‰
        th_strong = 0.08
        th_mid = 0.03
        th_weak = 0.01
        # æ¿å—ç¼©æ”¾
        scale = 1.0
        if board in ('ChiNext', 'STAR'):
            scale = 0.7
        elif board == 'SME':
            scale = 0.8
        elif board == 'Beijing':
            scale = 0.6

        # ä½“é‡ç¼©æ”¾ï¼ˆå¸‚å€¼å°çš„æ›´å®¹æ˜“è¾¾åˆ°å¼ºåº¦é—¨æ§›ï¼‰
        try:
            mktcap = self._estimate_market_cap(fundamental_data or {})
            if mktcap is not None:
                if mktcap < 1e10:      # < 100äº¿
                    scale *= 0.7
                elif mktcap < 4e10:   # 100-400äº¿
                    scale *= 0.85
                elif mktcap > 2e11:   # > 2000äº¿
                    scale *= 1.15
        except Exception:
            pass

        th_strong *= scale
        th_mid *= scale
        th_weak *= scale

        # å¤©æ•°å æ¯”
        total_days = int(len(df))
        pos_ratio_main = float((xd_pos + lg_pos) / total_days) if total_days > 0 else 0.0

        def label_status(ratio_val: Optional[float], pos_ratio: float) -> str:
            if ratio_val is None:
                # ç”¨å‡€é¢æ–¹å‘å…œåº•
                r = main_net
                if r > 0:
                    return 'å‡€æµå…¥(æ— æ³•ä¼°ç®—å¼ºåº¦)'
                elif r < 0:
                    return 'å‡€æµå‡º'
                else:
                    return 'æŒå¹³'
            if ratio_val >= th_strong and pos_ratio >= 0.6:
                return 'ä¸»åŠ›å‡€æµå…¥å¼º'
            if ratio_val >= th_mid and pos_ratio >= 0.5:
                return 'ä¸»åŠ›å‡€æµå…¥ä¸­'
            if ratio_val >= th_weak and pos_ratio >= 0.4:
                return 'ä¸»åŠ›å‡€æµå…¥å¼±'
            if ratio_val <= -th_mid:
                return 'ä¸»åŠ›å‡€æµå‡ºè¾ƒå¼º'
            if ratio_val < 0:
                return 'ä¸»åŠ›å‡€æµå‡º'
            return 'ä¸»åŠ›èµ„é‡‘è¶‹äºä¸­æ€§'

        result['status'] = label_status(result['main_force_ratio_to_turnover'], pos_ratio_main)

        # å•æ¡¶çŠ¶æ€
        def bucket_label(v_net: float, v_ratio: Optional[float], pos_days: int) -> str:
            if v_ratio is None:
                return 'å‡€æµå…¥' if v_net > 0 else ('å‡€æµå‡º' if v_net < 0 else 'æŒå¹³')
            if v_ratio >= th_strong * 0.6 and pos_days >= max(6, total_days // 3):
                return 'å¼º'
            if v_ratio >= th_mid * 0.6 and pos_days >= max(5, total_days // 4):
                return 'ä¸­'
            if v_ratio >= th_weak * 0.5 and pos_days >= max(4, total_days // 5):
                return 'å¼±'
            if v_ratio < 0:
                return 'æµå‡º'
            return 'ä¸­æ€§'

        for k in ['extra_large', 'large', 'medium', 'small']:
            b = result['buckets'][k]
            b['status'] = bucket_label(b['net'], b['ratio_to_turnover'], b['pos_days'])

        result['note'] = 'èµ„é‡‘å‡€é¢æŒ‰ä¸œè´¢å£å¾„ï¼Œè¿‘çº¦30è‡ªç„¶æ—¥å†…çš„äº¤æ˜“æ—¥ç´¯è®¡ï¼›æ¯”ä¾‹ä»¥åŒæœŸæˆäº¤é¢ä¼°ç®—ï¼ˆè‹¥å¯ç”¨ï¼‰'
        return result

        

    def _load_config(self):
        """åŠ è½½JSONé…ç½®æ–‡ä»¶"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                self.logger.info(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")
                return config
            else:
                self.logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                default_config = self._get_default_config()
                self._save_config(default_config)
                return default_config
                
        except json.JSONDecodeError as e:
            self.logger.error(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            self.logger.info("ä½¿ç”¨é»˜è®¤é…ç½®å¹¶å¤‡ä»½é”™è¯¯æ–‡ä»¶")
            
            if os.path.exists(self.config_file):
                backup_name = f"{self.config_file}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                os.rename(self.config_file, backup_name)
                self.logger.info(f"é”™è¯¯é…ç½®æ–‡ä»¶å·²å¤‡ä»½ä¸º: {backup_name}")
            default_config = self._get_default_config()
            self._save_config(default_config)
            return default_config
            
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return self._get_default_config()

    def _get_default_config(self):
        return {
            "api_keys": {
                "openai": "",
                "anthropic": "",
                "zhipu": "",
                "notes": "è¯·å¡«å…¥æ‚¨çš„APIå¯†é’¥"
            },
            "ai": {
                "model_preference": "openai",
                "models": {
                    "openai": "gpt-4o-mini",
                    "anthropic": "claude-3-haiku-20240307",
                    "zhipu": "chatglm_turbo"
                },
                "max_tokens": 6000,
                "temperature": 0.7,
                "api_base_urls": {
                    "openai": "https://api.openai.com/v1",
                    "notes": "å¦‚ä½¿ç”¨ä¸­è½¬APIï¼Œä¿®æ”¹ä¸Šè¿°URL"
                }
            },
            "analysis_weights": {
                "technical": 0.4,
                "fundamental": 0.4,
                "sentiment": 0.2,
                "notes": "æƒé‡æ€»å’Œåº”ä¸º1.0"
            },
            "technical_thresholds": {
                "rsi_overbought": 70.0,
                "rsi_oversold": 30.0,
                "rsi_neutral_low": 45.0,
                "rsi_neutral_high": 65.0,
                "bb_lower": 0.2,
                "bb_upper": 0.8,
                "volume_ratio_low": 0.6,
                "volume_ratio_high": 1.5,
                "volume_ratio_very_low": 0.7,
                "volume_ratio_very_high": 2.0,
                "atr_high_risk": 6.0,
                "atr_low_vol": 2.0,
                "confirm_days": 1,
                "notes": "å¯è°ƒæŠ€æœ¯é¢é˜ˆå€¼ä¸ç¡®è®¤å¤©æ•°"
            },
            "cache": {
                "price_hours": 1,
                "fundamental_hours": 6,
                "news_hours": 2
            },
            "network": {
                "snapshot_cache_ttl_hours": 4,
                "enable_proxies": False,
                "http_proxy": "",
                "https_proxy": "",
                "no_proxy": ""
            },
            "streaming": {
                "enabled": True,
                "show_thinking": True,
                "delay": 0.1
            },
            "analysis_params": {
                "max_news_count": 200,
                "technical_period_days": 365,
                "financial_indicators_count": 25
            },
            "logging": {
                "level": "INFO",
                "file": "stock_analyzer.log"
            },
            "data_sources": {
                "akshare_token": "",
                "backup_sources": ["akshare"]
            },
            "ui": {
                "theme": "default",
                "language": "zh_CN",
                "window_size": [1200, 800]
            },
            "_metadata": {
                "version": "3.0.0",
                "created": datetime.now().isoformat(),
                "description": "å¢å¼ºç‰ˆAIè‚¡ç¥¨åˆ†æç³»ç»Ÿé…ç½®æ–‡ä»¶"
            }
        }

    def _save_config(self, config):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=4)
            self.logger.info(f"âœ… é…ç½®æ–‡ä»¶å·²ä¿å­˜: {self.config_file}")
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

    def _log_config_status(self):
        """è®°å½•é…ç½®çŠ¶æ€"""
        self.logger.info("=== å¢å¼ºç‰ˆç³»ç»Ÿé…ç½®çŠ¶æ€ ===")
        
        # æ£€æŸ¥APIå¯†é’¥çŠ¶æ€
        available_apis = []
        for api_name, api_key in self.api_keys.items():
            if api_name != 'notes' and api_key and api_key.strip():
                available_apis.append(api_name)
        
        if available_apis:
            self.logger.info(f"ğŸ¤– å¯ç”¨AI API: {', '.join(available_apis)}")
        else:
            self.logger.warning("âš ï¸ æœªé…ç½®ä»»ä½•AI APIå¯†é’¥")
        
        self.logger.info(f"ğŸ“Š è´¢åŠ¡æŒ‡æ ‡æ•°é‡: {self.analysis_params['financial_indicators_count']}")
        self.logger.info(f"ğŸ“° æœ€å¤§æ–°é—»æ•°é‡: {self.analysis_params['max_news_count']}")
        self.logger.info("=" * 35)

    def _init_baostock(self):
        """åˆå§‹åŒ–BaoStockè¿æ¥"""
        try:
            # ç™»å½•BaoStockç³»ç»Ÿ
            lg = bs.login()
            if lg.error_code != '0':
                self.logger.error(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
                raise Exception(f"BaoStockç™»å½•å¤±è´¥: {lg.error_msg}")
            else:
                self.logger.info("âœ… BaoStockè¿æ¥æˆåŠŸ")
                self.baostock_connected = True
        except Exception as e:
            self.logger.warning(f"âš ï¸ BaoStockè¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨akshareä½œä¸ºå¤‡ç”¨: {e}")
            self.baostock_connected = False

    def _format_stock_code_for_baostock(self, stock_code):
        """æ ¼å¼åŒ–è‚¡ç¥¨ä»£ç ä¸ºBaoStockæ ¼å¼"""
        # BaoStockéœ€è¦å¸¦äº¤æ˜“æ‰€å‰ç¼€çš„æ ¼å¼ï¼Œå¦‚sh.600000, sz.000001
        if stock_code.startswith(('60', '68', '90')):
            return f"sh.{stock_code}"
        elif stock_code.startswith(('00', '30', '20')):
            return f"sz.{stock_code}"
        else:
            # é»˜è®¤è®¤ä¸ºæ˜¯æ·±äº¤æ‰€
            return f"sz.{stock_code}"

    def _query_baostock_data(self, query_func, *args, **kwargs):
        """å®‰å…¨æŸ¥è¯¢BaoStockæ•°æ®çš„é€šç”¨æ–¹æ³•"""
        try:
            if not self.baostock_connected:
                raise Exception("BaoStockæœªè¿æ¥")
            
            result = query_func(*args, **kwargs)
            if result.error_code != '0':
                raise Exception(f"æŸ¥è¯¢å¤±è´¥: {result.error_msg}")
            
            # è½¬æ¢ä¸ºDataFrame
            data_list = []
            while (result.error_code == '0') & result.next():
                data_list.append(result.get_row_data())
            
            if not data_list:
                return pd.DataFrame()
            
            # ä½¿ç”¨resultçš„å­—æ®µåä½œä¸ºåˆ—å
            columns = result.fields if hasattr(result, 'fields') else None
            df = pd.DataFrame(data_list, columns=columns)
            return df
            
        except Exception as e:
            self.logger.warning(f"BaoStockæŸ¥è¯¢å¤±è´¥: {e}")
            return pd.DataFrame()

    def __del__(self):
        """ææ„å‡½æ•°ï¼šä¸å†åœ¨æ­¤å¤„è°ƒç”¨å…¨å±€ bs.logout()ï¼Œé¿å…å½±å“å…¶ä»–å®ä¾‹æˆ–åœ¨ç”¨ä¼šè¯ã€‚"""
        try:
            # ä»…è®°å½•ï¼Œä¸ä¸»åŠ¨ç™»å‡ºï¼ˆBaoStockä¸ºè¿›ç¨‹çº§ä¼šè¯ï¼Œäº¤ç”±æ˜¾å¼ç”Ÿå‘½å‘¨æœŸç®¡ç†æˆ–è¿›ç¨‹ç»“æŸï¼‰
            self.logger.debug("Analyzer å®ä¾‹é”€æ¯")
        except Exception:
            pass

    # =============================
    # é€šç”¨è¾…åŠ©å‡½æ•°ï¼ˆä¸æ”¹å¤–éƒ¨æ¥å£ï¼‰
    # =============================
    def _winsorize(self, series: pd.Series, lower: float = 0.02, upper: float = 0.98) -> pd.Series:
        """åˆ†ä½æ•°ç¼©å°¾ï¼Œæå‡ç¨³å¥æ€§"""
        try:
            if series is None or len(series) == 0:
                return series
            low = series.quantile(lower)
            up = series.quantile(upper)
            return series.clip(lower=low, upper=up)
        except Exception:
            return series

    def _safe_ratio(self, a: float, b: float, default: float = 0.0) -> float:
        """å®‰å…¨é™¤æ³•"""
        try:
            a = float(a)
            b = float(b)
            if b == 0 or np.isnan(b):
                return default
            val = a / b
            if not np.isfinite(val):
                return default
            return float(val)
        except Exception:
            return default

    def _normalize01(self, val: float, vmin: float, vmax: float, clip: bool = True) -> float:
        """å°†æ•°å€¼æ ‡å‡†åŒ–åˆ°[0,1]"""
        try:
            if vmax == vmin:
                return 0.5
            x = (float(val) - vmin) / (vmax - vmin)
            if clip:
                x = max(0.0, min(1.0, x))
            return x
        except Exception:
            return 0.5

    def _time_decay_weights(self, dates: List, half_life_days: float = 30.0) -> List[float]:
        """æ—¶é—´è¡°å‡æƒé‡ï¼Œè¶Šæ–°çš„æ–°é—»æƒé‡è¶Šé«˜ï¼Œè¿”å›å’Œä¸º1çš„æƒé‡åˆ—è¡¨"""
        try:
            now = datetime.now()
            weights = []
            for d in dates:
                try:
                    dt = pd.to_datetime(d, errors='coerce')
                    if pd.isna(dt):
                        w = 0.7  # æ— æ³•è§£ææ—¥æœŸæ—¶ç»™ä¸€ä¸ªä¸­ç­‰æƒé‡
                    else:
                        days = max(0.0, (now - dt).days)
                        w = np.exp(-np.log(2) * days / max(1e-6, half_life_days))
                except Exception:
                    w = 0.7
                weights.append(float(w))
            s = sum(weights)
            return [w / s if s > 0 else 0.0 for w in weights]
        except Exception:
            return [1.0 / max(1, len(dates))] * max(1, len(dates))

    # ===== å¿«ç…§ç¼“å­˜è¾…åŠ© =====
    def _snapshot_cache_path(self) -> str:
        try:
            cache_dir = os.path.dirname(os.path.abspath(self.config_file)) or os.getcwd()
        except Exception:
            cache_dir = os.getcwd()
        return os.path.join(cache_dir, 'spot_snapshot_cache.csv')

    def _snapshot_cache_ttl(self) -> timedelta:
        try:
            net = self.config.get('network', {}) if isinstance(self.config, dict) else {}
            hours = float(net.get('snapshot_cache_ttl_hours', 4))
            return timedelta(hours=max(0.5, min(24.0, hours)))
        except Exception:
            return timedelta(hours=4)

    def _load_spot_snapshot_cache(self) -> pd.DataFrame:
        path = self._snapshot_cache_path()
        try:
            if not os.path.exists(path):
                return pd.DataFrame()
            mtime = datetime.fromtimestamp(os.path.getmtime(path))
            if datetime.now() - mtime > self._snapshot_cache_ttl():
                return pd.DataFrame()
            df = pd.read_csv(path)
            return df if df is not None else pd.DataFrame()
        except Exception:
            return pd.DataFrame()

    def _save_spot_snapshot_cache(self, df: pd.DataFrame):
        try:
            if df is None or df.empty:
                return
            path = self._snapshot_cache_path()
            # ä»…ä¿ç•™å¸¸ç”¨åˆ—ï¼Œå‡å°ä½“ç§¯
            keep_cols = [c for c in df.columns if c in ['ä»£ç ','åç§°','æ¶¨è·Œå¹…','æœ€æ–°ä»·','æ€»å¸‚å€¼','æ€»å¸‚å€¼(äº¿)','å¸‚ç›ˆç‡','å¸‚ç›ˆç‡-åŠ¨æ€','å¸‚ç›ˆç‡TTM','å¸‚å‡€ç‡','è‚¡æ¯ç‡TTM(%)','è‚¡æ¯ç‡TTM','è‚¡æ¯ç‡']]
            df_to_save = df[keep_cols] if keep_cols else df
            df_to_save.to_csv(path, index=False)
            self.logger.info("âœ“ ä¼°å€¼å¿«ç…§å·²å†™å…¥æœ¬åœ°ç¼“å­˜")
        except Exception as e:
            self.logger.debug(f"å†™å…¥å¿«ç…§ç¼“å­˜å¤±è´¥: {e}")

    # ===== è¡Œä¸šæˆä»½ç¼“å­˜è¾…åŠ© =====
    def _industry_cache_dir(self) -> str:
        try:
            base = os.path.dirname(os.path.abspath(self.config_file)) or os.getcwd()
        except Exception:
            base = os.getcwd()
        path = os.path.join(base, 'industry_cons_cache')
        os.makedirs(path, exist_ok=True)
        return path

    def _industry_cons_cache_path(self, industry_name: str) -> str:
        safe = re.sub(r"[^\w\u4e00-\u9fa5]+", "_", str(industry_name or 'unknown'))[:40]
        return os.path.join(self._industry_cache_dir(), f"{safe}.csv")

    def _industry_cons_cache_ttl(self) -> timedelta:
        try:
            net = self.config.get('network', {}) if isinstance(self.config, dict) else {}
            days = float(net.get('industry_cache_ttl_days', 7))
            return timedelta(days=max(1.0, min(30.0, days)))
        except Exception:
            return timedelta(days=7)

    def _load_industry_cons_cache(self, industry_name: str) -> pd.DataFrame:
        path = self._industry_cons_cache_path(industry_name)
        try:
            if not os.path.exists(path):
                return pd.DataFrame()
            mtime = datetime.fromtimestamp(os.path.getmtime(path))
            if datetime.now() - mtime > self._industry_cons_cache_ttl():
                return pd.DataFrame()
            df = pd.read_csv(path)
            return df if df is not None else pd.DataFrame()
        except Exception:
            return pd.DataFrame()

    def _save_industry_cons_cache(self, industry_name: str, df: pd.DataFrame):
        try:
            if df is None or df.empty:
                return
            path = self._industry_cons_cache_path(industry_name)
            # ä»…ä¿ç•™å¸¸è§åˆ—
            keep = [c for c in df.columns if c in ['ä»£ç ','åç§°','è‚¡ç¥¨ä»£ç ','è¯åˆ¸ä»£ç ','è‚¡ç¥¨ç®€ç§°','åç§°_x','åç§°_y']]
            df_to_save = df[keep] if keep else df
            df_to_save.to_csv(path, index=False)
            self.logger.info(f"âœ“ è¡Œä¸šæˆä»½ç¼“å­˜å·²å†™å…¥: {os.path.basename(path)}")
        except Exception as e:
            self.logger.debug(f"å†™å…¥è¡Œä¸šç¼“å­˜å¤±è´¥: {e}")

    def _tokenize_cn(self, text: str) -> List[str]:
        """ä¸­æ–‡ä¼˜å…ˆçš„è½»é‡åˆ†è¯ï¼Œä¼˜å…ˆä½¿ç”¨jiebaï¼Œä¸å¯ç”¨æ—¶å›é€€åˆ°ç®€å•æ‹†åˆ†"""
        try:
            import jieba  # å¯é€‰ä¾èµ–
            tokens = [t.strip() for t in jieba.lcut(text) if t.strip()]
            return tokens
        except Exception:
            # é€€åŒ–ï¼šæŒ‰ä¸­è‹±æ–‡æ•°å­—ç‰‡æ®µä¸æ ‡ç‚¹åˆ†éš”
            if not isinstance(text, str):
                return []
            text = text.strip()
            if not text:
                return []
            # å°†è‹±æ–‡å°å†™åŒ–ï¼Œä¿ç•™ä¸­æ–‡
            text = text.lower()
            # ä»¥éå­—æ¯æ•°å­—å’Œéä¸­æ–‡å­—ç¬¦åˆ‡åˆ†
            parts = re.split(r"[^0-9a-zA-Z\u4e00-\u9fa5]+", text)
            return [p for p in parts if p]

    def _sentiment_from_tokens(self, tokens: List[str], positive_words: set, negative_words: set) -> float:
        """åŸºäºå¦å®šè¯å’Œç¨‹åº¦å‰¯è¯çš„ç®€æ˜“æƒ…ç»ªæ‰“åˆ†ï¼Œè¿”å›[-1,1]"""
        if not tokens:
            return 0.0

        negations = {"ä¸", "æœª", "æ— ", "é", "å¦", "æ²¡", "æ²’æœ‰", "å¹¶é", "ä¸¦é"}
        degree_map = {
            # ç¨‹åº¦å‰¯è¯ æ”¾å¤§å› å­
            "æå…¶": 2.0, "éå¸¸": 1.8, "ç‰¹åˆ«": 1.6, "æ˜¾è‘—": 1.5, "æ˜æ˜¾": 1.4,
            "è¾ƒä¸º": 1.2, "æ¯”è¾ƒ": 1.2, "ä¸€å®š": 1.1, "ç•¥": 0.9, "æœ‰ç‚¹": 0.8
        }

        window = 3  # è¿‘3è¯çª—å£å†…çš„å¦å®šå’Œç¨‹åº¦å½±å“
        score = 0.0
        hits = 0

        for i, tok in enumerate(tokens):
            base = 0.0
            if tok in positive_words:
                base = 1.0
            elif tok in negative_words:
                base = -1.0
            else:
                continue

            # å›çœ‹çª—å£
            neg_flip = 1
            degree = 1.0
            for j in range(max(0, i - window), i):
                t = tokens[j]
                if t in negations:
                    neg_flip *= -1
                if t in degree_map:
                    degree *= degree_map[t]

            score += base * neg_flip * degree
            hits += 1

        if hits == 0:
            return 0.0
        # å½’ä¸€åŒ–åˆ°[-1,1]ï¼Œå¯¹æç«¯ç¨‹åº¦åštanhæ”¶æ•›
        return float(np.tanh(score / max(1.0, hits)))

    def get_stock_data(self, stock_code, period='1y'):
        """è·å–è‚¡ç¥¨ä»·æ ¼æ•°æ® - ä¼˜å…ˆä½¿ç”¨BaoStockï¼Œå¤±è´¥å›é€€åˆ°akshareï¼›å¸¦ç¼“å­˜"""
        # ç¼“å­˜å‘½ä¸­
        if stock_code in self.price_cache:
            cache_time, data = self.price_cache[stock_code]
            if datetime.now() - cache_time < self.cache_duration:
                self.logger.info(f"ä½¿ç”¨ç¼“å­˜çš„ä»·æ ¼æ•°æ®: {stock_code}")
                return data

        # BaoStock ä¼˜å…ˆ
        if self.baostock_connected:
            try:
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=self.analysis_params.get('technical_period_days', 365))).strftime('%Y-%m-%d')
                formatted_code = self._format_stock_code_for_baostock(stock_code)

                self.logger.info(f"æ­£åœ¨ä»BaoStockè·å– {stock_code} çš„å†å²æ•°æ®...")
                rs = bs.query_history_k_data_plus(
                    code=formatted_code,
                    fields="date,code,open,high,low,close,preclose,volume,amount,turn,tradestatus,pctChg,isST",
                    start_date=start_date,
                    end_date=end_date,
                    frequency="d",
                    adjustflag="2"
                )
                if rs.error_code != '0':
                    raise Exception(rs.error_msg)

                data_list = []
                while (rs.error_code == '0') & rs.next():
                    data_list.append(rs.get_row_data())
                if not data_list:
                    raise ValueError("BaoStockæœªè¿”å›æ•°æ®")

                stock_data = pd.DataFrame(data_list, columns=rs.fields)
                stock_data = self._preprocess_baostock_data(stock_data, stock_code)

                # ç¼“å­˜
                self.price_cache[stock_code] = (datetime.now(), stock_data)
                self.logger.info(f"âœ“ æˆåŠŸä»BaoStockè·å– {stock_code} çš„ä»·æ ¼æ•°æ®ï¼Œå…± {len(stock_data)} æ¡è®°å½•")
                return stock_data
            except Exception as e:
                self.logger.warning(f"BaoStockä»·æ ¼æ•°æ®å¤±è´¥ï¼Œå°†å›é€€akshare: {e}")

        # å›é€€åˆ° akshare
        data = self._get_stock_data_from_akshare(stock_code, period)
        return data

    def _preprocess_baostock_data(self, stock_data, stock_code):
        """é¢„å¤„ç†BaoStockæ•°æ®"""
        try:
            # è¿‡æ»¤æ‰äº¤æ˜“çŠ¶æ€ä¸º0çš„æ•°æ®ï¼ˆåœç‰Œç­‰ï¼‰
            stock_data = stock_data[stock_data['tradestatus'] == '1'].copy()
            
            # è½¬æ¢æ•°æ®ç±»å‹
            numeric_columns = ['open', 'high', 'low', 'close', 'preclose', 'volume', 'amount', 'turn', 'pctChg']
            for col in numeric_columns:
                if col in stock_data.columns:
                    stock_data[col] = pd.to_numeric(stock_data[col], errors='coerce')
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            stock_data['date'] = pd.to_datetime(stock_data['date'])
            stock_data = stock_data.sort_values('date').reset_index(drop=True)
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ‰€éœ€çš„é¢å¤–å­—æ®µ
            stock_data['volume_ratio'] = 1.0  # BaoStockæš‚æ—¶æ— æ³•ç›´æ¥è·å–ï¼Œè®¾ä¸ºé»˜è®¤å€¼
            stock_data['change_pct'] = stock_data['pctChg']  # é‡å‘½åä»¥ä¿æŒä¸€è‡´æ€§
            stock_data['change_amount'] = stock_data['close'] - stock_data['preclose']
            stock_data['turnover'] = stock_data['amount']  # æˆäº¤é¢
            stock_data['turnover_rate'] = stock_data['turn']  # æ¢æ‰‹ç‡
            
            # è®¡ç®—æŒ¯å¹…
            stock_data['amplitude'] = ((stock_data['high'] - stock_data['low']) / stock_data['preclose'] * 100).round(2)
            
            # æ•°æ®éªŒè¯
            if len(stock_data) > 0:
                latest_close = stock_data['close'].iloc[-1]
                latest_open = stock_data['open'].iloc[-1]
                self.logger.info(f"âœ“ æ•°æ®éªŒè¯ - æœ€æ–°æ”¶ç›˜ä»·: {latest_close}, æœ€æ–°å¼€ç›˜ä»·: {latest_open}")
            
            return stock_data
            
        except Exception as e:
            self.logger.error(f"BaoStockæ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            raise

    def _get_stock_data_from_akshare(self, stock_code, period='1y'):
        """ä½¿ç”¨akshareè·å–è‚¡ç¥¨ä»·æ ¼æ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            import akshare as ak
            
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=self.analysis_params['technical_period_days'])).strftime('%Y%m%d')
            
            self.logger.info(f"æ­£åœ¨ä»akshareè·å– {stock_code} çš„å†å²æ•°æ®...")
            
            stock_data = ak.stock_zh_a_hist(
                symbol=stock_code,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"
            )
            
            if stock_data.empty:
                raise ValueError(f"akshareæœªè¿”å›æ•°æ®")
            
            # æ ‡å‡†åŒ–akshareåˆ—åæ˜ å°„
            try:
                # akshareè¿”å›çš„åˆ—åé€šå¸¸æ˜¯ä¸­æ–‡ï¼Œéœ€è¦æ˜ å°„ä¸ºè‹±æ–‡
                column_mapping = {
                    'æ—¥æœŸ': 'date',
                    'è‚¡ç¥¨ä»£ç ': 'code',
                    'å¼€ç›˜': 'open',
                    'æ”¶ç›˜': 'close', 
                    'æœ€é«˜': 'high',
                    'æœ€ä½': 'low',
                    'æˆäº¤é‡': 'volume',
                    'æˆäº¤é¢': 'amount',
                    'æŒ¯å¹…': 'amplitude',
                    'æ¶¨è·Œå¹…': 'change_pct',
                    'æ¶¨è·Œé¢': 'change_amount',
                    'æ¢æ‰‹ç‡': 'turnover_rate'
                }
                
                # åº”ç”¨åˆ—åæ˜ å°„
                stock_data = stock_data.rename(columns=column_mapping)
                self.logger.info(f"akshareåˆ—åæ˜ å°„å®Œæˆ: {list(stock_data.columns)}")
                
                # æˆäº¤é‡å•ä½è½¬æ¢ï¼šakshareæ˜¯æ‰‹(éœ€è¦Ã—100è½¬ä¸ºè‚¡æ•°)
                if 'volume' in stock_data.columns:
                    stock_data['volume'] = stock_data['volume'] * 100
                    self.logger.info("akshareæˆäº¤é‡å•ä½å·²è½¬æ¢ä¸ºè‚¡æ•°")
                
            except Exception as e:
                self.logger.warning(f"åˆ—åæ ‡å‡†åŒ–å¤±è´¥: {e}ï¼Œä¿æŒåŸåˆ—å")
            
            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨å¹¶ä¸”æ˜ å°„æ­£ç¡®
            required_columns = ['close', 'open', 'high', 'low', 'volume']
            missing_columns = []
            
            for col in required_columns:
                if col not in stock_data.columns:
                    # å°è¯•æ‰¾åˆ°ç›¸ä¼¼çš„åˆ—å
                    similar_cols = [c for c in stock_data.columns if col in c.lower() or c.lower() in col]
                    if similar_cols:
                        stock_data[col] = stock_data[similar_cols[0]]
                        self.logger.info(f"âœ“ æ˜ å°„åˆ— {similar_cols[0]} -> {col}")
                    else:
                        missing_columns.append(col)
            
            if missing_columns:
                self.logger.warning(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
                # å¦‚æœç¼ºå°‘å¿…è¦åˆ—ï¼Œå°è¯•ä½¿ç”¨ä½ç½®ç´¢å¼•æ˜ å°„
                if len(stock_data.columns) >= 6:  # è‡³å°‘æœ‰6åˆ—æ‰èƒ½è¿›è¡Œä½ç½®æ˜ å°„
                    cols = list(stock_data.columns)
                    # é€šå¸¸akshareçš„åˆ—é¡ºåºæ˜¯: æ—¥æœŸ, [ä»£ç ], å¼€ç›˜, æ”¶ç›˜, æœ€é«˜, æœ€ä½, æˆäº¤é‡, ...
                    if 'code' in cols[1].lower() or len(cols[1]) == 6:  # ç¬¬äºŒåˆ—æ˜¯è‚¡ç¥¨ä»£ç 
                        position_mapping = {
                            cols[0]: 'date',
                            cols[1]: 'code', 
                            cols[2]: 'open',
                            cols[3]: 'close',  # ç¡®ä¿ç¬¬4åˆ—æ˜¯æ”¶ç›˜ä»·
                            cols[4]: 'high',
                            cols[5]: 'low'
                        }
                        if len(cols) > 6:
                            position_mapping[cols[6]] = 'volume'
                    else:  # æ²¡æœ‰ä»£ç åˆ—
                        position_mapping = {
                            cols[0]: 'date',
                            cols[1]: 'open', 
                            cols[2]: 'close',  # ç¡®ä¿ç¬¬3åˆ—æ˜¯æ”¶ç›˜ä»·
                            cols[3]: 'high',
                            cols[4]: 'low'
                        }
                        if len(cols) > 5:
                            position_mapping[cols[5]] = 'volume'
                    
                    # åº”ç”¨ä½ç½®æ˜ å°„
                    stock_data = stock_data.rename(columns=position_mapping)
                    self.logger.info(f"âœ“ åº”ç”¨ä½ç½®æ˜ å°„: {position_mapping}")
            
            # å¤„ç†æ—¥æœŸåˆ—
            try:
                if 'date' in stock_data.columns:
                    stock_data['date'] = pd.to_datetime(stock_data['date'])
                    stock_data = stock_data.set_index('date')
                else:
                    stock_data.index = pd.to_datetime(stock_data.index)
            except Exception as e:
                self.logger.warning(f"æ—¥æœŸå¤„ç†å¤±è´¥: {e}")
            
            # ç¡®ä¿æ•°å€¼åˆ—ä¸ºæ•°å€¼ç±»å‹
            numeric_columns = ['open', 'close', 'high', 'low', 'volume']
            for col in numeric_columns:
                if col in stock_data.columns:
                    try:
                        stock_data[col] = pd.to_numeric(stock_data[col], errors='coerce')
                    except:
                        pass
            
            # éªŒè¯æ•°æ®è´¨é‡
            if 'close' in stock_data.columns:
                latest_close = stock_data['close'].iloc[-1]
                latest_open = stock_data['open'].iloc[-1] if 'open' in stock_data.columns else 0
                self.logger.info(f"âœ“ æ•°æ®éªŒè¯ - æœ€æ–°æ”¶ç›˜ä»·: {latest_close}, æœ€æ–°å¼€ç›˜ä»·: {latest_open}")
                
                # æ£€æŸ¥æ”¶ç›˜ä»·æ˜¯å¦åˆç†
                if pd.isna(latest_close) or latest_close <= 0:
                    self.logger.error(f"âŒ æ”¶ç›˜ä»·æ•°æ®å¼‚å¸¸: {latest_close}")
                    raise ValueError(f"è‚¡ç¥¨ {stock_code} çš„æ”¶ç›˜ä»·æ•°æ®å¼‚å¸¸")
            
            # ç¼“å­˜æ•°æ®
            self.price_cache[stock_code] = (datetime.now(), stock_data)
            
            self.logger.info(f"âœ“ æˆåŠŸè·å– {stock_code} çš„ä»·æ ¼æ•°æ®ï¼Œå…± {len(stock_data)} æ¡è®°å½•")
            self.logger.info(f"âœ“ æ•°æ®åˆ—: {list(stock_data.columns)}")
            
            return stock_data
            
        except Exception as e:
            self.logger.error(f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def get_comprehensive_fundamental_data(self, stock_code):
        """è·å–25é¡¹ç»¼åˆè´¢åŠ¡æŒ‡æ ‡æ•°æ® - ä¼˜å…ˆä½¿ç”¨BaoStock"""
        if stock_code in self.fundamental_cache:
            cache_time, data = self.fundamental_cache[stock_code]
            if datetime.now() - cache_time < self.fundamental_cache_duration:
                self.logger.info(f"ä½¿ç”¨ç¼“å­˜çš„åŸºæœ¬é¢æ•°æ®: {stock_code}")
                return data
        
        # é¦–å…ˆå°è¯•ä½¿ç”¨BaoStockè·å–éƒ¨åˆ†æ•°æ®
        fundamental_data = {}
        
        # BaoStockä¸»è¦ç”¨äºè·å–åŸºæœ¬é¢æ¦‚è§ˆ
        if self.baostock_connected:
            try:
                fundamental_data.update(self._get_fundamental_data_from_baostock(stock_code))
            except Exception as e:
                self.logger.warning(f"BaoStockè·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
        
        # ä½¿ç”¨akshareè¡¥å……è¯¦ç»†çš„è´¢åŠ¡æŒ‡æ ‡ï¼ˆBaoStockçš„è´¢åŠ¡æ•°æ®ç›¸å¯¹æœ‰é™ï¼‰
        try:
            akshare_data = self._get_fundamental_data_from_akshare(stock_code)
            # åˆå¹¶æ•°æ®ï¼Œakshareçš„æ•°æ®ä¼˜å…ˆçº§æ›´é«˜ï¼ˆæ›´è¯¦ç»†ï¼‰
            for key, value in akshare_data.items():
                if key not in fundamental_data or not fundamental_data[key]:
                    fundamental_data[key] = value
                elif isinstance(value, dict) and isinstance(fundamental_data.get(key), dict):
                    fundamental_data[key].update(value)
        except Exception as e:
            self.logger.warning(f"akshareè·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
        
        # ç¼“å­˜æ•°æ®
        self.fundamental_cache[stock_code] = (datetime.now(), fundamental_data)
        self.logger.info(f"âœ“ {stock_code} ç»¼åˆåŸºæœ¬é¢æ•°æ®è·å–å®Œæˆå¹¶å·²ç¼“å­˜")
        
        return fundamental_data

    def _get_fundamental_data_from_baostock(self, stock_code):
        """ä½¿ç”¨BaoStockè·å–åŸºæœ¬é¢æ•°æ®"""
        try:
            fundamental_data = {}
            formatted_code = self._format_stock_code_for_baostock(stock_code)
            
            self.logger.info(f"æ­£åœ¨ä»BaoStockè·å– {stock_code} çš„åŸºæœ¬é¢æ•°æ®...")
            
            # 1. è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
            try:
                rs = bs.query_stock_basic(code=formatted_code)
                if rs.error_code == '0':
                    basic_data = []
                    while (rs.error_code == '0') & rs.next():
                        basic_data.append(rs.get_row_data())
                    
                    if basic_data:
                        basic_df = pd.DataFrame(basic_data, columns=rs.fields)
                        if not basic_df.empty:
                            basic_info = basic_df.iloc[0].to_dict()
                            fundamental_data['basic_info'] = basic_info
                            self.logger.info("âœ“ BaoStockåŸºæœ¬ä¿¡æ¯è·å–æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"BaoStockè·å–åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
                fundamental_data['basic_info'] = {}
            
            # 2. è·å–æœ€æ–°çš„å­£åº¦è´¢åŠ¡æ•°æ®
            try:
                # è·å–æœ€è¿‘çš„è´¢åŠ¡æŠ¥å‘ŠæœŸ
                end_date = datetime.now().strftime('%Y-%m-%d')
                start_date = (datetime.now() - timedelta(days=500)).strftime('%Y-%m-%d')
                
                # è·å–ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡
                rs_profit = bs.query_profit_data(
                    code=formatted_code,
                    year=datetime.now().year,
                    quarter=((datetime.now().month-1) // 3) + 1
                )
                
                if rs_profit.error_code == '0':
                    profit_data = []
                    while (rs_profit.error_code == '0') & rs_profit.next():
                        profit_data.append(rs_profit.get_row_data())
                    
                    if profit_data:
                        profit_df = pd.DataFrame(profit_data, columns=rs_profit.fields)
                        if not profit_df.empty:
                            latest_profit = profit_df.iloc[-1].to_dict()
                            fundamental_data['profit_data'] = latest_profit
                            self.logger.info("âœ“ BaoStockç›ˆåˆ©èƒ½åŠ›æ•°æ®è·å–æˆåŠŸ")
                
                # è·å–æˆé•¿èƒ½åŠ›æŒ‡æ ‡
                rs_growth = bs.query_growth_data(
                    code=formatted_code,
                    year=datetime.now().year,
                    quarter=((datetime.now().month-1) // 3) + 1
                )
                
                if rs_growth.error_code == '0':
                    growth_data = []
                    while (rs_growth.error_code == '0') & rs_growth.next():
                        growth_data.append(rs_growth.get_row_data())
                    
                    if growth_data:
                        growth_df = pd.DataFrame(growth_data, columns=rs_growth.fields)
                        if not growth_df.empty:
                            latest_growth = growth_df.iloc[-1].to_dict()
                            fundamental_data['growth_data'] = latest_growth
                            self.logger.info("âœ“ BaoStockæˆé•¿èƒ½åŠ›æ•°æ®è·å–æˆåŠŸ")
                
                # è·å–æœé‚¦æŒ‡æ ‡
                rs_dupont = bs.query_dupont_data(
                    code=formatted_code,
                    year=datetime.now().year,
                    quarter=((datetime.now().month-1) // 3) + 1
                )
                
                if rs_dupont.error_code == '0':
                    dupont_data = []
                    while (rs_dupont.error_code == '0') & rs_dupont.next():
                        dupont_data.append(rs_dupont.get_row_data())
                    
                    if dupont_data:
                        dupont_df = pd.DataFrame(dupont_data, columns=rs_dupont.fields)
                        if not dupont_df.empty:
                            latest_dupont = dupont_df.iloc[-1].to_dict()
                            fundamental_data['dupont_data'] = latest_dupont
                            self.logger.info("âœ“ BaoStockæœé‚¦æŒ‡æ ‡è·å–æˆåŠŸ")
                            
            except Exception as e:
                self.logger.warning(f"BaoStockè·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
            
            return fundamental_data
            
        except Exception as e:
            self.logger.error(f"BaoStockè·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
            return {}

    def _get_fundamental_data_from_akshare(self, stock_code):
        """ä½¿ç”¨akshareè·å–åŸºæœ¬é¢æ•°æ®ï¼ˆè¯¦ç»†ç‰ˆï¼‰"""
        try:
            import akshare as ak
            
            fundamental_data = {}
            self.logger.info(f"å¼€å§‹ä»akshareè·å– {stock_code} çš„25é¡¹ç»¼åˆè´¢åŠ¡æŒ‡æ ‡...")
            
            # 1. åŸºæœ¬ä¿¡æ¯
            try:
                self.logger.info("æ­£åœ¨è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
                stock_info = ak.stock_individual_info_em(symbol=stock_code)
                if stock_info is not None and not stock_info.empty:
                    info_dict = dict(zip(stock_info['item'], stock_info['value']))
                    fundamental_data['basic_info'] = info_dict
                    self.logger.info("âœ“ è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯è·å–æˆåŠŸ")
                else:
                    fundamental_data['basic_info'] = {}
            except Exception as e:
                self.logger.warning(f"è·å–åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
                fundamental_data['basic_info'] = {}
            
            # 2. è¯¦ç»†è´¢åŠ¡æŒ‡æ ‡ - 25é¡¹æ ¸å¿ƒæŒ‡æ ‡
            try:
                self.logger.info("æ­£åœ¨è·å–25é¡¹è¯¦ç»†è´¢åŠ¡æŒ‡æ ‡...")
                financial_indicators = {}
                
                # è·å–ä¸»è¦è´¢åŠ¡æ•°æ®
                try:
                    # åˆ©æ¶¦è¡¨æ•°æ®
                    income_statement = ak.stock_financial_abstract_ths(symbol=stock_code, indicator="æŒ‰æŠ¥å‘ŠæœŸ")
                    if income_statement is not None and not income_statement.empty:
                        if self._is_data_stale(income_statement, ['æŠ¥å‘ŠæœŸ','å‘å¸ƒæ—¥æœŸ','date'], max_days=540, what='åˆ©æ¶¦è¡¨'):
                            income_statement = pd.DataFrame()
                    if income_statement is not None and not income_statement.empty:
                        latest_income = income_statement.iloc[0].to_dict()
                        financial_indicators.update(latest_income)
                except Exception as e:
                    self.logger.warning(f"è·å–åˆ©æ¶¦è¡¨æ•°æ®å¤±è´¥: {e}")
                
                try:
                    # è´¢åŠ¡åˆ†ææŒ‡æ ‡
                    balance_sheet = ak.stock_financial_analysis_indicator(symbol=stock_code)
                    if balance_sheet is not None and not balance_sheet.empty:
                        if self._is_data_stale(balance_sheet, ['æ—¥æœŸ','æŠ¥å‘ŠæœŸ','date'], max_days=540, what='è´¢åŠ¡åˆ†ææŒ‡æ ‡'):
                            balance_sheet = pd.DataFrame()
                    if balance_sheet is not None and not balance_sheet.empty:
                        latest_balance = balance_sheet.iloc[-1].to_dict()
                        financial_indicators.update(latest_balance)
                except Exception as e:
                    self.logger.warning(f"è·å–è´¢åŠ¡åˆ†ææŒ‡æ ‡å¤±è´¥: {e}")
                
                try:
                    # ç°é‡‘æµé‡è¡¨ - ä¿®å¤Noneæ£€æŸ¥
                    cash_flow = ak.stock_cash_flow_sheet_by_report_em(symbol=stock_code)
                    if cash_flow is not None and not cash_flow.empty:
                        if self._is_data_stale(cash_flow, ['æŠ¥å‘ŠæœŸ','å…¬å‘Šæ—¥æœŸ','date'], max_days=540, what='ç°é‡‘æµé‡è¡¨'):
                            cash_flow = pd.DataFrame()
                    if cash_flow is not None and not cash_flow.empty:
                        latest_cash = cash_flow.iloc[-1].to_dict()
                        financial_indicators.update(latest_cash)
                    else:
                        self.logger.info("ç°é‡‘æµé‡è¡¨æ•°æ®ä¸ºç©º")
                except Exception as e:
                    self.logger.warning(f"è·å–ç°é‡‘æµé‡è¡¨å¤±è´¥: {e}")
                
                # è®¡ç®—25é¡¹æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡
                core_indicators = self._calculate_core_financial_indicators(financial_indicators)
                fundamental_data['financial_indicators'] = core_indicators
                
                self.logger.info(f"âœ“ æˆåŠŸè®¡ç®— {len(core_indicators)} é¡¹æœ‰æ•ˆè´¢åŠ¡æŒ‡æ ‡")
                self.logger.info(f"âœ“ è·å–åˆ° {len(core_indicators)} é¡¹è´¢åŠ¡æŒ‡æ ‡")
                
            except Exception as e:
                self.logger.warning(f"è·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
                fundamental_data['financial_indicators'] = {}
            
            # 3. ä¼°å€¼æŒ‡æ ‡ - ä½¿ç”¨æ›´ç¨³å®šçš„API
            try:
                self.logger.info("æ­£åœ¨è·å–ä¼°å€¼æŒ‡æ ‡...")
                try:
                    spot = ak.stock_zh_a_spot_em()
                    if spot is not None and not spot.empty:
                        self._save_spot_snapshot_cache(spot)
                except Exception as _e:
                    self.logger.info("â„¹ï¸ åœ¨çº¿ä¼°å€¼å¿«ç…§è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜")
                    spot = self._load_spot_snapshot_cache()
                if spot is not None and not spot.empty:
                    try:
                        row = spot[spot['ä»£ç '].astype(str) == str(stock_code)]
                        if not row.empty:
                            r = row.iloc[0]
                            def pick(*names):
                                for n in names:
                                    if n in row.columns:
                                        return r.get(n)
                                return None
                            pe = pick('å¸‚ç›ˆç‡-åŠ¨æ€','å¸‚ç›ˆç‡TTM','å¸‚ç›ˆç‡')
                            pb = pick('å¸‚å‡€ç‡')
                            mktcap = pick('æ€»å¸‚å€¼','æ€»å¸‚å€¼(äº¿)')
                            divy = pick('è‚¡æ¯ç‡TTM(%)','è‚¡æ¯ç‡TTM','è‚¡æ¯ç‡')
                            # è§„èŒƒåŒ–
                            def to_float(x):
                                try:
                                    if isinstance(x, str) and x.endswith('%'):
                                        return float(x.strip('%'))
                                    return float(x)
                                except Exception:
                                    return None
                            valuation = {
                                'å¸‚ç›ˆç‡': to_float(pe),
                                'å¸‚å‡€ç‡': to_float(pb),
                                'æ€»å¸‚å€¼': to_float(mktcap),
                                'è‚¡æ¯æ”¶ç›Šç‡': to_float(divy)
                            }
                            # å»é™¤None
                            valuation = {k: v for k, v in valuation.items() if v is not None}
                            fundamental_data['valuation'] = valuation
                            self.logger.info("âœ“ ä¼°å€¼æŒ‡æ ‡è·å–æˆåŠŸ(å¿«ç…§)")
                        else:
                            fundamental_data['valuation'] = {}
                            self.logger.info("â„¹ï¸ æœªåœ¨å¿«ç…§ä¸­æ‰¾åˆ°è¯¥ä»£ç ")
                    except Exception as e2:
                        self.logger.warning(f"å¤„ç†ä¼°å€¼å¿«ç…§å¤±è´¥: {e2}")
                        fundamental_data['valuation'] = {}
                else:
                    fundamental_data['valuation'] = {}
                    self.logger.info("â„¹ï¸ ä¼°å€¼å¿«ç…§ä¸å¯ç”¨")
            except Exception as e:
                self.logger.warning(f"è·å–ä¼°å€¼æŒ‡æ ‡å¤±è´¥: {e}")
                fundamental_data['valuation'] = {}
            
            # 4. ä¸šç»©é¢„å‘Šå’Œä¸šç»©å¿«æŠ¥
            try:
                self.logger.info("æ­£åœ¨è·å–ä¸šç»©é¢„å‘Š...")
                perf_items = []
                def _filter_by_code(df):
                    if df is None or df.empty:
                        return df
                    cols = [c for c in df.columns if str(c) in ('ä»£ç ','è‚¡ç¥¨ä»£ç ','è¯åˆ¸ä»£ç ')] or [c for c in df.columns if 'ç ' in str(c)] or [df.columns[0]]
                    col = cols[0]
                    s = df[col].astype(str)
                    mask = s.str.endswith(str(stock_code)) | s.str.contains(str(stock_code), na=False)
                    return df[mask]
                # å…ˆå°è¯•ä¸šç»©é¢„å‘Š
                try:
                    yjyg = ak.stock_yjyg_em()
                    if yjyg is not None and not yjyg.empty:
                        df = _filter_by_code(yjyg)
                        # æŒ‰å…¬å‘Šæ—¥æœŸå€’åº
                        date_col = 'å…¬å‘Šæ—¥æœŸ' if 'å…¬å‘Šæ—¥æœŸ' in df.columns else ('æœ€æ–°å…¬å‘Šæ—¥æœŸ' if 'æœ€æ–°å…¬å‘Šæ—¥æœŸ' in df.columns else None)
                        if date_col:
                            df = df.sort_values(by=date_col, ascending=False)
                        for _, r in df.head(10).iterrows():
                            item = {
                                'date': str(r.get('å…¬å‘Šæ—¥æœŸ') or r.get('æœ€æ–°å…¬å‘Šæ—¥æœŸ') or r.get('å…¬å‘Šæ—¶é—´') or ''),
                                'type': 'ä¸šç»©é¢„å‘Š',
                                'range': str(r.get('é¢„å‘Šç±»å‹') or r.get('å˜åŠ¨å¹…åº¦') or r.get('é¢„å‘Šå‡€åˆ©æ¶¦å˜åŠ¨å¹…åº¦') or ''),
                                'reason': str(r.get('å˜åŠ¨åŸå› ') or ''),
                                'profit_low': str(r.get('é¢„æµ‹å‡€åˆ©æ¶¦ä¸‹é™') or r.get('é¢„å‘Šå‡€åˆ©æ¶¦ä¸‹é™') or ''),
                                'profit_high': str(r.get('é¢„æµ‹å‡€åˆ©æ¶¦ä¸Šé™') or r.get('é¢„å‘Šå‡€åˆ©æ¶¦ä¸Šé™') or ''),
                                'eps': str(r.get('æ¯è‚¡æ”¶ç›Š') or r.get('åŸºæœ¬æ¯è‚¡æ”¶ç›Š') or ''),
                            }
                            perf_items.append(item)
                except Exception as e:
                    self.logger.info(f"ä¸šç»©é¢„å‘Šæ¥å£ä¸å¯ç”¨: {e}")
                # å†å°è¯•ä¸šç»©å¿«æŠ¥
                if not perf_items:
                    try:
                        yjkb = ak.stock_yjkb_em()
                        if yjkb is not None and not yjkb.empty:
                            df = _filter_by_code(yjkb)
                            date_col = 'å…¬å‘Šæ—¥æœŸ' if 'å…¬å‘Šæ—¥æœŸ' in df.columns else ('æœ€æ–°å…¬å‘Šæ—¥æœŸ' if 'æœ€æ–°å…¬å‘Šæ—¥æœŸ' in df.columns else None)
                            if date_col:
                                df = df.sort_values(by=date_col, ascending=False)
                            for _, r in df.head(10).iterrows():
                                item = {
                                    'date': str(r.get('å…¬å‘Šæ—¥æœŸ') or r.get('æœ€æ–°å…¬å‘Šæ—¥æœŸ') or r.get('å…¬å‘Šæ—¶é—´') or ''),
                                    'type': 'ä¸šç»©å¿«æŠ¥',
                                    'revenue': str(r.get('è¥ä¸šæ€»æ”¶å…¥') or r.get('è¥ä¸šæ”¶å…¥') or ''),
                                    'net_profit': str(r.get('å‡€åˆ©æ¶¦') or r.get('å½’æ¯å‡€åˆ©æ¶¦') or ''),
                                    'eps': str(r.get('æ¯è‚¡æ”¶ç›Š') or r.get('åŸºæœ¬æ¯è‚¡æ”¶ç›Š') or ''),
                                    'yoy_revenue': str(r.get('è¥ä¸šæ€»æ”¶å…¥åŒæ¯”å¢é•¿') or r.get('è¥ä¸šæ”¶å…¥åŒæ¯”å¢é•¿') or ''),
                                    'yoy_netprofit': str(r.get('å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿') or r.get('å½’æ¯å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿') or ''),
                                }
                                perf_items.append(item)
                    except Exception as e:
                        self.logger.info(f"ä¸šç»©å¿«æŠ¥æ¥å£ä¸å¯ç”¨: {e}")
                fundamental_data['performance_forecast'] = perf_items[:10]
                if perf_items:
                    self.logger.info("âœ“ ä¸šç»©é¢„å‘Š/å¿«æŠ¥è·å–æˆåŠŸ")
                else:
                    self.logger.info("â„¹ï¸ ä¸šç»©é¢„å‘Šæš‚æ—¶ä¸å¯ç”¨")
            except Exception as e:
                self.logger.warning(f"è·å–ä¸šç»©é¢„å‘Šå¤±è´¥: {e}")
                fundamental_data['performance_forecast'] = []
            
            # 5. åˆ†çº¢é…è‚¡ä¿¡æ¯ - ä¼˜å…ˆä½¿ç”¨BaoStock
            try:
                self.logger.info("æ­£åœ¨è·å–åˆ†çº¢é…è‚¡ä¿¡æ¯...")
                dividend_info_list = []
                
                # é¦–å…ˆå°è¯•BaoStockåˆ†çº¢æ•°æ®ï¼ˆæ¨èï¼‰
                if self.baostock_connected:
                    try:
                        formatted_code = self._format_stock_code_for_baostock(stock_code)
                        
                        # è·å–æœ€è¿‘3å¹´çš„åˆ†çº¢æ•°æ®
                        current_year = datetime.now().year
                        for year in [current_year, current_year-1, current_year-2]:
                            rs_dividend = bs.query_dividend_data(
                                code=formatted_code,
                                year=year,
                                yearType="report"
                            )
                            
                            if rs_dividend.error_code == '0':
                                dividend_data = []
                                while (rs_dividend.error_code == '0') & rs_dividend.next():
                                    dividend_data.append(rs_dividend.get_row_data())
                                
                                if dividend_data:
                                    df_dividend = pd.DataFrame(dividend_data, columns=rs_dividend.fields)
                                    # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œä½¿ç”¨æ­£ç¡®çš„å­—æ®µå
                                    for _, row in df_dividend.iterrows():
                                        dividend_item = {
                                            'year': str(year),  # ä½¿ç”¨æŸ¥è¯¢çš„å¹´ä»½
                                            'dividend_per_share': str(row.get('dividCashPsBeforeTax', '0')),
                                            'dividend_after_tax': str(row.get('dividCashPsAfterTax', '0')),
                                            'dividend_type': 'ç°é‡‘åˆ†çº¢',
                                            'announcement_date': str(row.get('dividPlanAnnounceDate', '')),
                                            'record_date': str(row.get('dividRegistDate', '')),
                                            'ex_dividend_date': str(row.get('dividOperateDate', '')),
                                            'pay_date': str(row.get('dividPayDate', '')),
                                            'dividend_description': str(row.get('dividCashStock', '')),
                                            'source': 'BaoStock'
                                        }
                                        dividend_info_list.append(dividend_item)
                        
                        if dividend_info_list:
                            dividend_info_list = self._normalize_dividend_records(dividend_info_list)
                            dividend_info_list = sorted(dividend_info_list, key=lambda x: str(x.get('year','')), reverse=True)
                            fundamental_data['dividend_info'] = dividend_info_list
                            self.logger.info(f"âœ“ BaoStockè·å–åˆ†çº¢é…è‚¡ä¿¡æ¯æˆåŠŸï¼Œå…±{len(dividend_info_list)}æ¡")
                        else:
                            self.logger.info("âœ“ BaoStockæŸ¥è¯¢å®Œæˆï¼Œè¯¥è‚¡ç¥¨æš‚æ— åˆ†çº¢è®°å½•")
                            fundamental_data['dividend_info'] = []
                    
                    except Exception as e:
                        self.logger.warning(f"BaoStockè·å–åˆ†çº¢æ•°æ®å¤±è´¥: {e}")
                        dividend_info_list = []
                
                # å¦‚æœBaoStockæ²¡æœ‰è·å–åˆ°æ•°æ®ï¼Œå°è¯•akshareä½œä¸ºå¤‡ç”¨
                if not dividend_info_list:
                    try:
                        # å°è¯•akshareçš„åˆ†çº¢æ•°æ®API
                        dividend_apis = [
                            ('stock_dividend_cninfo', lambda: ak.stock_dividend_cninfo(symbol=stock_code)),
                            ('stock_history_dividend_detail', lambda: ak.stock_history_dividend_detail(symbol=stock_code)),
                        ]
                        
                        for api_name, api_func in dividend_apis:
                            try:
                                dividend_data = api_func()
                                if dividend_data is not None and not dividend_data.empty:
                                    # è½¬æ¢akshareæ•°æ®æ ¼å¼
                                    for _, row in dividend_data.head(10).iterrows():
                                        dividend_item = {
                                            'year': str(row.iloc[0] if len(row) > 0 else ''),
                                            'dividend_per_share': str(row.iloc[1] if len(row) > 1 else '0'),
                                            'dividend_type': str(row.iloc[2] if len(row) > 2 else 'åˆ†çº¢'),
                                            'announcement_date': str(row.iloc[3] if len(row) > 3 else ''),
                                            'record_date': str(row.iloc[4] if len(row) > 4 else ''),
                                            'ex_dividend_date': str(row.iloc[5] if len(row) > 5 else ''),
                                            'source': f'akshare_{api_name}'
                                        }
                                        dividend_info_list.append(dividend_item)
                                    # æ ‡å‡†åŒ–ä¸æ’åº
                                    dividend_info_list = self._normalize_dividend_records(dividend_info_list)
                                    dividend_info_list = sorted(dividend_info_list, key=lambda x: str(x.get('year','')), reverse=True)
                                    fundamental_data['dividend_info'] = dividend_info_list
                                    self.logger.info(f"âœ“ akshare({api_name})è·å–åˆ†çº¢é…è‚¡ä¿¡æ¯æˆåŠŸï¼Œå…±{len(dividend_info_list)}æ¡")
                                    break
                            except Exception as e:
                                self.logger.warning(f"akshare {api_name} è·å–åˆ†çº¢æ•°æ®å¤±è´¥: {e}")
                                continue
                        
                        if not dividend_info_list:
                            fundamental_data['dividend_info'] = []
                            self.logger.info("â„¹ï¸ åˆ†çº¢é…è‚¡ä¿¡æ¯æš‚æ—¶ä¸å¯ç”¨")
                    
                    except Exception as e:
                        self.logger.warning(f"akshareè·å–åˆ†çº¢é…è‚¡ä¿¡æ¯å¤±è´¥: {e}")
                        fundamental_data['dividend_info'] = []
                
            except Exception as e:
                self.logger.warning(f"è·å–åˆ†çº¢é…è‚¡ä¿¡æ¯å¤±è´¥: {e}")
                fundamental_data['dividend_info'] = []
            
            # 6. è¡Œä¸šåˆ†ææ•°æ®
            try:
                self.logger.info("æ­£åœ¨è·å–è¡Œä¸šåˆ†ææ•°æ®...")
                industry_data = self._get_industry_analysis(stock_code)
                fundamental_data['industry_analysis'] = industry_data
                self.logger.info("âœ“ è¡Œä¸šåˆ†ææ•°æ®è·å–æˆåŠŸ")
            except Exception as e:
                self.logger.warning(f"è·å–è¡Œä¸šåˆ†æå¤±è´¥: {e}")
                fundamental_data['industry_analysis'] = {}
            
            # å…¶ä»–æ•°æ®é¡¹åˆå§‹åŒ–
            fundamental_data.setdefault('shareholders', [])
            fundamental_data.setdefault('institutional_holdings', [])
            
            return fundamental_data
            
        except Exception as e:
            self.logger.error(f"akshareè·å–ç»¼åˆåŸºæœ¬é¢æ•°æ®å¤±è´¥: {str(e)}")
            return {
                'basic_info': {},
                'financial_indicators': {},
                'valuation': {},
                'performance_forecast': [],
                'dividend_info': [],
                'industry_analysis': {},
                'shareholders': [],
                'institutional_holdings': []
            }

    def _calculate_core_financial_indicators(self, raw_data):
        """è®¡ç®—25é¡¹æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡"""
        try:
            indicators = {}
            
            # ä»åŸå§‹æ•°æ®ä¸­å®‰å…¨è·å–æ•°å€¼
            def safe_get(key, default=0):
                value = raw_data.get(key, default)
                try:
                    return float(value) if value not in [None, '', 'nan'] else default
                except:
                    return default
            
            # 1-5: ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡
            indicators['å‡€åˆ©æ¶¦ç‡'] = safe_get('å‡€åˆ©æ¶¦ç‡')
            indicators['å‡€èµ„äº§æ”¶ç›Šç‡'] = safe_get('å‡€èµ„äº§æ”¶ç›Šç‡')
            indicators['æ€»èµ„äº§æ”¶ç›Šç‡'] = safe_get('æ€»èµ„äº§æ”¶ç›Šç‡')
            indicators['æ¯›åˆ©ç‡'] = safe_get('æ¯›åˆ©ç‡')
            indicators['è¥ä¸šåˆ©æ¶¦ç‡'] = safe_get('è¥ä¸šåˆ©æ¶¦ç‡')
            
            # 6-10: å¿å€ºèƒ½åŠ›æŒ‡æ ‡
            indicators['æµåŠ¨æ¯”ç‡'] = safe_get('æµåŠ¨æ¯”ç‡')
            indicators['é€ŸåŠ¨æ¯”ç‡'] = safe_get('é€ŸåŠ¨æ¯”ç‡')
            indicators['èµ„äº§è´Ÿå€ºç‡'] = safe_get('èµ„äº§è´Ÿå€ºç‡')
            indicators['äº§æƒæ¯”ç‡'] = safe_get('äº§æƒæ¯”ç‡')
            indicators['åˆ©æ¯ä¿éšœå€æ•°'] = safe_get('åˆ©æ¯ä¿éšœå€æ•°')
            
            # 11-15: è¥è¿èƒ½åŠ›æŒ‡æ ‡
            indicators['æ€»èµ„äº§å‘¨è½¬ç‡'] = safe_get('æ€»èµ„äº§å‘¨è½¬ç‡')
            indicators['å­˜è´§å‘¨è½¬ç‡'] = safe_get('å­˜è´§å‘¨è½¬ç‡')
            indicators['åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡'] = safe_get('åº”æ”¶è´¦æ¬¾å‘¨è½¬ç‡')
            indicators['æµåŠ¨èµ„äº§å‘¨è½¬ç‡'] = safe_get('æµåŠ¨èµ„äº§å‘¨è½¬ç‡')
            indicators['å›ºå®šèµ„äº§å‘¨è½¬ç‡'] = safe_get('å›ºå®šèµ„äº§å‘¨è½¬ç‡')
            
            # 16-20: å‘å±•èƒ½åŠ›æŒ‡æ ‡
            indicators['è¥æ”¶åŒæ¯”å¢é•¿ç‡'] = safe_get('è¥æ”¶åŒæ¯”å¢é•¿ç‡')
            indicators['å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡'] = safe_get('å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡')
            indicators['æ€»èµ„äº§å¢é•¿ç‡'] = safe_get('æ€»èµ„äº§å¢é•¿ç‡')
            indicators['å‡€èµ„äº§å¢é•¿ç‡'] = safe_get('å‡€èµ„äº§å¢é•¿ç‡')
            indicators['ç»è¥ç°é‡‘æµå¢é•¿ç‡'] = safe_get('ç»è¥ç°é‡‘æµå¢é•¿ç‡')
            
            # 21-25: å¸‚åœºè¡¨ç°æŒ‡æ ‡
            indicators['å¸‚ç›ˆç‡'] = safe_get('å¸‚ç›ˆç‡')
            indicators['å¸‚å‡€ç‡'] = safe_get('å¸‚å‡€ç‡')
            indicators['å¸‚é”€ç‡'] = safe_get('å¸‚é”€ç‡')
            indicators['PEGæ¯”ç‡'] = safe_get('PEGæ¯”ç‡')
            indicators['è‚¡æ¯æ”¶ç›Šç‡'] = safe_get('è‚¡æ¯æ”¶ç›Šç‡')
            
            # è®¡ç®—ä¸€äº›è¡ç”ŸæŒ‡æ ‡
            try:
                # å¦‚æœæœ‰åŸºç¡€æ•°æ®ï¼Œè®¡ç®—ä¸€äº›å…³é”®æ¯”ç‡
                revenue = safe_get('è¥ä¸šæ”¶å…¥')
                net_income = safe_get('å‡€åˆ©æ¶¦')
                total_assets = safe_get('æ€»èµ„äº§')
                shareholders_equity = safe_get('è‚¡ä¸œæƒç›Š')
                
                if revenue > 0 and net_income > 0:
                    if indicators['å‡€åˆ©æ¶¦ç‡'] == 0:
                        indicators['å‡€åˆ©æ¶¦ç‡'] = (net_income / revenue) * 100
                
                if total_assets > 0 and net_income > 0:
                    if indicators['æ€»èµ„äº§æ”¶ç›Šç‡'] == 0:
                        indicators['æ€»èµ„äº§æ”¶ç›Šç‡'] = (net_income / total_assets) * 100
                
                if shareholders_equity > 0 and net_income > 0:
                    if indicators['å‡€èµ„äº§æ”¶ç›Šç‡'] == 0:
                        indicators['å‡€èµ„äº§æ”¶ç›Šç‡'] = (net_income / shareholders_equity) * 100
                        
            except Exception as e:
                self.logger.warning(f"è®¡ç®—è¡ç”ŸæŒ‡æ ‡å¤±è´¥: {e}")
            
            # è¿‡æ»¤æ‰æ— æ•ˆçš„æŒ‡æ ‡
            valid_indicators = {k: v for k, v in indicators.items() if v not in [0, None, 'nan']}
            
            self.logger.info(f"âœ“ æˆåŠŸè®¡ç®— {len(valid_indicators)} é¡¹æœ‰æ•ˆè´¢åŠ¡æŒ‡æ ‡")
            return valid_indicators
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {e}")
            return {}

    def _get_industry_analysis(self, stock_code):
        """è·å–è¡Œä¸šåˆ†ææ•°æ®ï¼ˆå«åŒä¸šå¯¹æ¯”ä¸æ’åï¼‰"""
        try:
            import akshare as ak
            import difflib
            industry_data = {}

            # è·å–åŸºæœ¬è¡Œä¸šå½’å±
            try:
                info = ak.stock_individual_info_em(symbol=stock_code)
                industry_name = None
                if info is not None and not info.empty:
                    m = dict(zip(info['item'], info['value']))
                    industry_name = m.get('æ‰€å±è¡Œä¸š') or m.get('è¡Œä¸š')
                # ä¸»å£å¾„ï¼ˆä¸œè´¢ï¼‰çš„è¡Œä¸šå
                primary = industry_name or ''
                industry_data['industry_name'] = primary  # å…¼å®¹æ—§å­—æ®µ
                industry_data['industry_name_primary'] = primary
                # é¢„ç½®å¤šå£å¾„ä¿¡æ¯å ä½
                industry_data['baostock_industry_name'] = ''
                industry_data['industry_source'] = ''
                industry_data['resolved_em_name'] = ''
                industry_data['industry_tags'] = []
            except Exception as e:
                self.logger.warning(f"è·å–è¡Œä¸šå½’å±å¤±è´¥: {e}")
                industry_data['industry_name'] = ''
                industry_data['industry_name_primary'] = ''
                industry_data['baostock_industry_name'] = ''
                industry_data['industry_source'] = ''
                industry_data['resolved_em_name'] = ''
                industry_data['industry_tags'] = []

            # è·å–è¡Œä¸šæˆä»½å¹¶åšåŒä¸šå¯¹æ¯”
            peers = []
            try:
                # æ ¹æ®è¡Œä¸šåç§°è§£æä¸ºEastmoneyå¯è¯†åˆ«åç§°
                def _resolve_em_industry_name(name: str) -> str:
                    if not isinstance(name, str) or not name.strip():
                        return ''
                    try:
                        df_names = ak.stock_board_industry_name_em()
                    except Exception:
                        df_names = pd.DataFrame()
                    if df_names is None or df_names.empty:
                        return name
                    # å–å¯èƒ½çš„åç§°åˆ—
                    cand_cols = [c for c in ['æ¿å—åç§°','åç§°','è¡Œä¸šåç§°','è¡Œä¸š'] if c in df_names.columns]
                    name_col = cand_cols[0] if cand_cols else df_names.columns[0]
                    pool = [str(x) for x in df_names[name_col].dropna().unique().tolist()]
                    # 1) ç²¾ç¡®åŒ¹é…
                    if name in pool:
                        return name
                    # 2) å­ä¸²åŒ¹é…ï¼ˆåŒå‘ï¼‰
                    subs = [p for p in pool if (name in p) or (p in name)]
                    if subs:
                        return subs[0]
                    # 3) ç›¸ä¼¼åº¦åŒ¹é…
                    m = difflib.get_close_matches(name, pool, n=1, cutoff=0.6)
                    if m:
                        return m[0]
                    return name

                if industry_data['industry_name']:
                    em_name = _resolve_em_industry_name(industry_data['industry_name'])
                    industry_data['resolved_em_name'] = em_name
                    cons = pd.DataFrame()
                    # å…ˆå°è¯•EMå£å¾„
                    try:
                        cons = ak.stock_board_industry_cons_em(symbol=em_name)
                        if cons is not None and not cons.empty:
                            industry_data['industry_source'] = 'EM'
                    except Exception as e_em:
                        self.logger.info(f"â„¹ï¸ EMè¡Œä¸šæˆä»½è·å–å¤±è´¥({e_em})ï¼Œå°è¯•THSå£å¾„")
                    # å…œåº•ï¼šå°è¯•åŒèŠ±é¡ºå£å¾„
                    if (cons is None or cons.empty):
                        try:
                            cons = ak.stock_board_industry_cons_ths(symbol=em_name)
                            if cons is not None and not cons.empty and not industry_data.get('industry_source'):
                                industry_data['industry_source'] = 'THS'
                        except Exception as e_ths:
                            self.logger.info(f"â„¹ï¸ THSè¡Œä¸šæˆä»½è·å–å¤±è´¥({e_ths})")
                    # è‹¥ä»ä¸ºç©ºï¼Œå°è¯•ä»ç¼“å­˜è¯»å–
                    if (cons is None or cons.empty):
                        cache_df = self._load_industry_cons_cache(em_name)
                        if cache_df is not None and not cache_df.empty:
                            cons = cache_df
                            self.logger.info("â„¹ï¸ ä½¿ç”¨æœ¬åœ°è¡Œä¸šæˆä»½ç¼“å­˜")
                            if not industry_data.get('industry_source'):
                                industry_data['industry_source'] = 'Cache'
                else:
                    cons = pd.DataFrame()
                if cons is not None and not cons.empty:
                    # æˆåŠŸåˆ™å†™å…¥ç¼“å­˜
                    try:
                        self._save_industry_cons_cache(em_name, cons)
                    except Exception:
                        pass
                # è¿›ä¸€æ­¥å…œåº•ï¼šä½¿ç”¨BaoStockè¡Œä¸šåˆ†ç±»æ„é€ æˆä»½åˆ—è¡¨
                if (cons is None or cons.empty) and getattr(self, 'baostock_connected', False):
                    try:
                        # è·å–å…¨å¸‚åœºè¡Œä¸šåˆ†ç±»
                        dt = datetime.now().strftime('%Y-%m-%d')
                        df_ind = self._query_baostock_data(bs.query_stock_industry, date=dt)
                        if (df_ind is None or df_ind.empty):
                            df_ind = self._query_baostock_data(bs.query_stock_industry)
                        if df_ind is not None and not df_ind.empty:
                            # æ‰¾åˆ°ç›®æ ‡è‚¡ç¥¨æ‰€åœ¨è¡Œä¸š
                            formatted = self._format_stock_code_for_baostock(stock_code)
                            # å…¼å®¹æ— å‰ç¼€åŒ¹é…
                            row_self = df_ind[(df_ind['code'] == formatted) | (df_ind['code'].str.endswith(str(stock_code)))]
                            if not row_self.empty:
                                bs_ind_name = row_self.iloc[0].get('industry') or ''
                                industry_data['baostock_industry_name'] = str(bs_ind_name)
                                peers_df = df_ind[df_ind['industry'] == bs_ind_name].copy()
                                if not peers_df.empty:
                                    # æ„é€ ä¸EMç±»ä¼¼çš„æˆä»½è¡¨ç»“æ„
                                    cons = pd.DataFrame({
                                        'ä»£ç ': peers_df['code'].astype(str).str[-6:],
                                        'åç§°': peers_df['code_name'] if 'code_name' in peers_df.columns else peers_df.get('codeName', '')
                                    })
                                    # è®¾ç½®è¡Œä¸šåç§°ï¼ˆè‹¥åŸæœ¬ä¸ºç©ºï¼‰
                                    if not industry_data.get('industry_name'):
                                        industry_data['industry_name'] = str(bs_ind_name)
                                        industry_data['industry_name_primary'] = industry_data.get('industry_name_primary','')
                                    if not industry_data.get('industry_source'):
                                        industry_data['industry_source'] = 'BaoStock'
                                    self.logger.info("âœ“ ä½¿ç”¨BaoStockè¡Œä¸šåˆ†ç±»æ„é€ è¡Œä¸šæˆä»½")
                    except Exception as e_bs:
                        self.logger.info(f"â„¹ï¸ BaoStockè¡Œä¸šåˆ†ç±»å…œåº•å¤±è´¥: {e_bs}")
                    # ç»Ÿä¸€åˆ—å
                    code_col = 'ä»£ç ' if 'ä»£ç ' in cons.columns else cons.columns[0]
                    name_col = 'åç§°' if 'åç§°' in cons.columns else (cons.columns[1] if len(cons.columns)>1 else code_col)
                    # å–å¿«ç…§ç”¨äºæ¶¨è·Œå¹…ä¸å¸‚å€¼ï¼ˆåœ¨çº¿å¤±è´¥åˆ™å›é€€ç¼“å­˜ï¼‰
                    try:
                        spot = ak.stock_zh_a_spot_em()
                        if spot is not None and not spot.empty:
                            self._save_spot_snapshot_cache(spot)
                    except Exception:
                        spot = self._load_spot_snapshot_cache()
                    if spot is not None and not spot.empty:
                        spot = spot[[c for c in spot.columns if c in ['ä»£ç ','åç§°','æ¶¨è·Œå¹…','æœ€æ–°ä»·','æ€»å¸‚å€¼','æ€»å¸‚å€¼(äº¿)']]]
                        df = cons.merge(spot, left_on=code_col, right_on='ä»£ç ', how='left')
                    else:
                        df = cons.copy()
                    # åˆå¹¶åï¼Œç»Ÿä¸€é€‰æ‹©å¯ç”¨çš„ä»£ç /åç§°åˆ—ï¼ˆé¿å… _x/_y å†²çªï¼‰
                    def pick_col(df_cols, candidates):
                        for c in candidates:
                            if c in df_cols:
                                return c
                        return None
                    code_candidates = [code_col, 'ä»£ç ', f'{code_col}_x', 'ä»£ç _x', f'{code_col}_y', 'ä»£ç _y']
                    name_candidates = [name_col, 'åç§°', f'{name_col}_x', 'åç§°_x', f'{name_col}_y', 'åç§°_y']
                    code_eff = pick_col(df.columns, code_candidates) or code_col
                    name_eff = pick_col(df.columns, name_candidates) or name_col
                    # è®¡ç®—æ’å
                    def to_float(x):
                        try:
                            if isinstance(x,str) and x.endswith('%'):
                                return float(x.strip('%'))
                            return float(x)
                        except Exception:
                            return np.nan
                    df['æ¶¨è·Œå¹…_val'] = df['æ¶¨è·Œå¹…'].apply(to_float) if 'æ¶¨è·Œå¹…' in df.columns else np.nan
                    cap_col = 'æ€»å¸‚å€¼' if 'æ€»å¸‚å€¼' in df.columns else ('æ€»å¸‚å€¼(äº¿)' if 'æ€»å¸‚å€¼(äº¿)' in df.columns else None)
                    if cap_col:
                        df['æ€»å¸‚å€¼_val'] = df[cap_col].apply(to_float)
                    else:
                        df['æ€»å¸‚å€¼_val'] = np.nan
                    # æ’åä¸ç™¾åˆ†ä½
                    df['rank_return'] = df['æ¶¨è·Œå¹…_val'].rank(ascending=False, method='min')
                    df['pct_return'] = df['rank_return'] / df['rank_return'].max()
                    df['rank_mktcap'] = df['æ€»å¸‚å€¼_val'].rank(ascending=False, method='min')
                    df['pct_mktcap'] = df['rank_mktcap'] / df['rank_mktcap'].max()
                    # å½“å‰ä¸ªè‚¡è¡Œï¼ˆå…¼å®¹ä¸åŒä»£ç åˆ—åï¼‰
                    code_match_col = 'ä»£ç ' if 'ä»£ç ' in df.columns else code_eff
                    try:
                        cur = df[df[code_match_col].astype(str) == str(stock_code)]
                    except Exception:
                        cur = pd.DataFrame()
                    if not cur.empty:
                        row = cur.iloc[0]
                        industry_data['industry_rank'] = {
                            'peers_count': int(len(df)),
                            'return_rank': float(row.get('rank_return', np.nan)),
                            'return_percentile': float(row.get('pct_return', np.nan)),
                            'mktcap_rank': float(row.get('rank_mktcap', np.nan)),
                            'mktcap_percentile': float(row.get('pct_mktcap', np.nan)),
                        }
                        industry_data['in_constituents'] = True
                    else:
                        industry_data['industry_rank'] = {}
                        industry_data['in_constituents'] = False
                    # é™„å¸¦å°‘é‡åŒä¸šæ‘˜è¦
                    try:
                        cols = []
                        for c in [code_eff, name_eff]:
                            if c and c in df.columns and c not in cols:
                                cols.append(c)
                        if 'æ¶¨è·Œå¹…' in df.columns:
                            cols.append('æ¶¨è·Œå¹…')
                        if 'æ€»å¸‚å€¼' in df.columns:
                            cols.append('æ€»å¸‚å€¼')
                        elif 'æ€»å¸‚å€¼(äº¿)' in df.columns:
                            cols.append('æ€»å¸‚å€¼(äº¿)')
                        if cols:
                            peers = df[cols].head(20).to_dict('records')
                        else:
                            peers = cons.head(20).to_dict('records')
                    except Exception:
                        peers = []
                else:
                    industry_data['industry_rank'] = {}
                    industry_data['in_constituents'] = False
            except Exception as e:
                self.logger.warning(f"åŒä¸šå¯¹æ¯”å¤±è´¥: {e}")
                industry_data['industry_rank'] = {}
                industry_data['in_constituents'] = False
            industry_data['peers_sample'] = peers

            # æ±‡æ€»è¡Œä¸šæ ‡ç­¾
            try:
                tags = []
                for t in [industry_data.get('industry_name_primary',''), industry_data.get('baostock_industry_name','')]:
                    if isinstance(t, str) and t.strip() and t not in tags:
                        tags.append(t)
                industry_data['industry_tags'] = tags
            except Exception:
                pass

            return industry_data
        except Exception as e:
            self.logger.warning(f"è¡Œä¸šåˆ†æå¤±è´¥: {e}")
            return {}

    def get_comprehensive_news_data(self, stock_code, days=30):
        """è·å–ç»¼åˆæ–°é—»æ•°æ®ï¼ˆå¤§å¹…å¢å¼ºï¼‰"""
        cache_key = f"{stock_code}_{days}"
        if cache_key in self.news_cache:
            cache_time, data = self.news_cache[cache_key]
            if datetime.now() - cache_time < self.news_cache_duration:
                self.logger.info(f"ä½¿ç”¨ç¼“å­˜çš„æ–°é—»æ•°æ®: {stock_code}")
                return data
        
        self.logger.info(f"å¼€å§‹è·å– {stock_code} çš„ç»¼åˆæ–°é—»æ•°æ®ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")
        
        try:
            import akshare as ak
            
            stock_name = self.get_stock_name(stock_code)
            all_news_data = {
                'company_news': [],
                'announcements': [],
                'research_reports': [],
                'industry_news': [],
                'market_sentiment': {},
                'news_summary': {}
            }
            
            # 1. å…¬å¸æ–°é—»
            try:
                self.logger.info("æ­£åœ¨è·å–å…¬å¸æ–°é—»...")
                company_news = ak.stock_news_em(symbol=stock_code)
                if not company_news.empty:
                    # å¤„ç†æ–°é—»æ•°æ®
                    processed_news = []
                    for _, row in company_news.head(50).iterrows():
                        news_item = {
                            'title': str(row.get('æ–°é—»æ ‡é¢˜', '')),
                            'content': str(row.get('æ–°é—»å†…å®¹', '')),
                            'date': str(row.get('å‘å¸ƒæ—¶é—´', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))),
                            'source': str(row.get('æ–‡ç« æ¥æº', 'eastmoney')),
                            'url': str(row.get('æ–°é—»é“¾æ¥', '')),
                            'keyword': str(row.get('å…³é”®è¯', stock_code)),
                            'relevance_score': 1.0
                        }
                        processed_news.append(news_item)
                    
                    all_news_data['company_news'] = processed_news
                    self.logger.info(f"âœ“ è·å–å…¬å¸æ–°é—» {len(processed_news)} æ¡")
                else:
                    self.logger.info("å…¬å¸æ–°é—»æ•°æ®ä¸ºç©º")
            except Exception as e:
                self.logger.warning(f"è·å–å…¬å¸æ–°é—»å¤±è´¥: {e}")
            
            # 2. å…¬å¸å…¬å‘Š
            try:
                self.logger.info("æ­£åœ¨è·å–å…¬å¸å…¬å‘Š...")
                announcements = ak.stock_notice_report()
                if not announcements.empty:
                    # ç­›é€‰å½“å‰è‚¡ç¥¨çš„å…¬å‘Šï¼ˆå…¼å®¹ä¸åŒåˆ—åï¼‰
                    code_cols = [c for c in ['ä»£ç ','è‚¡ç¥¨ä»£ç ','è¯åˆ¸ä»£ç ','è¯åˆ¸ä»£ç (6ä½)'] if c in announcements.columns]
                    if not code_cols:
                        # æ‰¾ä¸€ä¸ªçœ‹èµ·æ¥åƒä»£ç çš„åˆ—
                        code_cols = [c for c in announcements.columns if 'ä»£ç ' in str(c)] or [announcements.columns[0]]
                    code_col = code_cols[0]
                    stock_announcements = announcements[announcements[code_col].astype(str) == str(stock_code)]
                    # ä»…ä¿ç•™æœ€è¿‘365å¤©ï¼ˆå…¼å®¹ä¸åŒæ—¥æœŸåˆ—åï¼‰
                    date_cols = [c for c in ['å…¬å‘Šæ—¥æœŸ','å…¬å‘Šæ—¶é—´','æ—¥æœŸ','å‘å¸ƒæ—¶é—´'] if c in stock_announcements.columns]
                    if date_cols:
                        try:
                            cutoff = (datetime.now() - timedelta(days=365)).date()
                            dt = pd.to_datetime(stock_announcements[date_cols[0]], errors='coerce').dt.date
                            stock_announcements = stock_announcements.loc[dt >= cutoff]
                        except Exception:
                            pass
                    processed_announcements = []
                    for _, row in stock_announcements.head(30).iterrows():
                        announcement = {
                            'title': str(row.get('å…¬å‘Šæ ‡é¢˜', '')),
                            'content': str(row.get('å…¬å‘Šç±»å‹', '')) + ' - ' + str(row.get('å…¬å‘Šæ ‡é¢˜', '')),
                            'date': str(row.get('å…¬å‘Šæ—¥æœŸ') or row.get('å…¬å‘Šæ—¶é—´') or row.get('æ—¥æœŸ') or row.get('å‘å¸ƒæ—¶é—´') or datetime.now().strftime('%Y-%m-%d')),
                            'type': str(row.get('å…¬å‘Šç±»å‹', 'å…¬å‘Š')),
                            'relevance_score': 1.0
                        }
                        processed_announcements.append(announcement)
                    all_news_data['announcements'] = processed_announcements
                    self.logger.info(f"âœ“ è·å–å…¬å¸å…¬å‘Š {len(processed_announcements)} æ¡")
                else:
                    self.logger.info("æœªè·å–åˆ°å…¬å¸å…¬å‘Šæ•°æ®")
            except Exception as e:
                self.logger.warning(f"è·å–å…¬å¸å…¬å‘Šå¤±è´¥: {e}")
            
            # 3. ç ”ç©¶æŠ¥å‘Š
            try:
                self.logger.info("æ­£åœ¨è·å–ç ”ç©¶æŠ¥å‘Š...")
                research_reports = ak.stock_research_report_em(symbol=stock_code)
                if not research_reports.empty:
                    processed_reports = []
                    for _, row in research_reports.head(20).iterrows():
                        report = {
                            'title': str(row.get(row.index[0], '')),
                            'institution': str(row.get(row.index[1], '')) if len(row.index) > 1 else '',
                            'rating': str(row.get(row.index[2], '')) if len(row.index) > 2 else '',
                            'target_price': str(row.get(row.index[3], '')) if len(row.index) > 3 else '',
                            'date': str(row.get(row.index[4], '')) if len(row.index) > 4 else datetime.now().strftime('%Y-%m-%d'),
                            'relevance_score': 0.9
                        }
                        processed_reports.append(report)
                    
                    all_news_data['research_reports'] = processed_reports
                    self.logger.info(f"âœ“ è·å–ç ”ç©¶æŠ¥å‘Š {len(processed_reports)} æ¡")
            except Exception as e:
                self.logger.warning(f"è·å–ç ”ç©¶æŠ¥å‘Šå¤±è´¥: {e}")
            
            # 4. è¡Œä¸šæ–°é—»
            try:
                self.logger.info("æ­£åœ¨è·å–è¡Œä¸šæ–°é—»...")
                industry_news = self._get_comprehensive_industry_news(stock_code, days)
                all_news_data['industry_news'] = industry_news
                self.logger.info(f"âœ“ è·å–è¡Œä¸šæ–°é—» {len(industry_news)} æ¡")
            except Exception as e:
                self.logger.warning(f"è·å–è¡Œä¸šæ–°é—»å¤±è´¥: {e}")
            
            # 5. æ–°é—»æ‘˜è¦ç»Ÿè®¡
            try:
                total_news = (len(all_news_data['company_news']) + 
                            len(all_news_data['announcements']) + 
                            len(all_news_data['research_reports']) + 
                            len(all_news_data['industry_news']))
                
                all_news_data['news_summary'] = {
                    'total_news_count': total_news,
                    'company_news_count': len(all_news_data['company_news']),
                    'announcements_count': len(all_news_data['announcements']),
                    'research_reports_count': len(all_news_data['research_reports']),
                    'industry_news_count': len(all_news_data['industry_news']),
                    'data_freshness': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
            except Exception as e:
                self.logger.warning(f"ç”Ÿæˆæ–°é—»æ‘˜è¦å¤±è´¥: {e}")
            
            # ç¼“å­˜æ•°æ®
            self.news_cache[cache_key] = (datetime.now(), all_news_data)
            
            self.logger.info(f"âœ“ ç»¼åˆæ–°é—»æ•°æ®è·å–å®Œæˆï¼Œæ€»è®¡ {all_news_data['news_summary'].get('total_news_count', 0)} æ¡")
            return all_news_data
            
        except Exception as e:
            self.logger.error(f"è·å–ç»¼åˆæ–°é—»æ•°æ®å¤±è´¥: {str(e)}")
            return {
                'company_news': [],
                'announcements': [],
                'research_reports': [],
                'industry_news': [],
                'market_sentiment': {},
                'news_summary': {'total_news_count': 0}
            }

    def _get_comprehensive_industry_news(self, stock_code, days=30):
        """è·å–è¯¦ç»†çš„è¡Œä¸šæ–°é—»"""
        try:
            # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€è¦æ‰©å±•è¡Œä¸šæ–°é—»è·å–é€»è¾‘
            # ç›®å‰è¿”å›ä¸€ä¸ªç¤ºä¾‹ç»“æ„
            industry_news = []
            
            # å¯ä»¥æ·»åŠ æ›´å¤šçš„è¡Œä¸šæ–°é—»æº
            # æ¯”å¦‚è·å–åŒè¡Œä¸šå…¶ä»–å…¬å¸çš„æ–°é—»
            # è·å–è¡Œä¸šæ”¿ç­–æ–°é—»ç­‰
            
            self.logger.info(f"è¡Œä¸šæ–°é—»è·å–å®Œæˆï¼Œå…± {len(industry_news)} æ¡")
            return industry_news
            
        except Exception as e:
            self.logger.warning(f"è·å–è¡Œä¸šæ–°é—»å¤±è´¥: {e}")
            return []

    def calculate_advanced_sentiment_analysis(self, comprehensive_news_data):
        """è®¡ç®—é«˜çº§æƒ…ç»ªåˆ†æï¼ˆå¼ºåŒ–ç‰ˆï¼‰"""
        self.logger.info("å¼€å§‹é«˜çº§æƒ…ç»ªåˆ†æ...")

        try:
            # ç»Ÿä¸€æŠ½å–æ–‡æœ¬ä¸å…ƒæ•°æ®
            items = []
            def add_item(text, kind, date=None, source_weight=1.0):
                if not isinstance(text, str) or not text.strip():
                    return
                items.append({
                    'text': text.strip(),
                    'type': kind,
                    'date': date,
                    'source_weight': float(source_weight)
                })

            for x in comprehensive_news_data.get('company_news', []) or []:
                add_item(f"{x.get('title','')} {x.get('content','')}", 'company_news', x.get('date'), 1.0)

            for x in comprehensive_news_data.get('announcements', []) or []:
                add_item(f"{x.get('title','')} {x.get('content','')}", 'announcement', x.get('date'), 1.3)

            for x in comprehensive_news_data.get('research_reports', []) or []:
                add_item(f"{x.get('title','')} {x.get('rating','')}", 'research_report', x.get('date'), 1.1)

            for x in comprehensive_news_data.get('industry_news', []) or []:
                add_item(f"{x.get('title','')} {x.get('content','')}", 'industry_news', x.get('date'), 0.8)

            if not items:
                return {
                    'overall_sentiment': 0.0,
                    'sentiment_by_type': {},
                    'sentiment_trend': 'ä¸­æ€§',
                    'confidence_score': 0.0,
                    'total_analyzed': 0
                }

            # æƒ…æ„Ÿè¯è¡¨ï¼ˆå¯æ‰©å±•ï¼‰
            positive_words = {
                'ä¸Šæ¶¨','æ¶¨åœ','åˆ©å¥½','çªç ´','å¢é•¿','ç›ˆåˆ©','æ”¶ç›Š','å›å‡','å¼ºåŠ¿','çœ‹å¥½',
                'ä¹°å…¥','æ¨è','ä¼˜ç§€','é¢†å…ˆ','åˆ›æ–°','å‘å±•','æœºä¼š','æ½œåŠ›','ç¨³å®š','æ”¹å–„',
                'æå‡','è¶…é¢„æœŸ','ç§¯æ','ä¹è§‚','å‘å¥½','å—ç›Š','é¾™å¤´','çƒ­ç‚¹','çˆ†å‘','ç¿»å€',
                'ä¸šç»©','å¢æ”¶','æ‰©å¼ ','åˆä½œ','ç­¾çº¦','ä¸­æ ‡','è·å¾—','æˆåŠŸ','å®Œæˆ','è¾¾æˆ'
            }
            negative_words = {
                'ä¸‹è·Œ','è·Œåœ','åˆ©ç©º','ç ´ä½','ä¸‹æ»‘','äºæŸ','é£é™©','å›è°ƒ','å¼±åŠ¿','çœ‹ç©º',
                'å–å‡º','å‡æŒ','è¾ƒå·®','è½å','æ»å','å›°éš¾','å±æœº','æ‹…å¿§','æ‚²è§‚','æ¶åŒ–',
                'ä¸‹é™','ä½äºé¢„æœŸ','æ¶ˆæ','å‹åŠ›','å¥—ç‰¢','è¢«å¥—','æš´è·Œ','å´©ç›˜','è¸©é›·','é€€å¸‚',
                'è¿è§„','å¤„ç½š','è°ƒæŸ¥','åœç‰Œ','å€ºåŠ¡','è¿çº¦','è¯‰è®¼','çº çº·','é—®é¢˜'
            }

            # å»é‡ï¼šç›¸åŒæ ‡é¢˜/æ–‡æœ¬çš„åªå–ä¸€æ¬¡
            seen = set()
            dedup_items = []
            for it in items:
                key = (it['type'], it['text'])
                if key in seen:
                    continue
                seen.add(key)
                dedup_items.append(it)

            # è®¡ç®—æ—¶é—´è¡°å‡æƒé‡
            dates = [it.get('date') for it in dedup_items]
            tweights = self._time_decay_weights(dates, half_life_days=20.0)
            for it, tw in zip(dedup_items, tweights):
                it['time_weight'] = float(tw)

            # é€æ¡è®¡ç®—æƒ…ç»ªåˆ†
            by_type_scores = {}
            weighted_scores = []
            for it in dedup_items:
                tokens = self._tokenize_cn(it['text'])
                raw = self._sentiment_from_tokens(tokens, positive_words, negative_words)  # [-1,1]
                # ç»¼åˆæƒé‡ï¼šæ¥æºæƒé‡ * æ—¶é—´æƒé‡
                w = float(it.get('source_weight', 1.0)) * float(it.get('time_weight', 1.0))
                weighted = raw * w
                weighted_scores.append(weighted)

                typ = it['type']
                by_type_scores.setdefault(typ, []).append(weighted)

            # é²æ£’èšåˆï¼šé‡‡ç”¨ç¼©å°¾ä¸å‡å€¼
            ws = pd.Series(weighted_scores, dtype=float)
            ws = self._winsorize(ws, 0.05, 0.95)
            overall = float(ws.mean()) if len(ws) else 0.0

            # ç±»å‹å‡å€¼
            avg_by_type = {}
            for typ, arr in by_type_scores.items():
                s = pd.Series(arr, dtype=float)
                s = self._winsorize(s, 0.05, 0.95)
                avg_by_type[typ] = float(s.mean()) if len(s) else 0.0

            # æƒ…ç»ªè¶‹åŠ¿
            if overall > 0.35:
                trend = 'éå¸¸ç§¯æ'
            elif overall > 0.15:
                trend = 'åå‘ç§¯æ'
            elif overall > -0.15:
                trend = 'ç›¸å¯¹ä¸­æ€§'
            elif overall > -0.35:
                trend = 'åå‘æ¶ˆæ'
            else:
                trend = 'éå¸¸æ¶ˆæ'

            # ç½®ä¿¡åº¦ï¼šæ•°æ®é‡ä¸æ—¶é—´æ–°é²œåº¦åˆæˆ
            n = len(dedup_items)
            try:
                # åŸºäºæ•°é‡çš„ç½®ä¿¡åº¦ä¸Šé™æ›²çº¿ï¼ˆ100æ¡ä»¥ä¸ŠåŸºæœ¬é¥±å’Œï¼‰
                qty_conf = float(min(1.0, np.log1p(n) / np.log1p(100)))
            except Exception:
                qty_conf = float(min(1.0, n / 100.0))

            # åŸºäºæ—¶é—´çš„å¹³å‡æƒé‡ï¼ˆè¶Šæ–°è¶Šé«˜ï¼‰
            try:
                avg_time_w = float(np.mean([it.get('time_weight', 1.0) for it in dedup_items])) if n else 0.0
            except Exception:
                avg_time_w = 0.0

            confidence = float(max(0.0, min(1.0, 0.3 + 0.5 * qty_conf + 0.2 * avg_time_w)))

            result = {
                'overall_sentiment': overall,
                'sentiment_by_type': avg_by_type,
                'sentiment_trend': trend,
                'confidence_score': confidence,
                'total_analyzed': n,
                'type_distribution': {k: len(v) for k, v in by_type_scores.items()},
                'positive_ratio': float((ws > 0).mean()) if len(ws) else 0.0,
                'negative_ratio': float((ws < 0).mean()) if len(ws) else 0.0
            }

            self.logger.info(f"âœ“ é«˜çº§æƒ…ç»ªåˆ†æå®Œæˆ: {trend} (å¾—åˆ†: {overall:.3f})")
            return result

        except Exception as e:
            self.logger.error(f"é«˜çº§æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return {
                'overall_sentiment': 0.0,
                'sentiment_by_type': {},
                'sentiment_trend': 'åˆ†æå¤±è´¥',
                'confidence_score': 0.0,
                'total_analyzed': 0
            }

    def calculate_technical_indicators(self, price_data):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        try:
            # æ•°æ®è´¨é‡é¢„æ£€æŸ¥
            if price_data.empty:
                self.logger.warning("ä»·æ ¼æ•°æ®ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æŠ€æœ¯åˆ†æ")
                return self._get_default_technical_analysis()
            
            if 'close' not in price_data.columns:
                self.logger.warning("ç¼ºå°‘æ”¶ç›˜ä»·åˆ—ï¼Œè¿”å›é»˜è®¤æŠ€æœ¯åˆ†æ")
                return self._get_default_technical_analysis()
            
            # æ£€æŸ¥æ•°æ®é•¿åº¦
            data_length = len(price_data)
            if data_length < 5:
                self.logger.warning(f"æ•°æ®é•¿åº¦ä¸è¶³({data_length}è¡Œ)ï¼Œè¿”å›é»˜è®¤æŠ€æœ¯åˆ†æ")
                return self._get_default_technical_analysis()
            
            # æ£€æŸ¥å…³é”®åˆ—çš„æ•°æ®è´¨é‡
            required_columns = ['close']
            optional_columns = ['high', 'low', 'volume', 'open']
            
            for col in required_columns:
                if col in price_data.columns:
                    null_count = price_data[col].isnull().sum()
                    if null_count > 0:
                        self.logger.warning(f"'{col}'åˆ—æœ‰{null_count}ä¸ªç©ºå€¼")
                    
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
                    try:
                        price_data[col] = pd.to_numeric(price_data[col], errors='coerce')
                        invalid_count = price_data[col].isnull().sum()
                        if invalid_count > data_length * 0.5:  # è¶…è¿‡50%çš„æ•°æ®æ— æ•ˆ
                            self.logger.error(f"'{col}'åˆ—æ•°æ®è´¨é‡æå·®ï¼Œæœ‰æ•ˆæ•°æ®ä¸è¶³50%")
                            return self._get_default_technical_analysis()
                    except Exception as e:
                        self.logger.error(f"æ— æ³•è½¬æ¢'{col}'åˆ—ä¸ºæ•°å€¼ç±»å‹: {e}")
                        return self._get_default_technical_analysis()
            
            self.logger.info(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¼€å§‹ï¼šæ•°æ®è¡Œæ•°{data_length}ï¼Œåˆ—æ•°{len(price_data.columns)}")

            technical_analysis = {}

            # ä¸ºç¡®è®¤æœºåˆ¶é¢„ç•™åºåˆ—
            confirm_n = int(max(1, min(10, float(self.thresholds.get('confirm_days', 1) or 1))))
            rsi_series = None
            macd_hist_series = None
            macd_line_series = None
            signal_line_series = None
            ma20_series = None
            close_series = None

            close = price_data['close'].astype(float)
            high = price_data['high'].astype(float) if 'high' in price_data.columns else close
            low = price_data['low'].astype(float) if 'low' in price_data.columns else close
            volume = price_data['volume'].astype(float) if 'volume' in price_data.columns else pd.Series([np.nan]*len(price_data), index=price_data.index)

            # ç§»åŠ¨å¹³å‡çº¿ï¼ˆçŸ­ä¸­é•¿æœŸï¼‰
            try:
                price_data['ma20'] = close.rolling(window=20, min_periods=1).mean()
                price_data['ma50'] = close.rolling(window=50, min_periods=1).mean()
                price_data['ma120'] = close.rolling(window=120, min_periods=1).mean()

                latest = float(close.iloc[-1])
                ma20 = float(price_data['ma20'].iloc[-1])
                ma50 = float(price_data['ma50'].iloc[-1]) if len(price_data) >= 50 else ma20
                ma120 = float(price_data['ma120'].iloc[-1]) if len(price_data) >= 120 else ma50

                if latest > ma20 > ma50 > ma120:
                    technical_analysis['ma_trend'] = 'å¤šå¤´æ’åˆ—'
                elif latest < ma20 < ma50 < ma120:
                    technical_analysis['ma_trend'] = 'ç©ºå¤´æ’åˆ—'
                else:
                    technical_analysis['ma_trend'] = 'éœ‡è¡æ•´ç†'

                technical_analysis['price_above_ma20'] = latest / ma20 if ma20 else 1.0
                technical_analysis['ma_slope20'] = float(price_data['ma20'].diff().iloc[-1]) if len(price_data) >= 2 else 0.0
                # å…³é”®å‡çº¿æŒ‡æ ‡è¾“å‡º
                technical_analysis['ma20'] = ma20
                technical_analysis['ma50'] = ma50
                try:
                    technical_analysis['price_vs_ma20_pct'] = float((latest - ma20) / ma20 * 100.0) if ma20 else 0.0
                except Exception:
                    technical_analysis['price_vs_ma20_pct'] = 0.0
                try:
                    technical_analysis['price_vs_ma50_pct'] = float((latest - ma50) / ma50 * 100.0) if ma50 else 0.0
                except Exception:
                    technical_analysis['price_vs_ma50_pct'] = 0.0
                try:
                    technical_analysis['ma_slope50'] = float(price_data['ma50'].diff().iloc[-1]) if len(price_data) >= 2 else 0.0
                except Exception:
                    technical_analysis['ma_slope50'] = 0.0
                ma20_series = price_data['ma20']
                close_series = close
            except Exception:
                technical_analysis['ma_trend'] = 'è®¡ç®—å¤±è´¥'

            # RSI (Wilder) 14
            try:
                delta = close.diff()
                gain = delta.clip(lower=0)
                loss = -delta.clip(upper=0)
                window = 14
                avg_gain = gain.ewm(alpha=1/window, adjust=False, min_periods=window).mean()
                avg_loss = loss.ewm(alpha=1/window, adjust=False, min_periods=window).mean()
                rs = avg_gain / avg_loss.replace(0, np.nan)
                rsi = 100 - (100 / (1 + rs))
                rsi_series = rsi
                rsi_val = float(rsi.iloc[-1]) if np.isfinite(rsi.iloc[-1]) else 50.0
                technical_analysis['rsi'] = rsi_val
            except Exception:
                technical_analysis['rsi'] = 50.0

            # MACD with confirmation
            try:
                ema12 = close.ewm(span=12, adjust=False, min_periods=12).mean()
                ema26 = close.ewm(span=26, adjust=False, min_periods=26).mean()
                macd_line = ema12 - ema26
                signal_line = macd_line.ewm(span=9, adjust=False, min_periods=9).mean()
                hist = macd_line - signal_line
                macd_hist_series = hist
                macd_line_series = macd_line
                signal_line_series = signal_line

                macd_signal = 'æ•°æ®ä¸è¶³'
                if len(hist) >= 3:
                    last = float(hist.iloc[-1])
                    prev = float(hist.iloc[-2])
                    prev2 = float(hist.iloc[-3])
                    cross_up = (macd_line.iloc[-2] < signal_line.iloc[-2]) and (macd_line.iloc[-1] > signal_line.iloc[-1])
                    cross_down = (macd_line.iloc[-2] > signal_line.iloc[-2]) and (macd_line.iloc[-1] < signal_line.iloc[-1])
                    trend_up = last > prev > prev2
                    trend_down = last < prev < prev2

                    if (cross_up or trend_up) and last > 0:
                        macd_signal = 'é‡‘å‰å‘ä¸Š'
                    elif (cross_down or trend_down) and last < 0:
                        macd_signal = 'æ­»å‰å‘ä¸‹'
                    else:
                        macd_signal = 'æ¨ªç›˜æ•´ç†'

                technical_analysis['macd_signal'] = macd_signal
            except Exception:
                technical_analysis['macd_signal'] = 'è®¡ç®—å¤±è´¥'

            # å¸ƒæ—å¸¦ä½ç½®ä¸å¸¦å®½
            try:
                bb_window = min(20, len(close))
                mid = close.rolling(bb_window, min_periods=1).mean()
                std = close.rolling(bb_window, min_periods=1).std()
                upper = mid + 2*std
                lower = mid - 2*std
                last_close = float(close.iloc[-1])
                u = float(upper.iloc[-1])
                l = float(lower.iloc[-1])
                if u != l:
                    pos = (last_close - l) / (u - l)
                else:
                    pos = 0.5
                technical_analysis['bb_position'] = float(pos)
                technical_analysis['bb_width'] = float(self._safe_ratio(u - l, mid.iloc[-1], default=0.0))
            except Exception:
                technical_analysis['bb_position'] = 0.5
                technical_analysis['bb_width'] = 0.0

            # æˆäº¤é‡ä¸é‡èƒ½ç¡®è®¤
            try:
                vol_ma20 = volume.rolling(window=min(20, len(volume)), min_periods=1).mean()
                vol_ratio = float(self._safe_ratio(volume.iloc[-1], vol_ma20.iloc[-1], default=1.0)) if len(volume) else 1.0
                technical_analysis['volume_ratio'] = vol_ratio

                # ä»·æ ¼å˜åŠ¨ç™¾åˆ†æ¯”
                if 'change_pct' in price_data.columns and not pd.isna(price_data['change_pct'].iloc[-1]):
                    price_change = float(price_data['change_pct'].iloc[-1])
                elif len(close) >= 2 and close.iloc[-2] > 0:
                    price_change = float((close.iloc[-1] - close.iloc[-2]) / close.iloc[-2] * 100)
                else:
                    price_change = 0.0

                if vol_ratio > 1.5:
                    technical_analysis['volume_status'] = 'æ”¾é‡ä¸Šæ¶¨' if price_change > 0 else 'æ”¾é‡ä¸‹è·Œ'
                elif vol_ratio < 0.6:
                    technical_analysis['volume_status'] = 'ç¼©é‡è°ƒæ•´'
                else:
                    technical_analysis['volume_status'] = 'æ¸©å’Œæ”¾é‡'
            except Exception:
                technical_analysis['volume_status'] = 'æ•°æ®ä¸è¶³'
                technical_analysis['volume_ratio'] = 1.0

            # æ¢æ‰‹ç‡ï¼ˆå¦‚æœ‰ï¼‰
            try:
                if 'turnover_rate' in price_data.columns:
                    tr_series = pd.to_numeric(price_data['turnover_rate'], errors='coerce')
                    if len(tr_series.dropna()):
                        technical_analysis['turnover_rate'] = float(tr_series.iloc[-1])
                        tr_ma20 = tr_series.rolling(window=min(20, len(tr_series)), min_periods=1).mean().iloc[-1]
                        technical_analysis['turnover_rate_ma20'] = float(tr_ma20)
                        technical_analysis['turnover_rate_ratio'] = float(self._safe_ratio(tr_series.iloc[-1], tr_ma20, default=1.0))
            except Exception:
                pass

            # ATR(14) æ³¢åŠ¨ç‡
            try:
                prev_close = close.shift(1)
                tr = pd.concat([
                    (high - low).abs(),
                    (high - prev_close).abs(),
                    (low - prev_close).abs()
                ], axis=1).max(axis=1)
                atr = tr.ewm(alpha=1/14, adjust=False, min_periods=14).mean()
                atr_pct = float(self._safe_ratio(atr.iloc[-1], close.iloc[-1], default=0.0) * 100.0) if len(atr) else 0.0
                technical_analysis['atr_pct'] = atr_pct
            except Exception:
                technical_analysis['atr_pct'] = 0.0

            # é™„åŠ ç”¨äºå¤šæ—¥ç¡®è®¤çš„åºåˆ—å°¾éƒ¨ç‰‡æ®µï¼ˆæœ€å¤š10æ ¹Kçº¿ï¼‰
            try:
                tail_len = 10
                series_tail = {}
                if rsi_series is not None and len(rsi_series.dropna()) >= 1:
                    series_tail['rsi'] = [float(x) if np.isfinite(x) else 50.0 for x in rsi_series.tail(tail_len).tolist()]
                if macd_hist_series is not None and len(macd_hist_series.dropna()) >= 1:
                    series_tail['macd_hist'] = [float(x) if np.isfinite(x) else 0.0 for x in macd_hist_series.tail(tail_len).tolist()]
                if macd_line_series is not None and len(macd_line_series.dropna()) >= 1:
                    series_tail['macd_line'] = [float(x) if np.isfinite(x) else 0.0 for x in macd_line_series.tail(tail_len).tolist()]
                if signal_line_series is not None and len(signal_line_series.dropna()) >= 1:
                    series_tail['signal_line'] = [float(x) if np.isfinite(x) else 0.0 for x in signal_line_series.tail(tail_len).tolist()]
                if ma20_series is not None and len(ma20_series.dropna()) >= 1:
                    series_tail['ma20'] = [float(x) if np.isfinite(x) else 0.0 for x in ma20_series.tail(tail_len).tolist()]
                if close_series is not None and len(close_series.dropna()) >= 1:
                    series_tail['close'] = [float(x) if np.isfinite(x) else 0.0 for x in close_series.tail(tail_len).tolist()]
                if series_tail:
                    technical_analysis['series'] = series_tail
            except Exception:
                pass

            return technical_analysis

        except Exception as e:
            self.logger.error(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
            return self._get_default_technical_analysis()

    def _get_default_technical_analysis(self):
        """è·å–é»˜è®¤æŠ€æœ¯åˆ†æç»“æœ"""
        # æ£€æŸ¥å¸‚åœºçŠ¶æ€
        market_open, market_status = check_market_status()
        
        if not market_open:
            return {
                'ma_trend': market_status,
                'rsi': 50.0,
                'macd_signal': market_status,
                'bb_position': 0.5,
                'volume_status': market_status
            }
        else:
            return {
                'ma_trend': 'è®¡ç®—ä¸­...',
                'rsi': 50.0,
                'macd_signal': 'è®¡ç®—ä¸­...',
                'bb_position': 0.5,
                'volume_status': 'è®¡ç®—ä¸­...'
            }

    def calculate_technical_score(self, technical_analysis, confirm_days: Optional[int] = None):
        """è®¡ç®—æŠ€æœ¯åˆ†æå¾—åˆ†ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        try:
            score = 50.0

            # è¯»å–é˜ˆå€¼
            rsi_ob = float(self.thresholds.get('rsi_overbought', 70.0))
            rsi_os = float(self.thresholds.get('rsi_oversold', 30.0))
            rsi_nl = float(self.thresholds.get('rsi_neutral_low', 45.0))
            rsi_nh = float(self.thresholds.get('rsi_neutral_high', 65.0))
            bb_lo = float(self.thresholds.get('bb_lower', 0.2))
            bb_hi = float(self.thresholds.get('bb_upper', 0.8))
            vr_low = float(self.thresholds.get('volume_ratio_low', 0.6))
            vr_high = float(self.thresholds.get('volume_ratio_high', 1.5))
            vr_vlow = float(self.thresholds.get('volume_ratio_very_low', 0.7))
            vr_vhigh = float(self.thresholds.get('volume_ratio_very_high', 2.0))
            atr_hi = float(self.thresholds.get('atr_high_risk', 6.0))
            atr_low = float(self.thresholds.get('atr_low_vol', 2.0))

            n_confirm = int(confirm_days if confirm_days is not None else self.thresholds.get('confirm_days', 1))
            n_confirm = max(1, min(10, n_confirm))

            series = technical_analysis.get('series', {}) or {}
            rsi_series = series.get('rsi') or []
            macd_hist = series.get('macd_hist') or []
            macd_line = series.get('macd_line') or []
            signal_line = series.get('signal_line') or []
            ma20 = series.get('ma20') or []
            close = series.get('close') or []

            def last_n_all(pred_arr, predicate):
                try:
                    arr = list(pred_arr)[-n_confirm:]
                    return len(arr) >= n_confirm and all(predicate(x) for x in arr)
                except Exception:
                    return False

            # å‡çº¿è¶‹åŠ¿è¯„åˆ†ï¼ˆå«å¤šæ—¥ç¡®è®¤ï¼šæ”¶ç›˜ä»·è¿ç»­é«˜äºMA20ï¼Œå¹¶ä¸”MA20å‘ä¸Š/å‘ä¸‹ï¼‰
            ma_trend = technical_analysis.get('ma_trend', 'æ•°æ®ä¸è¶³')
            if ma_trend == 'å¤šå¤´æ’åˆ—':
                confirmed_ma = False
                if n_confirm > 1 and close and ma20 and len(close) >= n_confirm and len(ma20) >= n_confirm:
                    above = [c > m for c, m in zip(close[-n_confirm:], ma20[-n_confirm:])]
                    slope_up = all((ma20[i] - ma20[i-1]) >= 0 for i in range(1, min(len(ma20), n_confirm)))
                    confirmed_ma = all(above) and slope_up
                score += 18 if (n_confirm == 1 or confirmed_ma) else 12
            elif ma_trend == 'ç©ºå¤´æ’åˆ—':
                confirmed_ma = False
                if n_confirm > 1 and close and ma20 and len(close) >= n_confirm and len(ma20) >= n_confirm:
                    below = [c < m for c, m in zip(close[-n_confirm:], ma20[-n_confirm:])]
                    slope_down = all((ma20[i] - ma20[i-1]) <= 0 for i in range(1, min(len(ma20), n_confirm)))
                    confirmed_ma = all(below) and slope_down
                score -= 18 if (n_confirm == 1 or confirmed_ma) else 12

            # RSIè¯„åˆ†ï¼ˆç”¨é˜ˆå€¼ï¼‰
            rsi_val = float(technical_analysis.get('rsi', 50))
            if rsi_nl <= rsi_val <= rsi_nh:
                if n_confirm > 1 and rsi_series:
                    in_band = last_n_all(rsi_series, lambda v: rsi_nl <= float(v) <= rsi_nh)
                    score += 8 if in_band else 4
                else:
                    score += 8
            elif rsi_os <= rsi_val < rsi_nl:
                score += 4
            elif rsi_nh < rsi_val <= rsi_ob + 5:
                score -= 3
            elif rsi_val < rsi_os:
                score += 6  # è¶…å–åå¼¹æ½œåŠ›
            elif rsi_val > rsi_ob + 5:
                score -= 8  # è¶…ä¹°é£é™©

            # MACDè¯„åˆ†ï¼ˆå¤šæ—¥ç¡®è®¤ï¼šç›´æ–¹å›¾æŒç»­èµ°é«˜/èµ°ä½ï¼Œä¸”å½“å‰åœ¨é›¶è½´ä¹‹ä¸Š/ä¹‹ä¸‹ï¼‰
            macd_signal = technical_analysis.get('macd_signal', 'æ¨ªç›˜æ•´ç†')
            if macd_signal == 'é‡‘å‰å‘ä¸Š':
                if n_confirm > 1 and macd_hist and macd_line and signal_line:
                    arr_h = macd_hist[-n_confirm:]
                    arr_m = macd_line[-n_confirm:]
                    arr_s = signal_line[-n_confirm:]
                    inc = all(arr_h[i] >= arr_h[i-1] for i in range(1, len(arr_h)))
                    above = (arr_m[-1] > arr_s[-1]) and (arr_h[-1] > 0)
                    score += 14 if (inc and above) else 8
                else:
                    score += 14
            elif macd_signal == 'æ­»å‰å‘ä¸‹':
                if n_confirm > 1 and macd_hist and macd_line and signal_line:
                    arr_h = macd_hist[-n_confirm:]
                    arr_m = macd_line[-n_confirm:]
                    arr_s = signal_line[-n_confirm:]
                    dec = all(arr_h[i] <= arr_h[i-1] for i in range(1, len(arr_h)))
                    below = (arr_m[-1] < arr_s[-1]) and (arr_h[-1] < 0)
                    score -= 14 if (dec and below) else 8
                else:
                    score -= 14

            # å¸ƒæ—å¸¦ä½ç½®è¯„åˆ†ï¼ˆç”¨é˜ˆå€¼ï¼‰
            bb_position = float(technical_analysis.get('bb_position', 0.5))
            if (bb_lo + 0.05) <= bb_position <= (bb_hi - 0.05):
                score += 4
            elif bb_position < bb_lo:
                score += 7  # ä¸‹è½¨é™„è¿‘ï¼Œåå¼¹æ½œåŠ›
            elif bb_position > (bb_hi + 0.05):
                score -= 6  # ä¸Šè½¨é™„è¿‘ï¼Œå›è½é£é™©

            # æˆäº¤é‡çŠ¶æ€ä¸é‡èƒ½æ•°å€¼åŒ–
            volume_status = technical_analysis.get('volume_status', 'æ•°æ®ä¸è¶³')
            if 'æ”¾é‡ä¸Šæ¶¨' in volume_status:
                score += 10
            elif 'æ”¾é‡ä¸‹è·Œ' in volume_status:
                score -= 10

            vol_ratio = float(technical_analysis.get('volume_ratio', 1.0))
            if vol_ratio > vr_vhigh:
                score += 4
            elif vol_ratio < vr_vlow:
                score -= 3

            # æ³¢åŠ¨ç‡ï¼ˆATR%ï¼‰
            atr_pct = float(technical_analysis.get('atr_pct', 0.0))
            if atr_pct > atr_hi:
                score -= 6  # æ³¢åŠ¨è¿‡å¤§
            elif atr_pct < atr_low and ma_trend == 'å¤šå¤´æ’åˆ—':
                score += 3  # ç¨³å®šä¸Šè¡Œ

            score = float(max(0.0, min(100.0, score)))
            return score

        except Exception as e:
            self.logger.error(f"æŠ€æœ¯åˆ†æè¯„åˆ†å¤±è´¥: {str(e)}")
            return 50.0

    def calculate_fundamental_score(self, fundamental_data):
        """è®¡ç®—åŸºæœ¬é¢å¾—åˆ†ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        try:
            score = 50.0

            fi = fundamental_data.get('financial_indicators', {}) or {}
            count = len(fi)
            if count >= 15:
                score += 18
            elif count >= 8:
                score += 8

            # ç›ˆåˆ©èƒ½åŠ›ï¼šROE
            roe = float(fi.get('å‡€èµ„äº§æ”¶ç›Šç‡', 0) or 0)
            if roe > 20:
                score += 12
            elif roe > 15:
                score += 8
            elif roe > 10:
                score += 4
            elif roe < 5:
                score -= 4

            # å¿å€ºèƒ½åŠ›ï¼šèµ„äº§è´Ÿå€ºç‡ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
            debt_ratio = float(fi.get('èµ„äº§è´Ÿå€ºç‡', 50) or 50)
            if debt_ratio < 30:
                score += 6
            elif debt_ratio > 70:
                score -= 8

            # æˆé•¿æ€§ï¼šè¥æ”¶/å‡€åˆ©å¢é€Ÿ
            rev_g = float(fi.get('è¥æ”¶åŒæ¯”å¢é•¿ç‡', 0) or 0)
            np_g = float(fi.get('å‡€åˆ©æ¶¦åŒæ¯”å¢é•¿ç‡', 0) or 0)
            if rev_g > 20:
                score += 6
            elif rev_g > 10:
                score += 3
            elif rev_g < -10:
                score -= 6

            if np_g > 25:
                score += 6
            elif np_g > 10:
                score += 3
            elif np_g < -10:
                score -= 8

            # ä¼°å€¼ï¼šPEã€PBï¼ˆè¶Šä½è¶Šå¥½ï¼Œè¡Œä¸šå·®å¼‚å¿½ç•¥ï¼Œç»™åŒºé—´åˆ†ï¼‰
            val = fundamental_data.get('valuation', {}) or {}
            try:
                pe = float(val.get('å¸‚ç›ˆç‡', 0) or 0)
            except Exception:
                pe = 0
            try:
                pb = float(val.get('å¸‚å‡€ç‡', 0) or 0)
            except Exception:
                pb = 0
            try:
                dy = float(val.get('è‚¡æ¯æ”¶ç›Šç‡', 0) or 0)
            except Exception:
                dy = 0

            if 0 < pe <= 15:
                score += 6
            elif 15 < pe <= 30:
                score += 2
            elif pe > 60:
                score -= 8

            if 0 < pb <= 2:
                score += 4
            elif pb > 5:
                score -= 6

            if dy >= 3:
                score += 4

            # ä¸šç»©é¢„å‘Šï¼šæ­£å‘æªè¾åŠ åˆ†
            forecasts = fundamental_data.get('performance_forecast', []) or []
            positive_kw = ['é¢„å¢','ä¸Šè°ƒ','è¶…é¢„æœŸ','æ‰­äº','å¢é•¿','æ”¹å–„']
            negative_kw = ['é¢„å‡','ä¸‹è°ƒ','ä½äºé¢„æœŸ','äºæŸ','æ¶åŒ–']
            pos_hit = 0
            neg_hit = 0
            for f in forecasts[:10]:
                text = ' '.join([str(v) for v in (f.values() if isinstance(f, dict) else [f])])
                if any(k in text for k in positive_kw):
                    pos_hit += 1
                if any(k in text for k in negative_kw):
                    neg_hit += 1
            score += min(10, pos_hit * 2)
            score -= min(10, neg_hit * 2)

            score = float(max(0.0, min(100.0, score)))
            return score

        except Exception as e:
            self.logger.error(f"åŸºæœ¬é¢è¯„åˆ†å¤±è´¥: {str(e)}")
            return 50.0

    def calculate_sentiment_score(self, sentiment_analysis):
        """è®¡ç®—æƒ…ç»ªåˆ†æå¾—åˆ†"""
        try:
            overall_sentiment = sentiment_analysis.get('overall_sentiment', 0.0)
            confidence_score = sentiment_analysis.get('confidence_score', 0.0)
            total_analyzed = sentiment_analysis.get('total_analyzed', 0)
            
            # åŸºç¡€å¾—åˆ†ï¼šå°†æƒ…ç»ªå¾—åˆ†ä»[-1,1]æ˜ å°„åˆ°[0,100]
            base_score = (overall_sentiment + 1) * 50
            
            # ç½®ä¿¡åº¦è°ƒæ•´
            confidence_adjustment = confidence_score * 10
            
            # æ–°é—»æ•°é‡è°ƒæ•´
            news_adjustment = min(total_analyzed / 100, 1.0) * 10
            
            final_score = base_score + confidence_adjustment + news_adjustment
            final_score = max(0, min(100, final_score))
            
            return final_score
            
        except Exception as e:
            self.logger.error(f"æƒ…ç»ªå¾—åˆ†è®¡ç®—å¤±è´¥: {e}")
            return 50

    def calculate_comprehensive_score(self, scores):
        """è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆåŠ¨æ€æƒé‡ï¼‰"""
        try:
            t = float(scores.get('technical', 50.0))
            f = float(scores.get('fundamental', 50.0))
            s = float(scores.get('sentiment', 50.0))

            # ç»Ÿä¸€ä½¿ç”¨ self.weightsï¼ˆæ„é€ å™¨å¯è¦†ç›–ï¼‰ï¼Œå‘åå…¼å®¹ self.analysis_weights
            base_w = (getattr(self, 'weights', None) or self.analysis_weights).copy()
            # åŠ¨æ€ç¼©æ”¾ï¼šä¾æ®æœ€è¿‘ä¸€æ¬¡æ•°æ®è´¨é‡
            dq = getattr(self, '_last_data_quality', {}) or {}
            fi_count = float(dq.get('financial_indicators_count', 0) or 0)
            news_count = float(dq.get('total_news_count', dq.get('news_count', 0)) or 0)
            s_conf = float(dq.get('sentiment_confidence', dq.get('confidence_score', 0.0)) or 0.0)

            f_scale = 0.6 + min(1.0, fi_count / 15.0) * 0.6  # 0.6~1.2
            s_scale = 0.6 + min(1.0, news_count / 60.0) * 0.3 + min(1.0, s_conf) * 0.3  # 0.6~1.2
            t_scale = 1.0  # æŠ€æœ¯é¢ä¿æŒåŸºå‡†

            w_t = base_w.get('technical', 0.4) * t_scale
            w_f = base_w.get('fundamental', 0.4) * f_scale
            w_s = base_w.get('sentiment', 0.2) * s_scale

            w_sum = w_t + w_f + w_s
            if w_sum <= 0:
                w_t, w_f, w_s = 0.4, 0.4, 0.2
                w_sum = 1.0

            w_t, w_f, w_s = w_t / w_sum, w_f / w_sum, w_s / w_sum

            composite = t * w_t + f * w_f + s * w_s
            return float(max(0.0, min(100.0, composite)))

        except Exception as e:
            self.logger.error(f"è®¡ç®—ç»¼åˆå¾—åˆ†å¤±è´¥: {e}")
            return 50.0

    def get_stock_name(self, stock_code):
        """è·å–è‚¡ç¥¨åç§°"""
        try:
            import akshare as ak
            
            try:
                stock_info = ak.stock_individual_info_em(symbol=stock_code)
                if not stock_info.empty:
                    info_dict = dict(zip(stock_info['item'], stock_info['value']))
                    stock_name = info_dict.get('è‚¡ç¥¨ç®€ç§°', stock_code)
                    if stock_name and stock_name != stock_code:
                        return stock_name
            except Exception as e:
                self.logger.warning(f"è·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")
            
            return stock_code
            
        except Exception as e:
            self.logger.warning(f"è·å–è‚¡ç¥¨åç§°æ—¶å‡ºé”™: {e}")
            return stock_code

    def get_price_info(self, price_data):
        """ä»ä»·æ ¼æ•°æ®ä¸­æå–å…³é”®ä¿¡æ¯ - ä¿®å¤ç‰ˆæœ¬"""
        try:
            if price_data.empty or 'close' not in price_data.columns:
                self.logger.warning("ä»·æ ¼æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘æ”¶ç›˜ä»·åˆ—")
                return {
                    'current_price': 0.0,
                    'price_change': 0.0,
                    'volume_ratio': 1.0,
                    'volatility': 0.0
                }
            
            # è·å–æœ€æ–°æ•°æ®
            latest = price_data.iloc[-1]
            
            # ç¡®ä¿ä½¿ç”¨æ”¶ç›˜ä»·ä½œä¸ºå½“å‰ä»·æ ¼
            current_price = float(latest['close'])
            self.logger.info(f"âœ“ å½“å‰ä»·æ ¼(æ”¶ç›˜ä»·): {current_price}")
            # ç¼“å­˜æœ€è¿‘ä»·æ ¼
            try:
                self._last_price = float(current_price)
            except Exception:
                self._last_price = None

            # å¦‚æœæ”¶ç›˜ä»·å¼‚å¸¸ï¼Œå°è¯•ä½¿ç”¨å…¶ä»–ä»·æ ¼
            if pd.isna(current_price) or current_price <= 0:
                if 'open' in price_data.columns and not pd.isna(latest['open']) and latest['open'] > 0:
                    current_price = float(latest['open'])
                    self.logger.warning(f"âš ï¸ æ”¶ç›˜ä»·å¼‚å¸¸ï¼Œä½¿ç”¨å¼€ç›˜ä»·: {current_price}")
                elif 'high' in price_data.columns and not pd.isna(latest['high']) and latest['high'] > 0:
                    current_price = float(latest['high'])
                    self.logger.warning(f"âš ï¸ æ”¶ç›˜ä»·å¼‚å¸¸ï¼Œä½¿ç”¨æœ€é«˜ä»·: {current_price}")
                else:
                    self.logger.error(f"âŒ æ‰€æœ‰ä»·æ ¼æ•°æ®éƒ½å¼‚å¸¸")
                    return {
                        'current_price': 0.0,
                        'price_change': 0.0,
                        'volume_ratio': 1.0,
                        'volatility': 0.0
                    }
            
            # è®¡ç®—ä»·æ ¼å˜åŒ–
            price_change = 0.0
            try:
                if 'change_pct' in price_data.columns and not pd.isna(latest['change_pct']):
                    price_change = float(latest['change_pct'])
                    self.logger.info(f"âœ“ ä½¿ç”¨ç°æˆçš„æ¶¨è·Œå¹…: {price_change}%")
                elif len(price_data) > 1:
                    prev = price_data.iloc[-2]
                    prev_price = float(prev['close'])
                    if prev_price > 0 and not pd.isna(prev_price):
                        price_change = ((current_price - prev_price) / prev_price * 100)
                        self.logger.info(f"âœ“ è®¡ç®—æ¶¨è·Œå¹…: {price_change}%")
            except Exception as e:
                self.logger.warning(f"è®¡ç®—ä»·æ ¼å˜åŒ–å¤±è´¥: {e}")
                price_change = 0.0
            
            # è®¡ç®—æˆäº¤é‡æ¯”ç‡
            volume_ratio = 1.0
            try:
                if 'volume' in price_data.columns:
                    volume_data = price_data['volume'].dropna()
                    if len(volume_data) >= 5:
                        recent_volume = volume_data.tail(5).mean()
                        avg_volume = volume_data.mean()
                        if avg_volume > 0:
                            volume_ratio = recent_volume / avg_volume
            except Exception as e:
                self.logger.warning(f"è®¡ç®—æˆäº¤é‡æ¯”ç‡å¤±è´¥: {e}")
                volume_ratio = 1.0
            
            # è®¡ç®—æ³¢åŠ¨ç‡
            volatility = 0.0
            try:
                close_prices = price_data['close'].dropna()
                if len(close_prices) >= 20:
                    returns = close_prices.pct_change().dropna()
                    if len(returns) >= 20:
                        volatility = returns.tail(20).std() * 100
            except Exception as e:
                self.logger.warning(f"è®¡ç®—æ³¢åŠ¨ç‡å¤±è´¥: {e}")
                volatility = 0.0
            
            result = {
                'current_price': current_price,
                'price_change': price_change,
                'volume_ratio': volume_ratio,
                'volatility': volatility
            }
            
            self.logger.info(f"âœ“ ä»·æ ¼ä¿¡æ¯æå–å®Œæˆ: {result}")
            return result
            
        except Exception as e:
            self.logger.error(f"è·å–ä»·æ ¼ä¿¡æ¯å¤±è´¥: {e}")
            return {
                'current_price': 0.0,
                'price_change': 0.0,
                'volume_ratio': 1.0,
                'volatility': 0.0
            }

    def generate_recommendation(self, scores):
        """æ ¹æ®å¾—åˆ†ç”ŸæˆæŠ•èµ„å»ºè®®"""
        try:
            comprehensive_score = scores.get('comprehensive', 50)
            technical_score = scores.get('technical', 50)
            fundamental_score = scores.get('fundamental', 50)
            sentiment_score = scores.get('sentiment', 50)
            
            if comprehensive_score >= 80:
                if technical_score >= 75 and fundamental_score >= 75:
                    return "å¼ºçƒˆæ¨èä¹°å…¥"
                else:
                    return "æ¨èä¹°å…¥"
            elif comprehensive_score >= 65:
                if sentiment_score >= 60:
                    return "å»ºè®®ä¹°å…¥"
                else:
                    return "è°¨æ…ä¹°å…¥"
            elif comprehensive_score >= 45:
                return "æŒæœ‰è§‚æœ›"
            elif comprehensive_score >= 30:
                return "å»ºè®®å‡ä»“"
            else:
                return "å»ºè®®å–å‡º"
                
        except Exception as e:
            self.logger.warning(f"ç”ŸæˆæŠ•èµ„å»ºè®®å¤±è´¥: {e}")
            return "æ•°æ®ä¸è¶³ï¼Œå»ºè®®è°¨æ…"

    def _get_stock_snapshot_with_retry(self, max_retries: int = 3) -> pd.DataFrame:
        """è·å–Aè‚¡å¿«ç…§æ•°æ®ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        try:
            import akshare as ak
        except Exception:
            self.logger.warning("âš ï¸ akshare æœªå®‰è£…ï¼Œæ— æ³•è·å–åœ¨çº¿å¿«ç…§")
            return pd.DataFrame()
        
        for attempt in range(max_retries):
            try:
                self.logger.info(f"ğŸ“Š æ­£åœ¨è·å–Aè‚¡å®æ—¶å¿«ç…§ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰...")
                spot = ak.stock_zh_a_spot_em()
                if spot is not None and not spot.empty:
                    self.logger.info(f"âœ… æˆåŠŸè·å–Aè‚¡å¿«ç…§ï¼Œå…± {len(spot)} åªè‚¡ç¥¨")
                    try:
                        self._save_spot_snapshot_cache(spot)
                    except Exception as e:
                        self.logger.debug(f"ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
                    return spot
            except Exception as e:
                self.logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {str(e)[:100]}")
                if attempt < max_retries - 1:
                    import time
                    time.sleep(1 * (attempt + 1))  # é€’å¢ç­‰å¾…æ—¶é—´
        
        self.logger.warning("âš ï¸ åœ¨çº¿å¿«ç…§è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°ç¼“å­˜")
        return pd.DataFrame()

    def get_quick_recommendations(self, top_n: int = 20, min_mktcap_e: float = 30.0, exclude_st: bool = True) -> List[Dict]:
        """åŸºäºå¿«ç…§çš„è½»é‡çº§æ¨èåˆ—è¡¨ï¼ˆä¸æ‹‰å–é€è‚¡æ·±åº¦æ•°æ®ï¼Œç§’çº§è¿”å›ï¼‰ã€‚

        è¿”å›æ¯é¡¹ç¤ºä¾‹ï¼š
        {
          'stock_code': '000001', 'stock_name': 'å¹³å®‰é“¶è¡Œ',
          'latest_price': 12.34, 'change_pct': 1.23,
          'pe': 8.9, 'mktcap_e': 1500.0,  # äº¿
          'score': 87.5, 'recommendation': 'å»ºè®®ä¹°å…¥'
        }
        """
        # è·å–å¿«ç…§æ•°æ®ï¼ˆå¸¦é‡è¯•ï¼‰
        spot = self._get_stock_snapshot_with_retry(max_retries=3)
        
        # å¦‚æœåœ¨çº¿å¤±è´¥ï¼Œå°è¯•æœ¬åœ°ç¼“å­˜
        if (spot is None) or spot.empty:
            self.logger.info("ğŸ“‚ å°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½å¿«ç…§æ•°æ®...")
            spot = self._load_spot_snapshot_cache()
            if spot is not None and not spot.empty:
                self.logger.info(f"âœ… æˆåŠŸä»ç¼“å­˜åŠ è½½ {len(spot)} åªè‚¡ç¥¨æ•°æ®")
        
        # å¦‚æœä»ç„¶å¤±è´¥ï¼Œä½¿ç”¨ç¦»çº¿å…œåº•
        if spot is None or spot.empty:
            # ç¦»çº¿å…œåº•ï¼šä½¿ç”¨BaoStockå†å²Kçº¿åšå¿«é€Ÿå€™é€‰ï¼ˆæ— PE/å¸‚å€¼è¿‡æ»¤ï¼‰
            self.logger.warning("æ— æ³•è·å–Aè‚¡å¿«ç…§ï¼Œè¿›å…¥ç¦»çº¿å…œåº•æ¨¡å¼(åŸºäºBaoStockä»·æ ¼æ•°æ®)")
            try:
                fallback_rows = self._quick_recommendations_offline_via_price(top_n=max(5, int(top_n)), exclude_st=exclude_st)
                if fallback_rows:
                    self.logger.info(f"âœ“ ç¦»çº¿å…œåº•ç”Ÿæˆ {len(fallback_rows)} æ¡æ¨èï¼ˆåŸºäºè¿‘ç«¯åŠ¨é‡/æ³¢åŠ¨ï¼‰")
                    return fallback_rows
            except Exception as e:
                self.logger.warning(f"ç¦»çº¿å…œåº•å¤±è´¥: {e}")
            return []

        df = spot.copy()

        # åˆ—åé€‰æ‹©å™¨
        def pick_col(cands: List[str]) -> Optional[str]:
            for c in cands:
                if c in df.columns:
                    return c
            return None

        code_col = pick_col(['ä»£ç ','è‚¡ç¥¨ä»£ç ','è¯åˆ¸ä»£ç ','Aè‚¡ä»£ç ','code']) or df.columns[0]
        name_col = pick_col(['åç§°','è‚¡ç¥¨ç®€ç§°','ç®€ç§°','name']) or (df.columns[1] if len(df.columns) > 1 else code_col)
        pct_col  = pick_col(['æ¶¨è·Œå¹…','æ¶¨è·Œå¹…(%)','æ¶¨è·Œå¹…%','pct_chg'])
        price_col= pick_col(['æœ€æ–°ä»·','ç°ä»·','ä»·æ ¼','æœ€æ–°'])
        pe_col   = pick_col(['å¸‚ç›ˆç‡-åŠ¨æ€','å¸‚ç›ˆç‡TTM','å¸‚ç›ˆç‡'])
        mcap_col = pick_col(['æ€»å¸‚å€¼(äº¿)','æ€»å¸‚å€¼'])

        def to_float(x) -> Optional[float]:
            try:
                if isinstance(x, str):
                    xs = x.strip().replace(',', '')
                    if xs.endswith('%'):
                        return float(xs.rstrip('%'))
                    return float(xs)
                return float(x)
            except Exception:
                return None

        # é¢„å¤„ç†å¹¶è¿‡æ»¤
        out_rows = []
        for _, r in df.iterrows():
            try:
                code = str(r.get(code_col, '')).strip() if code_col else ''
                if not code or len(code) < 6:
                    continue
                code = code[-6:]  # ç»Ÿä¸€6ä½
                name = str(r.get(name_col, code)) if name_col else code
                if exclude_st and any(x in str(name) for x in ['ST','*ST','é€€']):
                    continue

                # å¸‚å€¼ï¼ˆäº¿ï¼‰
                mktcap_e = to_float(r.get(mcap_col)) if mcap_col else None
                # è‹¥åˆ—ä¸ºâ€œæ€»å¸‚å€¼â€ä¸”é‡çº§è¾ƒå¤§ï¼Œå°è¯•æŒ‰å…ƒ -> äº¿è½¬æ¢
                if mktcap_e is not None and mcap_col == 'æ€»å¸‚å€¼' and mktcap_e > 1e9:
                    mktcap_e = mktcap_e / 1e8
                if (mktcap_e is None) or (mktcap_e < min_mktcap_e):
                    continue

                # PE
                pe = to_float(r.get(pe_col)) if pe_col else None
                if pe is None or pe <= 0 or pe > 1200:  # æ’é™¤å¼‚å¸¸å€¼
                    continue

                # æ¶¨è·Œå¹…ï¼ˆ%ï¼‰
                chg = to_float(r.get(pct_col)) if pct_col else None
                if chg is None:
                    chg = 0.0

                # ä»·æ ¼
                price = to_float(r.get(price_col)) if price_col else None
                if price is None or price <= 0:
                    price = 0.0

                # è¯„åˆ†æ„é€ ï¼šåŠ¨é‡(å½“æ—¥æ¶¨è·Œ) + ä¼°å€¼(ä½PE) + ä½“é‡ï¼ˆé€‚ä¸­å¸‚å€¼ï¼‰
                # åŠ¨é‡ï¼š-5%~+5%çº¿æ€§æ˜ å°„åˆ°[0,1]
                mom = max(0.0, min(1.0, (float(chg) + 5.0) / 10.0))
                # ä¼°å€¼ï¼š0~80 æ˜ å°„ï¼Œè¶Šä½è¶Šå¥½
                pe_eff = max(0.0, min(120.0, float(pe)))
                pe_score = max(0.0, min(1.0, (80.0 - pe_eff) / 80.0))
                # å¸‚å€¼ï¼šåå¥½ 80~300 äº¿
                x = float(mktcap_e)
                if x <= 30:
                    mcap_score = 0.2
                elif x <= 80:
                    mcap_score = 0.6 + (x - 80.0) / 50.0 * 0.4  # å‘80é æ‹¢
                elif x <= 300:
                    mcap_score = 1.0 - abs((x - 190.0) / 110.0) * 0.4  # 190é™„è¿‘æœ€ä½³
                elif x <= 800:
                    mcap_score = 0.8 - (x - 300.0) / 500.0 * 0.6
                else:
                    mcap_score = 0.2
                mcap_score = max(0.0, min(1.0, mcap_score))

                score01 = 0.45 * mom + 0.35 * pe_score + 0.20 * mcap_score
                score = float(round(score01 * 100.0, 2))

                # å¿«é€Ÿå»ºè®®ï¼ˆå ä½ï¼šç”¨æ„é€ åˆ†æ•°æ˜ å°„ï¼‰
                quick_scores = {
                    'technical': mom * 100.0,
                    'fundamental': pe_score * 100.0,
                    'sentiment': 50.0,
                }
                quick_scores['comprehensive'] = self.calculate_comprehensive_score(quick_scores)
                rec = self.generate_recommendation(quick_scores)

                out_rows.append({
                    'stock_code': code,
                    'stock_name': name,
                    'latest_price': float(price),
                    'change_pct': float(chg),
                    'pe': float(pe),
                    'mktcap_e': float(mktcap_e),
                    'score': score,
                    'recommendation': rec
                })
            except Exception:
                continue

        if not out_rows:
            return []
        # æ’åºå¹¶æˆªæ–­
        out_rows.sort(key=lambda x: x.get('score', 0.0), reverse=True)
        return out_rows[: max(1, int(top_n))]

    def _get_candidate_codes_via_baostock(self, exclude_st: bool = True, limit: int = 200) -> List[Dict]:
        """é€šè¿‡BaoStockè·å–Aè‚¡å€™é€‰ä»£ç åˆ—è¡¨ï¼ˆå«åç§°ï¼‰ï¼Œç”¨äºç¦»çº¿å…œåº•ã€‚

        è¿”å›: [{ 'code': '000001', 'name': 'å¹³å®‰é“¶è¡Œ' }, ...]
        """
        try:
            if not getattr(self, 'baostock_connected', False):
                return []
            # è¡Œä¸šæ¥å£é€šå¸¸åŒ…å«è¾ƒå…¨æˆä»½
            df_ind = self._query_baostock_data(bs.query_stock_industry)
            if df_ind is None or df_ind.empty:
                # é€€è€Œæ±‚å…¶æ¬¡ï¼šå…¨å¸‚åœºåˆ—è¡¨ï¼ˆå¯èƒ½æ— åç§°ï¼‰
                rs = bs.query_all_stock()
                rows = []
                while (rs.error_code == '0') and rs.next():
                    rows.append(rs.get_row_data())
                if not rows:
                    return []
                import pandas as pd
                df = pd.DataFrame(rows, columns=rs.fields)
                codes = []
                for _, r in df.iterrows():
                    code = str(r.get('code',''))
                    if '.' in code:
                        code = code.split('.')[-1]
                    code = code[-6:]
                    if len(code) == 6 and code.isdigit():
                        codes.append({'code': code, 'name': ''})
                return codes[:max(1, int(limit))]

            # è§„èŒƒåŒ–
            codes = []
            for _, r in df_ind.iterrows():
                try:
                    code = str(r.get('code',''))
                    name = str(r.get('code_name',''))
                    if '.' in code:
                        code = code.split('.')[-1]
                    code = code[-6:]
                    if len(code) != 6 or (not code.isdigit()):
                        continue
                    if exclude_st and any(x in name for x in ['ST','*ST','é€€']):
                        continue
                    codes.append({'code': code, 'name': name})
                except Exception:
                    continue
            # å»é‡ä¿åº
            seen = set()
            uniq = []
            for it in codes:
                if it['code'] in seen:
                    continue
                seen.add(it['code'])
                uniq.append(it)
            return uniq[:max(1, int(limit))]
        except Exception:
            return []

    def _quick_recommendations_offline_via_price(self, top_n: int = 20, exclude_st: bool = True) -> List[Dict]:
        """å½“å¿«ç…§ä¸ç¼“å­˜éƒ½ä¸å¯ç”¨æ—¶çš„å…œåº•ï¼š
        ç”¨BaoStockå¯ç”¨çš„å†å²Kçº¿ï¼Œè®¡ç®—è¿‘20æ—¥åŠ¨é‡/æ³¢åŠ¨çš„ç®€å•åˆ†æ•°ï¼Œè¾“å‡ºTopNã€‚

        æ³¨æ„ï¼šPE/æ€»å¸‚å€¼æ— æ³•ä¿è¯ï¼Œç½®ä¸º0ã€‚è¯¥æ¨¡å¼ä¸»è¦ä¸ºâ€œæœ‰ç»“æœä¸ç©ºç™½â€ã€‚
        """
        try:
            import numpy as np
            import pandas as pd
        except Exception:
            return []

        cands = self._get_candidate_codes_via_baostock(exclude_st=exclude_st, limit=max(120, int(top_n) * 20))
        if not cands:
            return []

        out = []
        scanned = 0
        for it in cands:
            if len(out) >= max(10, int(top_n) * 2):  # æ”¶é›†ä¸€å®šå†—ä½™ååœæ­¢
                break
            code = it['code']
            name = it.get('name') or code
            try:
                df = self.get_stock_data(code)
                if df is None or df.empty or 'close' not in df.columns:
                    continue
                close = pd.to_numeric(df['close'], errors='coerce').dropna()
                if len(close) < 22:
                    continue
                close = close.tail(25)
                last = float(close.iloc[-1])
                prev = float(close.iloc[-2]) if len(close) >= 2 else last
                daily_chg_pct = ((last - prev) / prev) * 100.0 if prev > 1e-8 else 0.0
                # è¿‘20æ—¥åŠ¨é‡
                base = float(close.iloc[-21]) if len(close) >= 21 else last
                momentum = (last - base) / base if base > 1e-8 else 0.0
                # ç®€æ˜“æ³¢åŠ¨ï¼ˆè¿‘20æ—¥å¯¹æ•°æ”¶ç›Šçš„æ ‡å‡†å·®ï¼‰
                rets = np.diff(np.log(close.values))
                vol = float(np.std(rets[-20:])) if len(rets) >= 20 else float(np.std(rets))

                # è¯„åˆ†ï¼šåŠ¨é‡è¶Šé«˜è¶Šå¥½ï¼Œæ³¢åŠ¨è¶Šä½è¶Šå¥½
                mom_score = max(0.0, min(1.0, (momentum + 0.20) / 0.40))  # çº¦ -20%~+20% æ˜ å°„åˆ° 0~1
                vol_score = 1.0 - max(0.0, min(1.0, vol / 0.06))          # å¹´åŒ–çº¦åŒ–ç®€ï¼Œç²—ç•¥é˜ˆå€¼
                score = float(round(100.0 * (0.75 * mom_score + 0.25 * vol_score), 2))

                quick_scores = {
                    'technical': mom_score * 100.0,
                    'fundamental': 50.0,
                    'sentiment': 50.0,
                }
                quick_scores['comprehensive'] = self.calculate_comprehensive_score(quick_scores)
                rec = self.generate_recommendation(quick_scores)

                out.append({
                    'stock_code': code,
                    'stock_name': name,
                    'latest_price': float(round(last, 3)),
                    'change_pct': float(round(daily_chg_pct, 3)),
                    'pe': 0.0,
                    'mktcap_e': 0.0,
                    'score': score,
                    'recommendation': rec
                })
            except Exception:
                continue
            finally:
                scanned += 1

        if not out:
            return []
        out.sort(key=lambda x: x.get('score', 0.0), reverse=True)
        return out[: max(1, int(top_n))]

    # ===== è§„åˆ™ç­›é€‰æ¨èï¼ˆ7æ—¥çª—å£ï¼‰=====
    def _fetch_recent_ohlcv_light(self, stock_code: str, window_days: int = 25) -> pd.DataFrame:
        """è½»é‡è·å–è¿‘ç«¯æ—¥Kæ•°æ®ï¼Œç”¨äºè§„åˆ™ç­›é€‰ã€‚ä¼˜å…ˆakshareï¼Œå¤±è´¥å›é€€ç¼“å­˜ä¸é€šç”¨æ¥å£ã€‚

        å‚æ•°ï¼š
            window_days: éœ€è¦çš„äº¤æ˜“æ—¥æ•°é‡ï¼ˆä¸æ˜¯è‡ªç„¶æ—¥ï¼‰ï¼Œé»˜è®¤25ä¸ªäº¤æ˜“æ—¥
        
        è¿”å›ï¼šDataFrameåŒ…å«åˆ—ï¼šopen, high, low, close, volumeï¼Œç´¢å¼•ä¸ºæ—¥æœŸå‡åºã€‚
        
        æ³¨æ„ï¼šè¿”å›çš„æ•°æ®ä¸ºäº¤æ˜“æ—¥æ•°æ®ï¼Œå·²è‡ªåŠ¨æ’é™¤å‘¨æœ«å’ŒèŠ‚å‡æ—¥ã€‚
        """
        try:
            import akshare as ak
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=max(30, int(window_days) * 3))).strftime('%Y%m%d')
            df = ak.stock_zh_a_hist(
                symbol=str(stock_code),
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"
            )
            if df is None or df.empty:
                raise RuntimeError("akshareè¿”å›ç©º")
            # æ ‡å‡†åŒ–åˆ—
            mapping = {
                'æ—¥æœŸ': 'date', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close', 'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume'
            }
            for c_cn, c_en in mapping.items():
                if c_cn in df.columns:
                    df[c_en] = df[c_cn]
            # æˆäº¤é‡å•ä½è½¬è‚¡ï¼šakæ˜¯æ‰‹
            if 'volume' in df.columns:
                try:
                    df['volume'] = pd.to_numeric(df['volume'], errors='coerce') * 100.0
                except Exception:
                    pass
            # ç´¢å¼•ä¸æ•°å€¼åŒ–
            try:
                if 'date' in df.columns:
                    df['date'] = pd.to_datetime(df['date'])
                    df = df.set_index('date')
                else:
                    df.index = pd.to_datetime(df.index)
            except Exception:
                pass
            for c in ['open','high','low','close','volume']:
                if c in df.columns:
                    try:
                        df[c] = pd.to_numeric(df[c], errors='coerce')
                    except Exception:
                        pass
            df = df[['open','high','low','close','volume']].dropna()
            df = df.sort_index()
            # è¿”å›æœ€è¿‘çš„Nä¸ªäº¤æ˜“æ—¥æ•°æ®ï¼ˆ+5æ˜¯ä¸ºäº†ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œåˆ†æï¼‰
            # æ³¨æ„ï¼šakshareè¿”å›çš„æ—¥Kæ•°æ®å·²ç»æ˜¯äº¤æ˜“æ—¥ï¼Œè‡ªåŠ¨æ’é™¤äº†å‘¨æœ«å’ŒèŠ‚å‡æ—¥
            result_df = df.tail(int(window_days) + 5)
            self.logger.debug(f"è·å–åˆ° {len(result_df)} ä¸ªäº¤æ˜“æ—¥çš„Kçº¿æ•°æ®ï¼Œç”¨äºåˆ†æ")
            return result_df
        except Exception:
            # å›é€€ï¼šä½¿ç”¨é€šç”¨ç¼“å­˜çš„get_stock_data
            try:
                base = self.get_stock_data(stock_code)
                if base is None or base.empty:
                    return pd.DataFrame()
                cols = [c for c in ['open','high','low','close','volume'] if c in base.columns]
                if not cols:
                    return pd.DataFrame()
                df = base[cols].copy()
                if not isinstance(df.index, pd.DatetimeIndex):
                    try:
                        df.index = pd.to_datetime(base.get('date', base.index))
                    except Exception:
                        pass
                df = df.sort_index().tail(int(window_days) + 5)
                return df
            except Exception:
                return pd.DataFrame()

    def _check_7day_rule(self, df: pd.DataFrame) -> Tuple[bool, float, dict]:
        """åœ¨ç»™å®šçš„è¿‘ç«¯OHLCVæ•°æ®ä¸Šæ£€æŸ¥7æ—¥è§„åˆ™ï¼Œè¿”å›(æ˜¯å¦æ»¡è¶³, è§„åˆ™å¾—åˆ†0-100, è¯Šæ–­ä¿¡æ¯)ã€‚

        è§„åˆ™å£å¾„ï¼ˆç»“åˆç”¨æˆ·æè¿°ï¼Œåšåˆç†å·¥ç¨‹åŒ–è¿‘ä¼¼ï¼‰ï¼š
        - å–æœ€è¿‘7ä¸ªäº¤æ˜“æ—¥ä½œä¸ºçª—å£d1..d7ï¼ˆd7ä¸ºæœ€è¿‘æ—¥ï¼‰ã€‚
        - ç¬¬2æ—¥ä¸ºé˜´çº¿ä¸”ç¬¬3æ—¥ä¸ºé˜³çº¿ï¼ˆé˜´â†’é˜³ï¼‰ï¼Œè§†ä½œâ€œç¬¬3æ—¥èµ°é˜´é˜³çº¿â€çš„ç»„åˆä¿¡å·ã€‚
        - ç¬¬4æ—¥æœ€é«˜ä»· > ç¬¬3æ—¥æœ€é«˜ä»·ï¼ˆçªç ´ç¡®è®¤ï¼Œå…è®¸æœ€å°0.3%å®¹å·®ï¼‰ã€‚
        - æˆäº¤é‡æ•´ä½“å‘ˆâ€œå‰ä½åé«˜æˆ–æ³¢åŠ¨æ”¾å¤§â€ï¼š
          a) åä¸‰æ—¥(5-7)æ€»é‡ > å‰ä¸‰æ—¥(1-3)æ€»é‡ï¼›æˆ–
          b) æˆäº¤é‡å¯¹æ—¶é—´çš„å›å½’æ–œç‡>0ï¼›æˆ–
          c) æˆäº¤é‡çš„å˜å¼‚ç³»æ•°(std/mean) >= 0.28ã€‚
        - é™„åŠ ç»†åˆ™ï¼ˆåŠ åˆ†é¡¹ï¼‰ï¼š
          â€¢ çª—å£å†…æœ€å¤§é‡å½“æ—¥çš„æ¶¨è·Œä¸ºæ­£ï¼›
          â€¢ æœ€å°é‡å‡ºç°åœ¨ä¸‹è·Œæ—¥ï¼›
          â€¢ çª—å£å†…æœ‰1-2æ—¥å®ä½“è¾ƒå°(åå­—/æ¨ªç›˜)ï¼Œä½†ä¼´éšæ”¾é‡ã€‚
        """
        diag = {}
        try:
            if df is None or df.empty or len(df) < 7:
                return False, 0.0, {'reason': 'æ•°æ®ä¸è¶³'}
            
            # ç¡®ä¿ç´¢å¼•ä¸ºæ—¥æœŸç±»å‹ï¼Œå¹¶æ’åº
            if not isinstance(df.index, pd.DatetimeIndex):
                try:
                    df.index = pd.to_datetime(df.index)
                except Exception:
                    return False, 0.0, {'reason': 'æ—¥æœŸç´¢å¼•è½¬æ¢å¤±è´¥'}
            
            # æ’åºå¹¶å–æœ€è¿‘7ä¸ªäº¤æ˜“æ—¥ï¼ˆKçº¿æ•°æ®æœ¬èº«å°±æ˜¯äº¤æ˜“æ—¥ï¼Œæ— éœ€é¢å¤–è¿‡æ»¤ï¼‰
            df_sorted = df.sort_index(ascending=True)
            
            # å–æœ€è¿‘7ä¸ªäº¤æ˜“æ—¥ï¼ˆæ³¨æ„ï¼šKçº¿æ•°æ®æœ¬èº«å·²æ˜¯äº¤æ˜“æ—¥ï¼Œè‡ªåŠ¨æ’é™¤äº†å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼‰
            w = df_sorted.tail(7).copy()
            
            # æ•°æ®æœ‰æ•ˆæ€§éªŒè¯ï¼šç¡®ä¿æœ‰7ä¸ªä¸åŒçš„äº¤æ˜“æ—¥
            if len(w) < 7:
                return False, 0.0, {'reason': f'äº¤æ˜“æ—¥æ•°é‡ä¸è¶³ï¼Œä»…æœ‰{len(w)}ä¸ªäº¤æ˜“æ—¥'}
            
            # è®°å½•ç”¨äºåˆ†æçš„äº¤æ˜“æ—¥æœŸèŒƒå›´ï¼ˆä¾¿äºè°ƒè¯•ï¼‰
            try:
                date_range = f"{w.index[0].strftime('%Y-%m-%d')} è‡³ {w.index[-1].strftime('%Y-%m-%d')}"
                diag['trading_date_range'] = date_range
                diag['trading_days_count'] = len(w)
            except Exception:
                pass
            
            w = w[['open','high','low','close','volume']].astype(float)
            w.index = pd.to_datetime(w.index)
            o = w['open'].values
            h = w['high'].values
            l = w['low'].values
            c = w['close'].values
            v = w['volume'].values

            # é˜´â†’é˜³ï¼ˆd2é˜´, d3é˜³ï¼‰
            cond_yinyang = (c[1] < o[1]) and (c[2] > o[2])
            # d4 çªç ´ d3 highï¼Œå…è®¸0.3%å®¹å·®
            cond_break = h[3] > (h[2] * 1.003)

            # é‡èƒ½è¶‹åŠ¿ï¼šåä¸‰æ—¥é‡ > å‰ä¸‰æ—¥é‡ æˆ– æ–œç‡>0 æˆ– å˜å¼‚ç³»æ•°é«˜
            front = float(v[0] + v[1] + v[2])
            back = float(v[4] + v[5] + v[6])
            cond_back_higher = back > front * 1.05
            # ç®€å•å›å½’æ–œç‡
            try:
                x = np.arange(len(v))
                slope = np.polyfit(x, v, 1)[0]
            except Exception:
                slope = 0.0
            cond_slope_pos = slope > 0
            # å˜å¼‚ç³»æ•°
            vmean = float(np.mean(v)) if np.isfinite(np.mean(v)) else 0.0
            vstdev = float(np.std(v)) if np.isfinite(np.std(v)) else 0.0
            cond_cv = (vmean > 0) and ((vstdev / vmean) >= 0.28)

            volume_trend = cond_back_higher or cond_slope_pos or cond_cv

            base_ok = cond_yinyang and cond_break and volume_trend

            # åŠ åˆ†é¡¹
            bonus = 0.0
            # æœ€å¤§/æœ€å°é‡æ—¥ä½ç½®ä¸æ¶¨è·Œ
            try:
                max_idx = int(np.argmax(v))
                min_idx = int(np.argmin(v))
            except Exception:
                max_idx = 0
                min_idx = 0
            ret = np.diff(c, prepend=c[0]) / np.maximum(1e-6, np.concatenate([[c[0]], c[:-1]]))
            if max_idx >= 0 and max_idx < len(ret) and ret[max_idx] > 0:
                bonus += 8.0
            if min_idx >= 0 and min_idx < len(ret) and ret[min_idx] < 0:
                bonus += 4.0

            # å°å®ä½“æ”¾é‡ï¼ˆæ—¥å†…æŒ¯å¹…å æ”¶ç›˜ä»·çš„æ¯”ä¾‹ < 1.2%ï¼Œä½†ç›¸å¯¹é‡èƒ½>çª—å£å‡å€¼ï¼‰
            body = np.abs(c - o)
            body_ratio = body / np.maximum(1e-6, c)
            amp = (h - l) / np.maximum(1e-6, c)
            for i in range(len(w)):
                if body_ratio[i] <= 0.012 and v[i] >= vmean * 1.15 and amp[i] <= 0.035:
                    bonus += 3.0
                    break

            # è§„åˆ™è¯„åˆ†ï¼š
            score = 0.0
            if cond_yinyang:
                score += 35.0
            if cond_break:
                score += 30.0
            if volume_trend:
                score += 20.0
            score += bonus
            score = float(max(0.0, min(100.0, score)))

            diag.update({
                'yinyang': bool(cond_yinyang),
                'break_high': bool(cond_break),
                'volume_trend': bool(volume_trend),
                'bonus': float(bonus)
            })
            return bool(base_ok), score, diag
        except Exception as e:
            return False, 0.0, {'error': str(e)}

    def get_rule_based_recommendations(self, top_n: int = 20, min_mktcap_e: float = 30.0, exclude_st: bool = True) -> List[Dict]:
        """æŒ‰7æ—¥ä»·æ ¼/é‡èƒ½è§„åˆ™ç­›é€‰æ¨èåˆ—è¡¨ã€‚

        æµç¨‹ï¼š
        1) å–Aè‚¡å¿«ç…§åšâ€œå€™é€‰æ± â€ï¼ˆè¿‡æ»¤STã€é€€å¸‚ã€æ€»å¸‚å€¼ä¸‹é™ï¼‰ã€‚
        2) å¯¹å€™é€‰é€è‚¡æ‹‰å–è¿‘ç«¯æ—¥Kï¼ˆçº¦25å¤©ï¼‰ï¼Œæ£€æµ‹7æ—¥è§„åˆ™ã€‚
        3) å¯¹æ»¡è¶³è§„åˆ™çš„ï¼Œç»“åˆå¿«ç…§åŠ¨é‡/ä¼°å€¼åšç»¼åˆæ’åºï¼Œè¿”å›TopNã€‚
        """
        try:
            import akshare as ak
        except Exception:
            ak = None

        # å€™é€‰æ± ï¼ˆä¸å¿«ç…§æ¨èä¸€è‡´ï¼‰
        spot = pd.DataFrame()
        if ak is not None:
            try:
                spot = ak.stock_zh_a_spot_em()
                if spot is not None and not spot.empty:
                    try:
                        self._save_spot_snapshot_cache(spot)
                    except Exception:
                        pass
            except Exception:
                spot = pd.DataFrame()
        if (spot is None) or spot.empty:
            spot = self._load_spot_snapshot_cache()
        if spot is None or spot.empty:
            # ç¦»çº¿å…œåº•ï¼šç›´æ¥ç”¨BaoStockæ„é€ å€™é€‰æ± ï¼ˆä»…ä»£ç /åç§°ï¼‰ï¼Œåç»­é€è‚¡æ‹‰Kåšè§„åˆ™åˆ¤å®š
            self.logger.warning("æ— æ³•è·å–Aè‚¡å¿«ç…§ï¼Œè§„åˆ™æ¨èæ”¹ç”¨BaoStockå€™é€‰æ± ")
            df = None
            candidates = []
            try:
                pool = self._get_candidate_codes_via_baostock(exclude_st=exclude_st, limit=max(200, int(top_n) * 40))
                for it in pool:
                    candidates.append({
                        'stock_code': it['code'],
                        'stock_name': it.get('name') or it['code'],
                        'mktcap_e': 0.0,
                        'change_pct': 0.0,
                        'latest_price': 0.0,
                        'pe': 60.0  # åˆç†é»˜è®¤ç”¨äºæ’åº
                    })
            except Exception:
                pass
            if not candidates:
                return []

            # ç›´æ¥è¿›å…¥æ‰«æé˜¶æ®µ
            passed = []
            scan_cap = min(len(candidates), max(200, int(top_n) * 40))
            pool = candidates[:scan_cap]
            for item in pool:
                code = item['stock_code']
                df_k = self._fetch_recent_ohlcv_light(code, window_days=25)
                if df_k is None or df_k.empty or len(df_k) < 7:
                    continue
                ok, rule_score, diag = self._check_7day_rule(df_k)
                if not ok:
                    continue
                # å¿«é€Ÿåˆ†ï¼ˆæ— PE/å¸‚å€¼ï¼Œä½¿ç”¨é»˜è®¤ï¼‰
                chg = float(item.get('change_pct', 0.0))
                mom = max(0.0, min(1.0, (chg + 5.0) / 10.0))
                pe_eff = max(0.0, min(120.0, float(item.get('pe', 60.0))))
                pe_score = max(0.0, min(1.0, (80.0 - pe_eff) / 80.0))
                x = float(item.get('mktcap_e', 100.0))
                if x <= 30:
                    mcap_score = 0.2
                elif x <= 80:
                    mcap_score = 0.6 + (x - 80.0) / 50.0 * 0.4
                elif x <= 300:
                    mcap_score = 1.0 - abs((x - 190.0) / 110.0) * 0.4
                elif x <= 800:
                    mcap_score = 0.8 - (x - 300.0) / 500.0 * 0.6
                else:
                    mcap_score = 0.2
                mcap_score = max(0.0, min(1.0, mcap_score))
                quick01 = 0.45 * mom + 0.35 * pe_score + 0.20 * mcap_score
                quick_score = float(round(quick01 * 100.0, 2))

                combo_score = float(round(0.7 * rule_score + 0.3 * quick_score, 2))
                quick_scores = {
                    'technical': float(rule_score),
                    'fundamental': pe_score * 100.0,
                    'sentiment': 55.0,
                }
                quick_scores['comprehensive'] = self.calculate_comprehensive_score(quick_scores)
                rec = self.generate_recommendation(quick_scores)

                passed.append({
                    'stock_code': item['stock_code'],
                    'stock_name': item['stock_name'],
                    'latest_price': float(item.get('latest_price', 0.0)),
                    'change_pct': float(item.get('change_pct', 0.0)),
                    'pe': float(item.get('pe', 60.0)),
                    'mktcap_e': float(item.get('mktcap_e', 0.0)),
                    'score': combo_score,
                    'recommendation': rec
                })

            if not passed:
                return []
            passed.sort(key=lambda x: x.get('score', 0.0), reverse=True)
            return passed[: max(1, int(top_n))]

        df = spot.copy()

        def pick_col(cands: List[str]) -> Optional[str]:
            for c in cands:
                if c in df.columns:
                    return c
            return None

        code_col = pick_col(['ä»£ç ','è‚¡ç¥¨ä»£ç ','è¯åˆ¸ä»£ç ','Aè‚¡ä»£ç ','code']) or df.columns[0]
        name_col = pick_col(['åç§°','è‚¡ç¥¨ç®€ç§°','ç®€ç§°','name']) or (df.columns[1] if len(df.columns) > 1 else code_col)
        pct_col  = pick_col(['æ¶¨è·Œå¹…','æ¶¨è·Œå¹…(%)','æ¶¨è·Œå¹…%','pct_chg'])
        price_col= pick_col(['æœ€æ–°ä»·','ç°ä»·','ä»·æ ¼','æœ€æ–°'])
        pe_col   = pick_col(['å¸‚ç›ˆç‡-åŠ¨æ€','å¸‚ç›ˆç‡TTM','å¸‚ç›ˆç‡'])
        mcap_col = pick_col(['æ€»å¸‚å€¼(äº¿)','æ€»å¸‚å€¼'])

        def to_float(x) -> Optional[float]:
            try:
                if isinstance(x, str):
                    xs = x.strip().replace(',', '')
                    if xs.endswith('%'):
                        return float(xs.rstrip('%'))
                    return float(xs)
                return float(x)
            except Exception:
                return None

        # é¢„ç­› + æ§åˆ¶è§„æ¨¡
        candidates = []
        for _, r in df.iterrows():
            try:
                code = str(r.get(code_col, '')).strip()
                if not code:
                    continue
                code = code[-6:]
                # è¿‡æ»¤å¼‚å¸¸ä»£ç ï¼ˆå¿…é¡»ä¸º6ä½æ•°å­—ï¼‰
                if len(code) != 6 or (not code.isdigit()):
                    continue
                name = str(r.get(name_col, code))
                if exclude_st and any(x in str(name) for x in ['ST','*ST','é€€']):
                    continue
                mktcap_e = to_float(r.get(mcap_col)) if mcap_col else None
                if mktcap_e is not None and mcap_col == 'æ€»å¸‚å€¼' and mktcap_e > 1e9:
                    mktcap_e = mktcap_e / 1e8
                if (mktcap_e is None) or (mktcap_e < min_mktcap_e):
                    continue
                chg = to_float(r.get(pct_col)) if pct_col else 0.0
                price = to_float(r.get(price_col)) if price_col else 0.0
                pe = to_float(r.get(pe_col)) if pe_col else None
                if pe is None or pe <= 0 or pe > 1200:
                    continue
                candidates.append({
                    'stock_code': code,
                    'stock_name': name,
                    'mktcap_e': float(mktcap_e),
                    'change_pct': float(chg) if chg is not None else 0.0,
                    'latest_price': float(price) if price is not None else 0.0,
                    'pe': float(pe)
                })
            except Exception:
                continue

        if not candidates:
            return []

        # é™åˆ¶æ‰«æè§„æ¨¡ï¼šä¼˜å…ˆåŠ¨é‡+ä¸­ç­‰ä½“é‡ï¼ˆç®€å•æ’åºåå–å‰Kï¼‰
        candidates.sort(key=lambda x: (abs(x.get('change_pct', 0.0)) * 0.6 + (1.0 / (1.0 + abs(x.get('pe', 50.0)))) * 0.4), reverse=True)
        scan_cap = min(len(candidates), max(200, int(top_n) * 40))  # æ‰«æä¸Šé™
        pool = candidates[:scan_cap]

        passed = []
        for item in pool:
            code = item['stock_code']
            df_k = self._fetch_recent_ohlcv_light(code, window_days=25)
            if df_k is None or df_k.empty or len(df_k) < 7:
                continue
            ok, rule_score, diag = self._check_7day_rule(df_k)
            if not ok:
                continue
            # å¿«ç…§åˆ†ï¼ˆä¸å¿«é€Ÿæ¨èä¸€è‡´ï¼‰
            chg = float(item.get('change_pct', 0.0))
            mom = max(0.0, min(1.0, (chg + 5.0) / 10.0))
            pe_eff = max(0.0, min(120.0, float(item.get('pe', 60.0))))
            pe_score = max(0.0, min(1.0, (80.0 - pe_eff) / 80.0))
            x = float(item.get('mktcap_e', 100.0))
            if x <= 30:
                mcap_score = 0.2
            elif x <= 80:
                mcap_score = 0.6 + (x - 80.0) / 50.0 * 0.4
            elif x <= 300:
                mcap_score = 1.0 - abs((x - 190.0) / 110.0) * 0.4
            elif x <= 800:
                mcap_score = 0.8 - (x - 300.0) / 500.0 * 0.6
            else:
                mcap_score = 0.2
            mcap_score = max(0.0, min(1.0, mcap_score))
            quick01 = 0.45 * mom + 0.35 * pe_score + 0.20 * mcap_score
            quick_score = float(round(quick01 * 100.0, 2))

            # ç»¼åˆæ’åºåˆ†ï¼šè§„åˆ™ä¸ºä¸»
            combo_score = float(round(0.7 * rule_score + 0.3 * quick_score, 2))

            # ç”Ÿæˆå»ºè®®ï¼šå°†è§„åˆ™åˆ†è§†ä½œæŠ€æœ¯åˆ†
            quick_scores = {
                'technical': float(rule_score),
                'fundamental': pe_score * 100.0,
                'sentiment': 55.0,
            }
            quick_scores['comprehensive'] = self.calculate_comprehensive_score(quick_scores)
            rec = self.generate_recommendation(quick_scores)

            passed.append({
                'stock_code': item['stock_code'],
                'stock_name': item['stock_name'],
                'latest_price': float(item.get('latest_price', 0.0)),
                'change_pct': float(item.get('change_pct', 0.0)),
                'pe': float(item.get('pe', np.nan)),
                'mktcap_e': float(item.get('mktcap_e', np.nan)),
                'score': combo_score,
                'recommendation': rec
            })

        if not passed:
            return []
        passed.sort(key=lambda x: x.get('score', 0.0), reverse=True)
        return passed[: max(1, int(top_n))]

    def _build_enhanced_ai_analysis_prompt(self, stock_code, stock_name, scores, technical_analysis, 
                                        fundamental_data, sentiment_analysis, price_info):
        """æ„å»ºå¢å¼ºç‰ˆAIåˆ†ææç¤ºè¯ï¼ŒåŒ…å«æ‰€æœ‰è¯¦ç»†æ•°æ®"""
        
        # æå–25é¡¹è´¢åŠ¡æŒ‡æ ‡
        financial_indicators = fundamental_data.get('financial_indicators', {})
        financial_text = ""
        if financial_indicators:
            financial_text = "**25é¡¹æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡ï¼š**\n"
            for i, (key, value) in enumerate(financial_indicators.items(), 1):
                if isinstance(value, (int, float)) and value != 0:
                    financial_text += f"{i}. {key}: {value}\n"
        
        # æå–æ–°é—»è¯¦ç»†ä¿¡æ¯
        news_summary = sentiment_analysis.get('news_summary', {})
        company_news = sentiment_analysis.get('company_news', [])
        announcements = sentiment_analysis.get('announcements', [])
        research_reports = sentiment_analysis.get('research_reports', [])
        
        news_text = f"""
**æ–°é—»æ•°æ®è¯¦æƒ…ï¼š**
- å…¬å¸æ–°é—»ï¼š{len(company_news)}æ¡
- å…¬å¸å…¬å‘Šï¼š{len(announcements)}æ¡  
- ç ”ç©¶æŠ¥å‘Šï¼š{len(research_reports)}æ¡
- æ€»æ–°é—»æ•°ï¼š{news_summary.get('total_news_count', 0)}æ¡

**é‡è¦æ–°é—»æ ‡é¢˜ï¼ˆå‰10æ¡ï¼‰ï¼š**
"""
        
        for i, news in enumerate(company_news[:5], 1):
            news_text += f"{i}. {news.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n"
        
        for i, announcement in enumerate(announcements[:5], 1):
            news_text += f"{i+5}. [å…¬å‘Š] {announcement.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n"
        
        # æå–ç ”ç©¶æŠ¥å‘Šä¿¡æ¯
        research_text = ""
        if research_reports:
            research_text = "\n**ç ”ç©¶æŠ¥å‘Šæ‘˜è¦ï¼š**\n"
            for i, report in enumerate(research_reports[:5], 1):
                research_text += f"{i}. {report.get('institution', 'æœªçŸ¥æœºæ„')}: {report.get('rating', 'æœªçŸ¥è¯„çº§')} - {report.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n"
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        prompt = f"""è¯·ä½œä¸ºä¸€ä½èµ„æ·±çš„è‚¡ç¥¨åˆ†æå¸ˆï¼ŒåŸºäºä»¥ä¸‹è¯¦ç»†æ•°æ®å¯¹è‚¡ç¥¨è¿›è¡Œæ·±åº¦åˆ†æï¼š

**è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼š**
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}
- è‚¡ç¥¨åç§°ï¼š{stock_name}
- å½“å‰ä»·æ ¼ï¼š{price_info.get('current_price', 0):.2f}å…ƒ
- æ¶¨è·Œå¹…ï¼š{price_info.get('price_change', 0):.2f}%
- æˆäº¤é‡æ¯”ç‡ï¼š{price_info.get('volume_ratio', 1):.2f}
- æ³¢åŠ¨ç‡ï¼š{price_info.get('volatility', 0):.2f}%

**æŠ€æœ¯åˆ†æè¯¦æƒ…ï¼š**
- å‡çº¿è¶‹åŠ¿ï¼š{technical_analysis.get('ma_trend', 'æœªçŸ¥')}
- RSIæŒ‡æ ‡ï¼š{technical_analysis.get('rsi', 50):.1f}
- MACDä¿¡å·ï¼š{technical_analysis.get('macd_signal', 'æœªçŸ¥')}
- æˆäº¤é‡çŠ¶æ€ï¼š{technical_analysis.get('volume_status', 'æœªçŸ¥')}

{financial_text}

**ä¼°å€¼æŒ‡æ ‡ï¼š**
{self._format_dict_data(fundamental_data.get('valuation', {}))}

**ä¸šç»©é¢„å‘Šï¼š**
å…±{len(fundamental_data.get('performance_forecast', []))}æ¡ä¸šç»©é¢„å‘Š
{self._format_list_data(fundamental_data.get('performance_forecast', [])[:3])}

**åˆ†çº¢é…è‚¡ï¼š**
å…±{len(fundamental_data.get('dividend_info', []))}æ¡åˆ†çº¢é…è‚¡ä¿¡æ¯
{self._format_list_data(fundamental_data.get('dividend_info', [])[:3])}

**è‚¡ä¸œç»“æ„ï¼š**
å‰10å¤§è‚¡ä¸œä¿¡æ¯ï¼š{len(fundamental_data.get('shareholders', []))}æ¡
æœºæ„æŒè‚¡ï¼š{len(fundamental_data.get('institutional_holdings', []))}æ¡

**æ–°é—»æ•°æ®è¯¦æƒ…ï¼š**
- å…¬å¸æ–°é—»ï¼š{len(company_news)}æ¡
- å…¬å¸å…¬å‘Šï¼š{len(announcements)}æ¡  
- ç ”ç©¶æŠ¥å‘Šï¼š{len(research_reports)}æ¡
- æ€»æ–°é—»æ•°ï¼š{news_summary.get('total_news_count', 0)}æ¡

**é‡è¦æ–°é—»æ ‡é¢˜ï¼ˆå‰10æ¡ï¼‰ï¼š**
"""
        
        for i, news in enumerate(company_news[:5], 1):
            prompt += f"{i}. {news.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n"
        
        for i, announcement in enumerate(announcements[:5], 1):
            prompt += f"{i+5}. [å…¬å‘Š] {announcement.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n"
        
        # æå–ç ”ç©¶æŠ¥å‘Šä¿¡æ¯
        if research_reports:
            prompt += "\n**ç ”ç©¶æŠ¥å‘Šæ‘˜è¦ï¼š**\n"
            for i, report in enumerate(research_reports[:5], 1):
                prompt += f"{i}. {report.get('institution', 'æœªçŸ¥æœºæ„')}: {report.get('rating', 'æœªçŸ¥è¯„çº§')} - {report.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n"
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯
        prompt += f"""

**å¸‚åœºæƒ…ç»ªåˆ†æï¼š**
- æ•´ä½“æƒ…ç»ªå¾—åˆ†ï¼š{sentiment_analysis.get('overall_sentiment', 0):.3f}
- æƒ…ç»ªè¶‹åŠ¿ï¼š{sentiment_analysis.get('sentiment_trend', 'ä¸­æ€§')}
- ç½®ä¿¡åº¦ï¼š{sentiment_analysis.get('confidence_score', 0):.2f}
- å„ç±»æ–°é—»æƒ…ç»ªï¼š{sentiment_analysis.get('sentiment_by_type', {})}

**ç»¼åˆè¯„åˆ†ï¼š**
- æŠ€æœ¯é¢å¾—åˆ†ï¼š{scores.get('technical', 50):.1f}/100
- åŸºæœ¬é¢å¾—åˆ†ï¼š{scores.get('fundamental', 50):.1f}/100
- æƒ…ç»ªé¢å¾—åˆ†ï¼š{scores.get('sentiment', 50):.1f}/100
- ç»¼åˆå¾—åˆ†ï¼š{scores.get('comprehensive', 50):.1f}/100

**åˆ†æè¦æ±‚ï¼š**

è¯·åŸºäºä»¥ä¸Šè¯¦ç»†æ•°æ®ï¼Œä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œæ·±åº¦åˆ†æï¼š

1. **è´¢åŠ¡å¥åº·åº¦æ·±åº¦è§£è¯»**ï¼š
   - åŸºäº25é¡¹è´¢åŠ¡æŒ‡æ ‡ï¼Œå…¨é¢è¯„ä¼°å…¬å¸è´¢åŠ¡çŠ¶å†µ
   - è¯†åˆ«è´¢åŠ¡ä¼˜åŠ¿å’Œé£é™©ç‚¹
   - ä¸è¡Œä¸šå¹³å‡æ°´å¹³å¯¹æ¯”åˆ†æ
   - é¢„æµ‹æœªæ¥è´¢åŠ¡å‘å±•è¶‹åŠ¿

2. **æŠ€æœ¯é¢ç²¾å‡†åˆ†æ**ï¼š
   - ç»“åˆå¤šä¸ªæŠ€æœ¯æŒ‡æ ‡ï¼Œåˆ¤æ–­çŸ­ä¸­é•¿æœŸè¶‹åŠ¿
   - è¯†åˆ«å…³é”®æ”¯æ’‘ä½å’Œé˜»åŠ›ä½
   - åˆ†ææˆäº¤é‡ä¸ä»·æ ¼çš„é…åˆå…³ç³»
   - è¯„ä¼°å½“å‰ä½ç½®çš„é£é™©æ”¶ç›Šæ¯”

3. **å¸‚åœºæƒ…ç»ªæ·±åº¦æŒ–æ˜**ï¼š
   - åˆ†æå…¬å¸æ–°é—»ã€å…¬å‘Šã€ç ”æŠ¥çš„å½±å“
   - è¯„ä¼°å¸‚åœºå¯¹å…¬å¸çš„æ•´ä½“é¢„æœŸ
   - è¯†åˆ«æƒ…ç»ªæ‹ç‚¹å’Œå‚¬åŒ–å‰‚
   - åˆ¤æ–­æƒ…ç»ªå¯¹è‚¡ä»·çš„æ¨åŠ¨æˆ–æ‹–ç´¯ä½œç”¨

4. **åŸºæœ¬é¢ä»·å€¼åˆ¤æ–­**ï¼š
   - è¯„ä¼°å…¬å¸å†…åœ¨ä»·å€¼å’Œæˆé•¿æ½œåŠ›
   - åˆ†æè¡Œä¸šåœ°ä½å’Œç«äº‰ä¼˜åŠ¿
   - è¯„ä¼°ä¸šç»©é¢„å‘Šå’Œåˆ†çº¢æ”¿ç­–
   - åˆ¤æ–­å½“å‰ä¼°å€¼çš„åˆç†æ€§

5. **ç»¼åˆæŠ•èµ„ç­–ç•¥**ï¼š
   - ç»™å‡ºæ˜ç¡®çš„ä¹°å–å»ºè®®å’Œç†ç”±
   - è®¾å®šç›®æ ‡ä»·ä½å’Œæ­¢æŸç‚¹
   - åˆ¶å®šåˆ†æ‰¹æ“ä½œç­–ç•¥
   - è¯„ä¼°æŠ•èµ„æ—¶é—´å‘¨æœŸ

6. **é£é™©æœºä¼šè¯†åˆ«**ï¼š
   - åˆ—å‡ºä¸»è¦æŠ•èµ„é£é™©å’Œåº”å¯¹æªæ–½
   - è¯†åˆ«æ½œåœ¨å‚¬åŒ–å‰‚å’Œæˆé•¿æœºä¼š
   - åˆ†æå®è§‚ç¯å¢ƒå’Œæ”¿ç­–å½±å“
   - æä¾›åŠ¨æ€è°ƒæ•´å»ºè®®

è¯·ç”¨ä¸“ä¸šã€å®¢è§‚çš„è¯­è¨€è¿›è¡Œåˆ†æï¼Œç¡®ä¿é€»è¾‘æ¸…æ™°ã€æ•°æ®æ”¯æ’‘å……åˆ†ã€ç»“è®ºæ˜ç¡®å¯æ‰§è¡Œã€‚"""

        return prompt

    def _format_dict_data(self, data_dict, max_items=5):
        """æ ¼å¼åŒ–å­—å…¸æ•°æ®"""
        if not data_dict:
            return "æ— æ•°æ®"
        
        formatted = ""
        for i, (key, value) in enumerate(data_dict.items()):
            if i >= max_items:
                break
            formatted += f"- {key}: {value}\n"
        
        return formatted if formatted else "æ— æœ‰æ•ˆæ•°æ®"

    def _format_list_data(self, data_list, max_items=3):
        """æ ¼å¼åŒ–åˆ—è¡¨æ•°æ®"""
        if not data_list:
            return "æ— æ•°æ®"
        
        formatted = ""
        for i, item in enumerate(data_list):
            if i >= max_items:
                break
            if isinstance(item, dict):
                # å–å­—å…¸çš„å‰å‡ ä¸ªé”®å€¼å¯¹
                item_str = ", ".join([f"{k}: {v}" for k, v in list(item.items())[:3]])
                formatted += f"- {item_str}\n"
            else:
                formatted += f"- {item}\n"
        
        return formatted if formatted else "æ— æœ‰æ•ˆæ•°æ®"

    def generate_ai_analysis(self, analysis_data, enable_streaming=False):
        """ç”ŸæˆAIå¢å¼ºåˆ†æ"""
        try:
            self.logger.info("ğŸ¤– å¼€å§‹AIæ·±åº¦åˆ†æ...")
            
            stock_code = analysis_data.get('stock_code', '')
            stock_name = analysis_data.get('stock_name', stock_code)
            scores = analysis_data.get('scores', {})
            technical_analysis = analysis_data.get('technical_analysis', {})
            fundamental_data = analysis_data.get('fundamental_data', {})
            sentiment_analysis = analysis_data.get('sentiment_analysis', {})
            price_info = analysis_data.get('price_info', {})
            
            # æ„å»ºå¢å¼ºç‰ˆAIåˆ†ææç¤ºè¯
            prompt = self._build_enhanced_ai_analysis_prompt(
                stock_code, stock_name, scores, technical_analysis, 
                fundamental_data, sentiment_analysis, price_info
            )
            
            # è°ƒç”¨AI API
            ai_response = self._call_ai_api(prompt, enable_streaming)
            
            if ai_response:
                self.logger.info("âœ… AIæ·±åº¦åˆ†æå®Œæˆ")
                return ai_response
            else:
                self.logger.warning("âš ï¸ AI APIä¸å¯ç”¨ï¼Œä½¿ç”¨é«˜çº§åˆ†ææ¨¡å¼")
                return self._advanced_rule_based_analysis(analysis_data)
                
        except Exception as e:
            self.logger.error(f"AIåˆ†æå¤±è´¥: {e}")
            return self._advanced_rule_based_analysis(analysis_data)

    def _call_ai_api(self, prompt, enable_streaming=False):
        """è°ƒç”¨AI API"""
        try:
            model_preference = self.config.get('ai', {}).get('model_preference', 'openai')
            
            if model_preference == 'openai' and self.api_keys.get('openai'):
                result = self._call_openai_api(prompt, enable_streaming)
                if result:
                    return result
            
            elif model_preference == 'anthropic' and self.api_keys.get('anthropic'):
                result = self._call_claude_api(prompt, enable_streaming)
                if result:
                    return result
                    
            elif model_preference == 'zhipu' and self.api_keys.get('zhipu'):
                result = self._call_zhipu_api(prompt, enable_streaming)
                if result:
                    return result
            
            # å°è¯•å…¶ä»–å¯ç”¨çš„æœåŠ¡
            if self.api_keys.get('openai') and model_preference != 'openai':
                self.logger.info("å°è¯•å¤‡ç”¨OpenAI API...")
                result = self._call_openai_api(prompt, enable_streaming)
                if result:
                    return result
                    
            if self.api_keys.get('anthropic') and model_preference != 'anthropic':
                self.logger.info("å°è¯•å¤‡ç”¨Claude API...")
                result = self._call_claude_api(prompt, enable_streaming)
                if result:
                    return result
                    
            if self.api_keys.get('zhipu') and model_preference != 'zhipu':
                self.logger.info("å°è¯•å¤‡ç”¨æ™ºè°±AI API...")
                result = self._call_zhipu_api(prompt, enable_streaming)
                if result:
                    return result
            
            return None
                
        except Exception as e:
            self.logger.error(f"AI APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_openai_api(self, prompt, enable_streaming=False):
        """è°ƒç”¨OpenAI API"""
        try:
            import openai
            
            api_key = self.api_keys.get('openai')
            if not api_key:
                return None
                
            openai.api_key = api_key
            
            api_base = self.config.get('ai', {}).get('api_base_urls', {}).get('openai')
            if api_base:
                openai.api_base = api_base
            
            model = self.config.get('ai', {}).get('models', {}).get('openai', 'gpt-4o-mini')
            max_tokens = self.config.get('ai', {}).get('max_tokens', 6000)
            temperature = self.config.get('ai', {}).get('temperature', 0.7)
            
            self.logger.info(f"æ­£åœ¨è°ƒç”¨OpenAI {model} è¿›è¡Œæ·±åº¦åˆ†æ...")
            
            response = openai.ChatCompletion.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œå…·æœ‰ä¸°å¯Œçš„å¸‚åœºç»éªŒå’Œæ·±åšçš„é‡‘èçŸ¥è¯†ã€‚è¯·æä¾›ä¸“ä¸šã€å®¢è§‚ã€æœ‰æ·±åº¦çš„è‚¡ç¥¨åˆ†æã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            return response.choices[0].message.content
                
        except Exception as e:
            self.logger.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_claude_api(self, prompt, enable_streaming=False):
        """è°ƒç”¨Claude API"""
        try:
            import anthropic
            
            api_key = self.api_keys.get('anthropic')
            if not api_key:
                return None
            
            client = anthropic.Anthropic(api_key=api_key)
            
            model = self.config.get('ai', {}).get('models', {}).get('anthropic', 'claude-3-haiku-20240307')
            max_tokens = self.config.get('ai', {}).get('max_tokens', 6000)
            
            self.logger.info(f"æ­£åœ¨è°ƒç”¨Claude {model} è¿›è¡Œæ·±åº¦åˆ†æ...")
            
            response = client.messages.create(
                model=model,
                max_tokens=max_tokens,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            
            return response.content[0].text
            
        except Exception as e:
            self.logger.error(f"Claude APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _call_zhipu_api(self, prompt, enable_streaming=False):
        """è°ƒç”¨æ™ºè°±AI API"""
        try:
            import zhipuai
            
            api_key = self.api_keys.get('zhipu')
            if not api_key:
                return None
            
            zhipuai.api_key = api_key
            
            model = self.config.get('ai', {}).get('models', {}).get('zhipu', 'chatglm_turbo')
            max_tokens = self.config.get('ai', {}).get('max_tokens', 6000)
            temperature = self.config.get('ai', {}).get('temperature', 0.7)
            
            self.logger.info(f"æ­£åœ¨è°ƒç”¨æ™ºè°±AI {model} è¿›è¡Œæ·±åº¦åˆ†æ...")
            
            response = zhipuai.model_api.invoke(
                model=model,
                prompt=[
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            return response['data']['choices'][0]['content']
            
        except Exception as e:
            self.logger.error(f"æ™ºè°±AI APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _advanced_rule_based_analysis(self, analysis_data):
        """é«˜çº§è§„åˆ™åˆ†æï¼ˆAIå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        try:
            self.logger.info("ğŸ§  ä½¿ç”¨é«˜çº§è§„åˆ™å¼•æ“è¿›è¡Œåˆ†æ...")
            
            stock_code = analysis_data.get('stock_code', '')
            stock_name = analysis_data.get('stock_name', stock_code)
            scores = analysis_data.get('scores', {})
            technical_analysis = analysis_data.get('technical_analysis', {})
            fundamental_data = analysis_data.get('fundamental_data', {})
            sentiment_analysis = analysis_data.get('sentiment_analysis', {})
            price_info = analysis_data.get('price_info', {})
            
            analysis_sections = []
            
            # 1. ç»¼åˆè¯„ä¼°
            comprehensive_score = scores.get('comprehensive', 50)
            analysis_sections.append(f"""## ğŸ“Š ç»¼åˆè¯„ä¼°

åŸºäºæŠ€æœ¯é¢ã€åŸºæœ¬é¢å’Œå¸‚åœºæƒ…ç»ªçš„ç»¼åˆåˆ†æï¼Œ{stock_name}({stock_code})çš„ç»¼åˆå¾—åˆ†ä¸º{comprehensive_score:.1f}åˆ†ã€‚

- æŠ€æœ¯é¢å¾—åˆ†ï¼š{scores.get('technical', 50):.1f}/100
- åŸºæœ¬é¢å¾—åˆ†ï¼š{scores.get('fundamental', 50):.1f}/100  
- æƒ…ç»ªé¢å¾—åˆ†ï¼š{scores.get('sentiment', 50):.1f}/100""")
            
            # 2. è´¢åŠ¡åˆ†æ
            financial_indicators = fundamental_data.get('financial_indicators', {})
            if financial_indicators:
                key_metrics = []
                for key, value in list(financial_indicators.items())[:10]:
                    if isinstance(value, (int, float)) and value != 0:
                        key_metrics.append(f"- {key}: {value}")
                
                financial_text = f"""## ğŸ’° è´¢åŠ¡å¥åº·åº¦åˆ†æ

è·å–åˆ°{len(financial_indicators)}é¡¹è´¢åŠ¡æŒ‡æ ‡ï¼Œä¸»è¦æŒ‡æ ‡å¦‚ä¸‹ï¼š

{chr(10).join(key_metrics[:8])}

è´¢åŠ¡å¥åº·åº¦è¯„ä¼°ï¼š{'ä¼˜ç§€' if scores.get('fundamental', 50) >= 70 else 'è‰¯å¥½' if scores.get('fundamental', 50) >= 50 else 'éœ€å…³æ³¨'}"""
                analysis_sections.append(financial_text)
            
            # 3. æŠ€æœ¯é¢åˆ†æ
            tech_analysis = f"""## ğŸ“ˆ æŠ€æœ¯é¢åˆ†æ

å½“å‰æŠ€æœ¯æŒ‡æ ‡æ˜¾ç¤ºï¼š
- å‡çº¿è¶‹åŠ¿ï¼š{technical_analysis.get('ma_trend', 'æœªçŸ¥')}
- RSIæŒ‡æ ‡ï¼š{technical_analysis.get('rsi', 50):.1f}
- MACDä¿¡å·ï¼š{technical_analysis.get('macd_signal', 'æœªçŸ¥')}
- æˆäº¤é‡çŠ¶æ€ï¼š{technical_analysis.get('volume_status', 'æœªçŸ¥')}

æŠ€æœ¯é¢è¯„ä¼°ï¼š{'å¼ºåŠ¿' if scores.get('technical', 50) >= 70 else 'ä¸­æ€§' if scores.get('technical', 50) >= 50 else 'åå¼±'}"""
            analysis_sections.append(tech_analysis)
            
            # 4. å¸‚åœºæƒ…ç»ª
            sentiment_desc = f"""## ğŸ“° å¸‚åœºæƒ…ç»ªåˆ†æ

åŸºäº{sentiment_analysis.get('total_analyzed', 0)}æ¡æ–°é—»çš„åˆ†æï¼š
- æ•´ä½“æƒ…ç»ªï¼š{sentiment_analysis.get('sentiment_trend', 'ä¸­æ€§')}
- æƒ…ç»ªå¾—åˆ†ï¼š{sentiment_analysis.get('overall_sentiment', 0):.3f}
- ç½®ä¿¡åº¦ï¼š{sentiment_analysis.get('confidence_score', 0):.2%}

æ–°é—»åˆ†å¸ƒï¼š
- å…¬å¸æ–°é—»ï¼š{len(sentiment_analysis.get('company_news', []))}æ¡
- å…¬å¸å…¬å‘Šï¼š{len(sentiment_analysis.get('announcements', []))}æ¡  
- ç ”ç©¶æŠ¥å‘Šï¼š{len(sentiment_analysis.get('research_reports', []))}æ¡"""
            analysis_sections.append(sentiment_desc)
            
            # 5. æŠ•èµ„å»ºè®® + å¯æ‰§è¡Œæ“ä½œè®¡åˆ’
            recommendation = self.generate_recommendation(scores)

            # æ„é€ å…³é”®ä½ä¸é£æ§å‚æ•°
            bb_pos = float(technical_analysis.get('bb_position', 0.5) or 0.5)
            ma_trend = technical_analysis.get('ma_trend', 'æœªçŸ¥')
            rsi_val = float(technical_analysis.get('rsi', 50))
            macd_sig = technical_analysis.get('macd_signal', 'æœªçŸ¥')
            vol_ratio = float(technical_analysis.get('volume_ratio', 1.0))
            atr_pct = float(technical_analysis.get('atr_pct', 0.0))
            price = float(price_info.get('current_price', 0.0))
            ma20 = float(technical_analysis.get('price_above_ma20', 1.0) * price) if price > 0 else None

            # æ­¢æŸ/æ­¢ç›ˆçš„åŸºç¡€ï¼ˆæ ¹æ®æ³¢åŠ¨ç‡ATRè®¾å®šï¼‰
            sl_pct = 0.06 if atr_pct == 0 else min(0.06, max(0.03, atr_pct / 100 * 2.5))  # çº¦2.5å€ATR%
            tp_pct = max(0.06, min(0.18, sl_pct * 2.0))

            # ä¸‹ä¸€äº¤æ˜“æ—¥æ“ä½œå»ºè®®
            next_day_plan = []
            if ma_trend == 'å¤šå¤´æ’åˆ—' and macd_sig == 'é‡‘å‰å‘ä¸Š' and rsi_val < 70 and bb_pos <= 0.8:
                next_day_plan.append("è‹¥é«˜å¼€å¹¶æ”¾é‡(é‡æ¯”>1.5)ï¼Œå¯è€ƒè™‘åˆ†æ‰¹è·Ÿè¿›ï¼›ä½å¼€ä¸ç ´ MA20 å¯åœ¨å›è¸©æ—¶åŠ ä»“ã€‚")
            elif ma_trend == 'éœ‡è¡æ•´ç†' and 0.3 <= bb_pos <= 0.7:
                next_day_plan.append("éœ‡è¡åŒºé—´å†…é«˜æŠ›ä½å¸ï¼šæ¥è¿‘ä¸‹è½¨/MA20é™„è¿‘å°ä»“è¯•å¤šï¼Œé è¿‘ä¸Šè½¨é€æ­¥å‡ä»“ã€‚")
            elif ma_trend == 'ç©ºå¤´æ’åˆ—' or macd_sig == 'æ­»å‰å‘ä¸‹':
                next_day_plan.append("åå¼¹ç¼©é‡æ—¶é€¢é«˜å‡ä»“ï¼›ä»…åœ¨å¼ºåŠ¿æ”¾é‡æ”¶å¤MA20/MA50æ—¶è€ƒè™‘è¯•æ¢æ€§ä»“ä½ã€‚")
            else:
                next_day_plan.append("ç­‰å¾…æ–¹å‘é€‰æ‹©ï¼šè§‚å¯Ÿæ˜¯å¦æ”¾é‡çªç ´ MA20/MA50 æˆ– MACD é‡æ–°è½¬å¼ºåå†è¡ŒåŠ¨ã€‚")

            # æ¢æ‰‹ç‡ä¸é‡èƒ½æé†’
            tr = technical_analysis.get('turnover_rate')
            tr_ma20 = technical_analysis.get('turnover_rate_ma20')
            tr_ratio = technical_analysis.get('turnover_rate_ratio')
            turnover_tips = []
            if tr is not None and tr_ma20 is not None and tr_ratio is not None:
                if tr_ratio >= 1.8:
                    turnover_tips.append(f"ä¸Šä¸€äº¤æ˜“æ—¥æ¢æ‰‹ç‡ {tr:.2f}% æ˜¾è‘—é«˜äº20æ—¥å‡å€¼({tr_ma20:.2f}%)ï¼Œå…³æ³¨èµ„é‡‘åšå¼ˆä¸ä¸»åŠ›å¼‚åŠ¨ã€‚")
                elif tr_ratio <= 0.6:
                    turnover_tips.append(f"ä¸Šä¸€äº¤æ˜“æ—¥æ¢æ‰‹ç‡ {tr:.2f}% è¿œä½äº20æ—¥å‡å€¼({tr_ma20:.2f}%)ï¼ŒçŸ­çº¿å‚ä¸åº¦åä½ï¼Œçªç ´éœ€ç­‰å¾…æ”¾é‡ç¡®è®¤ã€‚")
                else:
                    turnover_tips.append(f"ä¸Šä¸€äº¤æ˜“æ—¥æ¢æ‰‹ç‡ {tr:.2f}%ï¼Œæ¥è¿‘20æ—¥å‡å€¼({tr_ma20:.2f}%)ï¼Œé‡èƒ½ä¸­æ€§ã€‚")
            else:
                turnover_tips.append("æœªè·å–åˆ°æ¢æ‰‹ç‡æ•°æ®ï¼Œé‡èƒ½ç ”åˆ¤ä»¥æˆäº¤é‡æ¯”å¯¹ä¸ºå‡†ã€‚")

            # é£é™©æé†’
            risks = []
            if atr_pct >= 6.0:
                risks.append("çŸ­æœŸæ³¢åŠ¨ç‡åé«˜ï¼Œä¸¥æ ¼æ§åˆ¶ä»“ä½ä¸æ­¢æŸï¼Œé¿å…è¿½é«˜ã€‚")
            if rsi_val >= 75:
                risks.append("RSI è¶…ä¹°åŒºåŸŸï¼Œå‡ºç°é•¿ä¸Šå½±/æ”¾é‡æ»æ¶¨éœ€åŠæ—¶æ­¢ç›ˆã€‚")
            if ma_trend == 'ç©ºå¤´æ’åˆ—':
                risks.append("ä¸­æœŸè¶‹åŠ¿åå¼±ï¼ŒåæŠ½æœªç«™ç¨³ MA20/MA50 å‰ä¸å®œé‡ä»“ã€‚")
            if vol_ratio > 2.0 and macd_sig != 'é‡‘å‰å‘ä¸Š':
                risks.append("æ”¾é‡ä½†åŠ¨èƒ½æœªåŒæ­¥è½¬å¼ºï¼Œè­¦æƒ•å†²é«˜å›è½ã€‚")
            if not risks:
                risks.append("å¸¸è§„å¸‚åœºé£é™©ï¼šå®è§‚æ”¿ç­–ã€è¡Œä¸šç›‘ç®¡ã€é»‘å¤©é¹…äº‹ä»¶ç­‰ï¼Œå»ºè®®åˆ†æ•£æŒä»“å¹¶è®¾ç½®é£æ§é˜ˆå€¼ã€‚")

            strategy = f"""## ğŸ¯ æŠ•èµ„ç­–ç•¥å»ºè®®

**æŠ•èµ„å»ºè®®ï¼š{recommendation}**

æ ¹æ®ç»¼åˆåˆ†æï¼Œæ‰§è¡Œè¦ç‚¹å¦‚ä¸‹ï¼š

### ğŸ“… ä¸‹ä¸€äº¤æ˜“æ—¥æ“ä½œ
- {next_day_plan[0]}

### ğŸ›¡ï¸ é£æ§ä¸ä»“ä½ç®¡ç†
- åˆå§‹æ­¢æŸï¼š{sl_pct*100:.1f}%ï¼ˆä»¥å…¥åœºä»·ä¸ºåŸºå‡†ï¼‰ï¼Œè§¦å‘å³é€€å‡ºï¼Œé¿å…äºæŸæ‰©å¤§ã€‚
- åˆ†æ‰¹æ­¢ç›ˆï¼šç¬¬ä¸€ç›®æ ‡ {tp_pct*100:.1f}%ï¼Œç¬¬äºŒç›®æ ‡ {(tp_pct*100*1.5):.1f}%ï¼›åˆ°ä»·åˆ†æ‰¹è½è¢‹ã€‚
- åŠ¨æ€è·Ÿè¸ªæ­¢æŸï¼šè‹¥ç›ˆåˆ©è¶…è¿‡ç¬¬ä¸€ç›®æ ‡ï¼Œå°†æ­¢æŸä¸Šç§»è‡³æˆæœ¬ä»·ä¸Šæ–¹ 1%-2%ã€‚

### ğŸ” æ¢æ‰‹ç‡ä¸é‡èƒ½æé†’
- {turnover_tips[0]}
- å…³æ³¨é‡æ¯”ä¸æˆäº¤é¢å˜åŒ–ï¼Œçªç ´å…³é”®å‡çº¿ï¼ˆå¦‚ MA20/MA50ï¼‰æ—¶éœ€æ”¾é‡é…åˆæ–¹å¯ç¡®è®¤æœ‰æ•ˆæ€§ã€‚

### âš ï¸ é£é™©æé†’
- {risks[0]}
"""
            analysis_sections.append(strategy)
            
            return "\n\n".join(analysis_sections)
            
        except Exception as e:
            self.logger.error(f"é«˜çº§è§„åˆ™åˆ†æå¤±è´¥: {e}")
            return "åˆ†æç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"

    def set_streaming_config(self, enabled=True, show_thinking=True):
        """è®¾ç½®æµå¼æ¨ç†é…ç½®"""
        self.streaming_config.update({
            'enabled': enabled,
            'show_thinking': show_thinking
        })

    def analyze_stock(self, stock_code, enable_streaming=None):
        """åˆ†æè‚¡ç¥¨çš„ä¸»æ–¹æ³•ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        if enable_streaming is None:
            enable_streaming = self.streaming_config.get('enabled', False)
        
        try:
            self.logger.info(f"å¼€å§‹å¢å¼ºç‰ˆè‚¡ç¥¨åˆ†æ: {stock_code}")
            
            # è·å–è‚¡ç¥¨åç§°
            stock_name = self.get_stock_name(stock_code)
            
            # 1. è·å–ä»·æ ¼æ•°æ®å’ŒæŠ€æœ¯åˆ†æ
            self.logger.info("æ­£åœ¨è¿›è¡ŒæŠ€æœ¯åˆ†æ...")
            price_data = self.get_stock_data(stock_code)
            if price_data.empty:
                raise ValueError(f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„ä»·æ ¼æ•°æ®")
            
            price_info = self.get_price_info(price_data)
            technical_analysis = self.calculate_technical_indicators(price_data)
            technical_score = self.calculate_technical_score(technical_analysis)

            # æå‰è®¡ç®—è¿‘æœˆèµ„é‡‘æµå‘ï¼Œå¹¶å¯¹æŠ€æœ¯é¢è¯„åˆ†åšè½»é‡çº§ä¿®æ­£
            try:
                capital_flow = self.calculate_capital_flow(stock_code, price_data, None, window_days=30)
                status = (capital_flow or {}).get('status', '')
                # ä¾æ®ä¸»åŠ›å‡€æµçŠ¶æ€å¾®è°ƒæŠ€æœ¯é¢å¾—åˆ†ï¼ˆÂ±6å†…ï¼‰
                if isinstance(status, str):
                    if 'ä¸»åŠ›å‡€æµå…¥å¼º' in status:
                        technical_score = float(min(100.0, technical_score + 6))
                    elif 'ä¸»åŠ›å‡€æµå…¥ä¸­' in status:
                        technical_score = float(min(100.0, technical_score + 3))
                    elif 'ä¸»åŠ›å‡€æµå…¥å¼±' in status:
                        technical_score = float(min(100.0, technical_score + 1))
                    elif 'ä¸»åŠ›å‡€æµå‡ºè¾ƒå¼º' in status:
                        technical_score = float(max(0.0, technical_score - 6))
                    elif 'ä¸»åŠ›å‡€æµå‡º' in status:
                        technical_score = float(max(0.0, technical_score - 3))
            except Exception as e:
                self.logger.info(f"èµ„é‡‘æµä¿®æ­£è·³è¿‡: {e}")
                capital_flow = {'status': 'æ•°æ®ä¸è¶³', 'note': str(e)}
            
            # 2. è·å–25é¡¹è´¢åŠ¡æŒ‡æ ‡å’Œç»¼åˆåŸºæœ¬é¢åˆ†æ
            self.logger.info("æ­£åœ¨è¿›è¡Œ25é¡¹è´¢åŠ¡æŒ‡æ ‡åˆ†æ...")
            fundamental_data = self.get_comprehensive_fundamental_data(stock_code)
            fundamental_score = self.calculate_fundamental_score(fundamental_data)
            # 2.1 ä½¿ç”¨åŸºæœ¬é¢å¸‚å€¼ä¿¡æ¯ï¼Œé‡æ–°è®¡ç®—èµ„é‡‘æµï¼ˆç”¨äºæŠ¥å‘Š/AIæ›´ç²¾å‡†çš„å¼ºåº¦åˆ†çº§ï¼‰
            try:
                capital_flow = self.calculate_capital_flow(stock_code, price_data, fundamental_data, window_days=30)
            except Exception as e:
                self.logger.info(f"èµ„é‡‘æµå¤ç®—å¤±è´¥: {e}")
            
            # 3. è·å–ç»¼åˆæ–°é—»æ•°æ®å’Œé«˜çº§æƒ…ç»ªåˆ†æ
            self.logger.info("æ­£åœ¨è¿›è¡Œç»¼åˆæ–°é—»å’Œæƒ…ç»ªåˆ†æ...")
            comprehensive_news_data = self.get_comprehensive_news_data(stock_code, days=30)
            sentiment_analysis = self.calculate_advanced_sentiment_analysis(comprehensive_news_data)
            sentiment_score = self.calculate_sentiment_score(sentiment_analysis)
            
            # åˆå¹¶æ–°é—»æ•°æ®åˆ°æƒ…ç»ªåˆ†æç»“æœä¸­ï¼Œæ–¹ä¾¿AIåˆ†æä½¿ç”¨
            sentiment_analysis.update(comprehensive_news_data)
            
            # 4. è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆå·²åŒ…å«èµ„é‡‘æµå¯¹æŠ€æœ¯é¢çš„ä¿®æ­£ï¼‰
            scores = {
                'technical': technical_score,
                'fundamental': fundamental_score,
                'sentiment': sentiment_score,
                'comprehensive': self.calculate_comprehensive_score({
                    'technical': technical_score,
                    'fundamental': fundamental_score,
                    'sentiment': sentiment_score
                })
            }
            
            # 5. ç”ŸæˆæŠ•èµ„å»ºè®®
            recommendation = self.generate_recommendation(scores)

            # 6. AIå¢å¼ºåˆ†æï¼ˆåŒ…å«æ‰€æœ‰è¯¦ç»†æ•°æ®ï¼‰
            ai_analysis = self.generate_ai_analysis({
                'stock_code': stock_code,
                'stock_name': stock_name,
                'price_info': price_info,
                'technical_analysis': technical_analysis,
                'fundamental_data': fundamental_data,
                'sentiment_analysis': sentiment_analysis,
                'capital_flow': capital_flow,
                'scores': scores
            }, enable_streaming)
            
            # 7. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            report = {
                'stock_code': stock_code,
                'stock_name': stock_name,
                'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'price_info': price_info,
                'technical_analysis': technical_analysis,
                'fundamental_data': fundamental_data,
                'comprehensive_news_data': comprehensive_news_data,
                'sentiment_analysis': sentiment_analysis,
                'capital_flow': capital_flow,
                'scores': scores,
                'analysis_weights': self.analysis_weights,
                'recommendation': recommendation,
                'ai_analysis': ai_analysis,
                'data_quality': {
                    'financial_indicators_count': len(fundamental_data.get('financial_indicators', {})),
                    'total_news_count': sentiment_analysis.get('total_analyzed', 0),
                    'sentiment_confidence': sentiment_analysis.get('confidence_score', 0.0),
                    'analysis_completeness': 'å®Œæ•´' if len(fundamental_data.get('financial_indicators', {})) >= 15 else 'éƒ¨åˆ†'
                }
            }

            # ä¿å­˜æœ€è¿‘ä¸€æ¬¡æ•°æ®è´¨é‡ä¾›åŠ¨æ€æƒé‡ä½¿ç”¨
            try:
                self._last_data_quality = {
                    'financial_indicators_count': report['data_quality']['financial_indicators_count'],
                    'total_news_count': report['data_quality']['total_news_count'],
                    'sentiment_confidence': report['data_quality']['sentiment_confidence']
                }
            except Exception:
                self._last_data_quality = {}
            
            self.logger.info(f"âœ“ å¢å¼ºç‰ˆè‚¡ç¥¨åˆ†æå®Œæˆ: {stock_code}")
            self.logger.info(f"  - è´¢åŠ¡æŒ‡æ ‡: {len(fundamental_data.get('financial_indicators', {}))} é¡¹")
            self.logger.info(f"  - æ–°é—»æ•°æ®: {sentiment_analysis.get('total_analyzed', 0)} æ¡")
            self.logger.info(f"  - ç»¼åˆå¾—åˆ†: {scores['comprehensive']:.1f}")
            
            return report
            
        except Exception as e:
            self.logger.error(f"å¢å¼ºç‰ˆè‚¡ç¥¨åˆ†æå¤±è´¥ {stock_code}: {str(e)}")
            raise

    # å…¼å®¹æ—§ç‰ˆæœ¬çš„æ–¹æ³•å
    def get_fundamental_data(self, stock_code):
        """å…¼å®¹æ–¹æ³•ï¼šè·å–åŸºæœ¬é¢æ•°æ®"""
        return self.get_comprehensive_fundamental_data(stock_code)
    
    def get_news_data(self, stock_code, days=30):
        """å…¼å®¹æ–¹æ³•ï¼šè·å–æ–°é—»æ•°æ®"""
        return self.get_comprehensive_news_data(stock_code, days)
    
    def calculate_news_sentiment(self, news_data):
        """å…¼å®¹æ–¹æ³•ï¼šè®¡ç®—æ–°é—»æƒ…ç»ª"""
        return self.calculate_advanced_sentiment_analysis(news_data)
    
    def get_sentiment_analysis(self, stock_code):
        """å…¼å®¹æ–¹æ³•ï¼šè·å–æƒ…ç»ªåˆ†æ"""
        news_data = self.get_comprehensive_news_data(stock_code)
        return self.calculate_advanced_sentiment_analysis(news_data)

    def _latest_dt(self, df, date_candidates: List[str]):
        """è¿”å›æ•°æ®æ¡†ä¸­å€™é€‰æ—¥æœŸåˆ—çš„æœ€æ–°æ—¥æœŸï¼Œç”¨äºæ–°é²œåº¦åˆ¤æ–­"""
        try:
            for c in date_candidates:
                if c in df.columns:
                    s = pd.to_datetime(df[c], errors='coerce')
                    if s.notna().any():
                        return s.max()
        except Exception:
            pass
        return None

    def _is_data_stale(self, df, date_candidates: List[str], max_days: int, what: str) -> bool:
        """åˆ¤æ–­æ•°æ®æ˜¯å¦è¿‡æ—§ï¼Œè¶…è¿‡max_daysåˆ™è§†ä¸ºè¿‡æœŸ"""
        dt = self._latest_dt(df, date_candidates)
        if dt is None:
            self.logger.warning(f"{what} æœªæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œæ— æ³•åˆ¤æ–­æ–°é²œåº¦")
            return False
        try:
            delta = (datetime.now() - dt.to_pydatetime()).days
        except Exception:
            delta = 99999
        self.logger.info(f"{what} æœ€æ–°æ—¥æœŸ: {getattr(dt, 'date', lambda: dt)()} (è·ä»Š {delta} å¤©)")
        if delta > max_days:
            self.logger.warning(f"{what} æ•°æ®è¿‡æ—§(>{max_days}å¤©)ï¼Œå¿½ç•¥è¯¥æ¥å£ç»“æœ")
            return True
        return False

    def _normalize_dividend_records(self, records: List[dict]) -> List[dict]:
        """æ ‡å‡†åŒ–åˆ†çº¢è®°å½•ç»“æ„ï¼Œç¡®ä¿è¿›å…¥æ¨¡å‹çš„é”®ä¸€è‡´ä¸”ç²¾ç®€"""
        norm: List[dict] = []
        for x in records or []:
            year = str(x.get('year') or x.get('dividYear') or x.get('æŠ¥å‘Šå¹´åº¦') or x.get('æŠ¥å‘Šæ—¶é—´') or '')
            per = x.get('dividend_per_share') or x.get('dividCashPsBeforeTax') or x.get('æ¯è‚¡æ´¾æ¯(ç¨å‰)') or x.get('æ´¾æ¯æ¯”ä¾‹')
            try:
                per = float(per)
            except Exception:
                per = None
            exd = x.get('ex_dividend_date') or x.get('dividOperateDate') or x.get('é™¤æƒé™¤æ¯æ—¥') or x.get('é™¤æƒæ—¥') or ''
            src = x.get('source') or 'unknown'
            item = {
                'year': year,
                'dividend_per_share': per,
                'ex_dividend_date': str(exd),
                'source': src,
            }
            if per is not None:
                norm.append(item)
        return norm

def main():
    """ä¸»å‡½æ•°"""
    analyzer = EnhancedStockAnalyzer()
    
    # æµ‹è¯•åˆ†æ
    test_stocks = ['000001', '600036', '300019', '000525']
    
    for stock_code in test_stocks:
        try:
            print(f"\n=== å¼€å§‹å¢å¼ºç‰ˆåˆ†æ {stock_code} ===")
            report = analyzer.analyze_stock(stock_code)
            
            print(f"è‚¡ç¥¨ä»£ç : {report['stock_code']}")
            print(f"è‚¡ç¥¨åç§°: {report['stock_name']}")
            print(f"å½“å‰ä»·æ ¼: {report['price_info']['current_price']:.2f}å…ƒ")
            print(f"æ¶¨è·Œå¹…: {report['price_info']['price_change']:.2f}%")
            print(f"è´¢åŠ¡æŒ‡æ ‡æ•°é‡: {report['data_quality']['financial_indicators_count']}")
            print(f"æ–°é—»æ•°æ®é‡: {report['data_quality']['total_news_count']}")
            print(f"ç»¼åˆå¾—åˆ†: {report['scores']['comprehensive']:.1f}")
            print(f"æŠ•èµ„å»ºè®®: {report['recommendation']}")
            print("=" * 60)
            
        except Exception as e:
            print(f"åˆ†æ {stock_code} å¤±è´¥: {e}")


if __name__ == "__main__":
    main()
